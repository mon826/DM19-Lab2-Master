{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: #e1ff00'> <h1>Student Information</h1>  \n",
    "    \n",
    "Name: Miss Pattamon Rattanapan\n",
    "\n",
    "Student ID: 108065436\n",
    "\n",
    "GitHub ID: https://github.com/mon826\n",
    "\n",
    "Kaggle name:Username : mon826 (display name Pattamon R, account ID 2514034)\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "[Snapshot](img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the [DM19-Lab2-Master Repo](https://github.com/EvaArevalo/DM19-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/t/179d01d4dd984fc5ac45a894822479dd) regarding Emotion Recognition on Twitter. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the score (ie. 20% of 30% )\n",
    "\n",
    "    - **Top 41% - 100%**: Get (101-x)% of the score, where x is your ranking in the leaderboard (ie. (101-x)% of 30% )   \n",
    "    Submit your last submission __BEFORE the deadline (Nov. 23rd 11:59 pm, Saturday)__. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "You can submit your homework following these guidelines: [Git Intro & How to hand your homework](https://github.com/EvaArevalo/DM19-Lab1-Master/blob/master/Git%20Intro%20%26%20How%20to%20hand%20your%20homework.ipynb), but make sure to fork the [DM19-Lab2-Homework](https://github.com/EvaArevalo/DM19-Lab2-Homework) repository this time! Also please __DONÂ´T UPLOAD HUGE DOCUMENTS__, please use Git ignore for that.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin Assignment Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import nltk\n",
    "import os\n",
    "import math\n",
    "import string\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import helpers.data_mining_helpers as dmh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File importing & Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Import the main file: Tweet_DM.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_index</th>\n",
       "      <th>_source</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>391</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['Snapchat'], 'tweet_id...</td>\n",
       "      <td>2015-05-23 11:42:47</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>433</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['freepress', 'TrumpLeg...</td>\n",
       "      <td>2016-01-28 04:52:09</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>232</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['bibleverse'], 'tweet_...</td>\n",
       "      <td>2017-12-25 04:39:20</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>376</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...</td>\n",
       "      <td>2016-01-24 23:53:05</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>989</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2de2...</td>\n",
       "      <td>2016-01-08 17:18:59</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867530</td>\n",
       "      <td>827</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['mixedfeeling', 'butim...</td>\n",
       "      <td>2015-05-12 12:51:52</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867531</td>\n",
       "      <td>368</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x29d0...</td>\n",
       "      <td>2017-10-02 17:54:04</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867532</td>\n",
       "      <td>498</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2a6a...</td>\n",
       "      <td>2016-10-10 11:04:32</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867533</td>\n",
       "      <td>840</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x24fa...</td>\n",
       "      <td>2016-09-02 14:25:06</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867534</td>\n",
       "      <td>360</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['Sundayvibes'], 'tweet...</td>\n",
       "      <td>2016-11-16 01:40:07</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         _score          _index  \\\n",
       "0           391  hashtag_tweets   \n",
       "1           433  hashtag_tweets   \n",
       "2           232  hashtag_tweets   \n",
       "3           376  hashtag_tweets   \n",
       "4           989  hashtag_tweets   \n",
       "...         ...             ...   \n",
       "1867530     827  hashtag_tweets   \n",
       "1867531     368  hashtag_tweets   \n",
       "1867532     498  hashtag_tweets   \n",
       "1867533     840  hashtag_tweets   \n",
       "1867534     360  hashtag_tweets   \n",
       "\n",
       "                                                   _source  \\\n",
       "0        {'tweet': {'hashtags': ['Snapchat'], 'tweet_id...   \n",
       "1        {'tweet': {'hashtags': ['freepress', 'TrumpLeg...   \n",
       "2        {'tweet': {'hashtags': ['bibleverse'], 'tweet_...   \n",
       "3        {'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...   \n",
       "4        {'tweet': {'hashtags': [], 'tweet_id': '0x2de2...   \n",
       "...                                                    ...   \n",
       "1867530  {'tweet': {'hashtags': ['mixedfeeling', 'butim...   \n",
       "1867531  {'tweet': {'hashtags': [], 'tweet_id': '0x29d0...   \n",
       "1867532  {'tweet': {'hashtags': [], 'tweet_id': '0x2a6a...   \n",
       "1867533  {'tweet': {'hashtags': [], 'tweet_id': '0x24fa...   \n",
       "1867534  {'tweet': {'hashtags': ['Sundayvibes'], 'tweet...   \n",
       "\n",
       "                  _crawldate   _type  \n",
       "0        2015-05-23 11:42:47  tweets  \n",
       "1        2016-01-28 04:52:09  tweets  \n",
       "2        2017-12-25 04:39:20  tweets  \n",
       "3        2016-01-24 23:53:05  tweets  \n",
       "4        2016-01-08 17:18:59  tweets  \n",
       "...                      ...     ...  \n",
       "1867530  2015-05-12 12:51:52  tweets  \n",
       "1867531  2017-10-02 17:54:04  tweets  \n",
       "1867532  2016-10-10 11:04:32  tweets  \n",
       "1867533  2016-09-02 14:25:06  tweets  \n",
       "1867534  2016-11-16 01:40:07  tweets  \n",
       "\n",
       "[1867535 rows x 5 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use pandas to read file \n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_json(r'C:\\Users\\User\\Data Mining_NTHU\\DMlab2x\\DM19-Lab2-Homework\\Data for Lab2_HW\\tweets_DM.json',lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_score', '_index', '_source', '_crawldate', '_type'], dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check columns name\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>_index</th>\n",
       "      <th>_source</th>\n",
       "      <th>_score</th>\n",
       "      <th>_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-23 11:42:47</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['Snapchat'], 'tweet_id...</td>\n",
       "      <td>391</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-28 04:52:09</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['freepress', 'TrumpLeg...</td>\n",
       "      <td>433</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2017-12-25 04:39:20</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['bibleverse'], 'tweet_...</td>\n",
       "      <td>232</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-24 23:53:05</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...</td>\n",
       "      <td>376</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2016-01-08 17:18:59</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2de2...</td>\n",
       "      <td>989</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867530</td>\n",
       "      <td>2015-05-12 12:51:52</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['mixedfeeling', 'butim...</td>\n",
       "      <td>827</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867531</td>\n",
       "      <td>2017-10-02 17:54:04</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x29d0...</td>\n",
       "      <td>368</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867532</td>\n",
       "      <td>2016-10-10 11:04:32</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2a6a...</td>\n",
       "      <td>498</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867533</td>\n",
       "      <td>2016-09-02 14:25:06</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x24fa...</td>\n",
       "      <td>840</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867534</td>\n",
       "      <td>2016-11-16 01:40:07</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['Sundayvibes'], 'tweet...</td>\n",
       "      <td>360</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  _crawldate          _index  \\\n",
       "0        2015-05-23 11:42:47  hashtag_tweets   \n",
       "1        2016-01-28 04:52:09  hashtag_tweets   \n",
       "2        2017-12-25 04:39:20  hashtag_tweets   \n",
       "3        2016-01-24 23:53:05  hashtag_tweets   \n",
       "4        2016-01-08 17:18:59  hashtag_tweets   \n",
       "...                      ...             ...   \n",
       "1867530  2015-05-12 12:51:52  hashtag_tweets   \n",
       "1867531  2017-10-02 17:54:04  hashtag_tweets   \n",
       "1867532  2016-10-10 11:04:32  hashtag_tweets   \n",
       "1867533  2016-09-02 14:25:06  hashtag_tweets   \n",
       "1867534  2016-11-16 01:40:07  hashtag_tweets   \n",
       "\n",
       "                                                   _source  _score   _type  \n",
       "0        {'tweet': {'hashtags': ['Snapchat'], 'tweet_id...     391  tweets  \n",
       "1        {'tweet': {'hashtags': ['freepress', 'TrumpLeg...     433  tweets  \n",
       "2        {'tweet': {'hashtags': ['bibleverse'], 'tweet_...     232  tweets  \n",
       "3        {'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...     376  tweets  \n",
       "4        {'tweet': {'hashtags': [], 'tweet_id': '0x2de2...     989  tweets  \n",
       "...                                                    ...     ...     ...  \n",
       "1867530  {'tweet': {'hashtags': ['mixedfeeling', 'butim...     827  tweets  \n",
       "1867531  {'tweet': {'hashtags': [], 'tweet_id': '0x29d0...     368  tweets  \n",
       "1867532  {'tweet': {'hashtags': [], 'tweet_id': '0x2a6a...     498  tweets  \n",
       "1867533  {'tweet': {'hashtags': [], 'tweet_id': '0x24fa...     840  tweets  \n",
       "1867534  {'tweet': {'hashtags': ['Sundayvibes'], 'tweet...     360  tweets  \n",
       "\n",
       "[1867535 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rearrange columns \n",
    "df = df[['_crawldate','_index','_source','_score','_type']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>index</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-23 11:42:47</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['Snapchat'], 'tweet_id...</td>\n",
       "      <td>391</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-28 04:52:09</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['freepress', 'TrumpLeg...</td>\n",
       "      <td>433</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2017-12-25 04:39:20</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['bibleverse'], 'tweet_...</td>\n",
       "      <td>232</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-24 23:53:05</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...</td>\n",
       "      <td>376</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2016-01-08 17:18:59</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2de2...</td>\n",
       "      <td>989</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867530</td>\n",
       "      <td>2015-05-12 12:51:52</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['mixedfeeling', 'butim...</td>\n",
       "      <td>827</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867531</td>\n",
       "      <td>2017-10-02 17:54:04</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x29d0...</td>\n",
       "      <td>368</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867532</td>\n",
       "      <td>2016-10-10 11:04:32</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2a6a...</td>\n",
       "      <td>498</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867533</td>\n",
       "      <td>2016-09-02 14:25:06</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x24fa...</td>\n",
       "      <td>840</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867534</td>\n",
       "      <td>2016-11-16 01:40:07</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['Sundayvibes'], 'tweet...</td>\n",
       "      <td>360</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date           index  \\\n",
       "0        2015-05-23 11:42:47  hashtag_tweets   \n",
       "1        2016-01-28 04:52:09  hashtag_tweets   \n",
       "2        2017-12-25 04:39:20  hashtag_tweets   \n",
       "3        2016-01-24 23:53:05  hashtag_tweets   \n",
       "4        2016-01-08 17:18:59  hashtag_tweets   \n",
       "...                      ...             ...   \n",
       "1867530  2015-05-12 12:51:52  hashtag_tweets   \n",
       "1867531  2017-10-02 17:54:04  hashtag_tweets   \n",
       "1867532  2016-10-10 11:04:32  hashtag_tweets   \n",
       "1867533  2016-09-02 14:25:06  hashtag_tweets   \n",
       "1867534  2016-11-16 01:40:07  hashtag_tweets   \n",
       "\n",
       "                                                    source  score    type  \n",
       "0        {'tweet': {'hashtags': ['Snapchat'], 'tweet_id...    391  tweets  \n",
       "1        {'tweet': {'hashtags': ['freepress', 'TrumpLeg...    433  tweets  \n",
       "2        {'tweet': {'hashtags': ['bibleverse'], 'tweet_...    232  tweets  \n",
       "3        {'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...    376  tweets  \n",
       "4        {'tweet': {'hashtags': [], 'tweet_id': '0x2de2...    989  tweets  \n",
       "...                                                    ...    ...     ...  \n",
       "1867530  {'tweet': {'hashtags': ['mixedfeeling', 'butim...    827  tweets  \n",
       "1867531  {'tweet': {'hashtags': [], 'tweet_id': '0x29d0...    368  tweets  \n",
       "1867532  {'tweet': {'hashtags': [], 'tweet_id': '0x2a6a...    498  tweets  \n",
       "1867533  {'tweet': {'hashtags': [], 'tweet_id': '0x24fa...    840  tweets  \n",
       "1867534  {'tweet': {'hashtags': ['Sundayvibes'], 'tweet...    360  tweets  \n",
       "\n",
       "[1867535 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rename the column to be easier to read and print the data to see \n",
    "#but the date and time is stored under the same column and the source is starting with {'tweet'{hastags'\n",
    "df.rename(columns={'_crawldate':'date'}, inplace = True)\n",
    "df.rename(columns={'_index':'index'}, inplace = True)\n",
    "df.rename(columns={'_source':'source'}, inplace = True)\n",
    "df.rename(columns={'_score':'score'}, inplace = True)\n",
    "df.rename(columns={'_type':'type'}, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then I try again using pandas to read the file  \n",
    "#Source: https://pandas.pydata.org/pandas-docs/stable/reference/io.html#json\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "spdf = json_normalize(df.source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet.hashtags</th>\n",
       "      <th>tweet.tweet_id</th>\n",
       "      <th>tweet.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867530</td>\n",
       "      <td>[mixedfeeling, butimTHATperson]</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867531</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867532</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867533</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867534</td>\n",
       "      <td>[Sundayvibes]</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          tweet.hashtags tweet.tweet_id  \\\n",
       "0                             [Snapchat]       0x376b20   \n",
       "1          [freepress, TrumpLegacy, CNN]       0x2d5350   \n",
       "2                           [bibleverse]       0x28b412   \n",
       "3                                     []       0x1cd5b0   \n",
       "4                                     []       0x2de201   \n",
       "...                                  ...            ...   \n",
       "1867530  [mixedfeeling, butimTHATperson]       0x316b80   \n",
       "1867531                               []       0x29d0cb   \n",
       "1867532                               []       0x2a6a4f   \n",
       "1867533                               []       0x24faed   \n",
       "1867534                    [Sundayvibes]       0x34be8c   \n",
       "\n",
       "                                                tweet.text  \n",
       "0        People who post \"add me on #Snapchat\" must be ...  \n",
       "1        @brianklaas As we see, Trump is dangerous to #...  \n",
       "2        Confident of your obedience, I write to you, k...  \n",
       "3                      Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>  \n",
       "4        \"Trust is not the same as faith. A friend is s...  \n",
       "...                                                    ...  \n",
       "1867530  When you buy the last 2 tickets remaining for ...  \n",
       "1867531  I swear all this hard work gone pay off one da...  \n",
       "1867532  @Parcel2Go no card left when I wasn't in so I ...  \n",
       "1867533  Ah, corporate life, where you can date <LH> us...  \n",
       "1867534             Blessed to be living #Sundayvibes <LH>  \n",
       "\n",
       "[1867535 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet.hashtags', 'tweet.tweet_id', 'tweet.text'], dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then check the column names\n",
    "spdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet.tweet_id</th>\n",
       "      <th>tweet.hashtags</th>\n",
       "      <th>tweet.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>[]</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867530</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>[mixedfeeling, butimTHATperson]</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867531</td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>[]</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867532</td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>[]</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867533</td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867534</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>[Sundayvibes]</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet.tweet_id                   tweet.hashtags  \\\n",
       "0             0x376b20                       [Snapchat]   \n",
       "1             0x2d5350    [freepress, TrumpLegacy, CNN]   \n",
       "2             0x28b412                     [bibleverse]   \n",
       "3             0x1cd5b0                               []   \n",
       "4             0x2de201                               []   \n",
       "...                ...                              ...   \n",
       "1867530       0x316b80  [mixedfeeling, butimTHATperson]   \n",
       "1867531       0x29d0cb                               []   \n",
       "1867532       0x2a6a4f                               []   \n",
       "1867533       0x24faed                               []   \n",
       "1867534       0x34be8c                    [Sundayvibes]   \n",
       "\n",
       "                                                tweet.text  \n",
       "0        People who post \"add me on #Snapchat\" must be ...  \n",
       "1        @brianklaas As we see, Trump is dangerous to #...  \n",
       "2        Confident of your obedience, I write to you, k...  \n",
       "3                      Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>  \n",
       "4        \"Trust is not the same as faith. A friend is s...  \n",
       "...                                                    ...  \n",
       "1867530  When you buy the last 2 tickets remaining for ...  \n",
       "1867531  I swear all this hard work gone pay off one da...  \n",
       "1867532  @Parcel2Go no card left when I wasn't in so I ...  \n",
       "1867533  Ah, corporate life, where you can date <LH> us...  \n",
       "1867534             Blessed to be living #Sundayvibes <LH>  \n",
       "\n",
       "[1867535 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rearrange the columns and print it to see how it looks like\n",
    "spdf = spdf[['tweet.tweet_id','tweet.hashtags','tweet.text']]\n",
    "spdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>[]</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867530</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>[mixedfeeling, butimTHATperson]</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867531</td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>[]</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867532</td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>[]</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867533</td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867534</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>[Sundayvibes]</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                         hashtags  \\\n",
       "0        0x376b20                       [Snapchat]   \n",
       "1        0x2d5350    [freepress, TrumpLegacy, CNN]   \n",
       "2        0x28b412                     [bibleverse]   \n",
       "3        0x1cd5b0                               []   \n",
       "4        0x2de201                               []   \n",
       "...           ...                              ...   \n",
       "1867530  0x316b80  [mixedfeeling, butimTHATperson]   \n",
       "1867531  0x29d0cb                               []   \n",
       "1867532  0x2a6a4f                               []   \n",
       "1867533  0x24faed                               []   \n",
       "1867534  0x34be8c                    [Sundayvibes]   \n",
       "\n",
       "                                                      text  \n",
       "0        People who post \"add me on #Snapchat\" must be ...  \n",
       "1        @brianklaas As we see, Trump is dangerous to #...  \n",
       "2        Confident of your obedience, I write to you, k...  \n",
       "3                      Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>  \n",
       "4        \"Trust is not the same as faith. A friend is s...  \n",
       "...                                                    ...  \n",
       "1867530  When you buy the last 2 tickets remaining for ...  \n",
       "1867531  I swear all this hard work gone pay off one da...  \n",
       "1867532  @Parcel2Go no card left when I wasn't in so I ...  \n",
       "1867533  Ah, corporate life, where you can date <LH> us...  \n",
       "1867534             Blessed to be living #Sundayvibes <LH>  \n",
       "\n",
       "[1867535 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rename the column to be easier to read and print the data to see again\n",
    "spdf.rename(columns={'tweet.tweet_id':'id'}, inplace = True)\n",
    "spdf.rename(columns={'tweet.hashtags':'hashtags'}, inplace = True)\n",
    "spdf.rename(columns={'tweet.text':'text'}, inplace = True)\n",
    "spdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data identification file - file defining which ID is training or testing set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0x29e452</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x2b3819</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x2a2acc</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867530</td>\n",
       "      <td>0x227e25</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867531</td>\n",
       "      <td>0x293813</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867532</td>\n",
       "      <td>0x1e1a7e</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867533</td>\n",
       "      <td>0x2156a5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867534</td>\n",
       "      <td>0x2bb9d2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id identification\n",
       "0        0x28cc61           test\n",
       "1        0x29e452          train\n",
       "2        0x2b3819          train\n",
       "3        0x2db41f           test\n",
       "4        0x2a2acc          train\n",
       "...           ...            ...\n",
       "1867530  0x227e25          train\n",
       "1867531  0x293813          train\n",
       "1867532  0x1e1a7e          train\n",
       "1867533  0x2156a5          train\n",
       "1867534  0x2bb9d2          train\n",
       "\n",
       "[1867535 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the file data identification by using pandas\n",
    "col_Names2=[\"id\", \"identification\"]\n",
    "dfid = pd.read_csv(r'C:\\Users\\User\\Data Mining_NTHU\\DMlab2x\\DM19-Lab2-Homework\\Data for Lab2_HW\\data_identification.csv',\n",
    "                      names =col_Names2, header =0)\n",
    "dfid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import emotion file - The training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x3140b1</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0x368b73</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x296183</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x2bd6e1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x2ee1dd</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455558</td>\n",
       "      <td>0x38dba0</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455559</td>\n",
       "      <td>0x300ea2</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455560</td>\n",
       "      <td>0x360b99</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455561</td>\n",
       "      <td>0x22eecf</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455562</td>\n",
       "      <td>0x2fb282</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id       emotion\n",
       "0        0x3140b1       sadness\n",
       "1        0x368b73       disgust\n",
       "2        0x296183  anticipation\n",
       "3        0x2bd6e1           joy\n",
       "4        0x2ee1dd  anticipation\n",
       "...           ...           ...\n",
       "1455558  0x38dba0           joy\n",
       "1455559  0x300ea2           joy\n",
       "1455560  0x360b99          fear\n",
       "1455561  0x22eecf           joy\n",
       "1455562  0x2fb282  anticipation\n",
       "\n",
       "[1455563 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the file emotion by using pandas\n",
    "col_Names=[\"id\", \"emotion\"]\n",
    "emotion = pd.read_csv(r'C:\\Users\\User\\Data Mining_NTHU\\DMlab2x\\DM19-Lab2-Homework\\Data for Lab2_HW\\emotion.csv', header = 0, names =col_Names)\n",
    "emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>id</th>\n",
       "      <th>identification</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3735065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x227e25</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3735066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x293813</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3735067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x1e1a7e</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3735068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x2156a5</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3735069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x2bb9d2</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3735070 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              hashtags        id identification  \\\n",
       "0                           [Snapchat]  0x376b20            NaN   \n",
       "1        [freepress, TrumpLegacy, CNN]  0x2d5350            NaN   \n",
       "2                         [bibleverse]  0x28b412            NaN   \n",
       "3                                   []  0x1cd5b0            NaN   \n",
       "4                                   []  0x2de201            NaN   \n",
       "...                                ...       ...            ...   \n",
       "3735065                            NaN  0x227e25          train   \n",
       "3735066                            NaN  0x293813          train   \n",
       "3735067                            NaN  0x1e1a7e          train   \n",
       "3735068                            NaN  0x2156a5          train   \n",
       "3735069                            NaN  0x2bb9d2          train   \n",
       "\n",
       "                                                      text  \n",
       "0        People who post \"add me on #Snapchat\" must be ...  \n",
       "1        @brianklaas As we see, Trump is dangerous to #...  \n",
       "2        Confident of your obedience, I write to you, k...  \n",
       "3                      Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>  \n",
       "4        \"Trust is not the same as faith. A friend is s...  \n",
       "...                                                    ...  \n",
       "3735065                                                NaN  \n",
       "3735066                                                NaN  \n",
       "3735067                                                NaN  \n",
       "3735068                                                NaN  \n",
       "3735069                                                NaN  \n",
       "\n",
       "[3735070 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge the spdf with the dfid together \n",
    "#>>https://stackoverflow.com/questions/21435176/appending-two-dataframes-with-same-columns-different-order\n",
    "#But it's wrong \n",
    "totaldf = pd.concat([spdf, dfid], ignore_index=True, sort=True)\n",
    "totaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>[]</td>\n",
       "      <td>@JZED74 While inappropriate AF, he likely wasn...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>[BlackMirror]</td>\n",
       "      <td>o m g Shut Up And Dance though #BlackMirror &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>[twitch, Destinybeta, Destiny, Destiny2, Desti...</td>\n",
       "      <td>On #twitch &lt;LH&gt; on the #Destinybeta #Destiny #...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>[]</td>\n",
       "      <td>I tried to figure out why you mean so much to ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>[auspol, fizza]</td>\n",
       "      <td>The only â€œbig planâ€ you ever had in your life,...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867530</td>\n",
       "      <td>0x38fe19</td>\n",
       "      <td>[WesHoolahan, WALvIRL, COYBIG]</td>\n",
       "      <td>Where is #WesHoolahan?!  #WALvIRL #COYBIG &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867531</td>\n",
       "      <td>0x38fe1a</td>\n",
       "      <td>[not, maga]</td>\n",
       "      <td>@mattmfm Fake news! &lt;LH&gt; propagated by Tumpkin...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867532</td>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>[]</td>\n",
       "      <td>I told myself I'd be twitter famous. twitter m...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867533</td>\n",
       "      <td>0x38fe1c</td>\n",
       "      <td>[]</td>\n",
       "      <td>..today was brutal  ..#Hungover</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867534</td>\n",
       "      <td>0x38fe1d</td>\n",
       "      <td>[redheadproblems, ouch, burnt]</td>\n",
       "      <td>Love it when I sun burn my forehead!! NOT!! ðŸ˜«ðŸ˜±...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                           hashtags  \\\n",
       "0        0x1c7f0f                                                 []   \n",
       "1        0x1c7f10                                      [BlackMirror]   \n",
       "2        0x1c7f11  [twitch, Destinybeta, Destiny, Destiny2, Desti...   \n",
       "3        0x1c7f12                                                 []   \n",
       "4        0x1c7f13                                    [auspol, fizza]   \n",
       "...           ...                                                ...   \n",
       "1867530  0x38fe19                     [WesHoolahan, WALvIRL, COYBIG]   \n",
       "1867531  0x38fe1a                                        [not, maga]   \n",
       "1867532  0x38fe1b                                                 []   \n",
       "1867533  0x38fe1c                                                 []   \n",
       "1867534  0x38fe1d                     [redheadproblems, ouch, burnt]   \n",
       "\n",
       "                                                      text identification  \n",
       "0        @JZED74 While inappropriate AF, he likely wasn...           test  \n",
       "1         o m g Shut Up And Dance though #BlackMirror <LH>          train  \n",
       "2        On #twitch <LH> on the #Destinybeta #Destiny #...          train  \n",
       "3        I tried to figure out why you mean so much to ...           test  \n",
       "4        The only â€œbig planâ€ you ever had in your life,...           test  \n",
       "...                                                    ...            ...  \n",
       "1867530     Where is #WesHoolahan?!  #WALvIRL #COYBIG <LH>          train  \n",
       "1867531  @mattmfm Fake news! <LH> propagated by Tumpkin...          train  \n",
       "1867532  I told myself I'd be twitter famous. twitter m...           test  \n",
       "1867533                    ..today was brutal  ..#Hungover          train  \n",
       "1867534  Love it when I sun burn my forehead!! NOT!! ðŸ˜«ðŸ˜±...          train  \n",
       "\n",
       "[1867535 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try again, Ok it works \n",
    "#>> https://stackoverflow.com/questions/43297589/merge-two-data-frames-based-on-common-column-values-in-pandas\n",
    "totaldf = pd.merge(spdf, dfid, on='id',sort = True)\n",
    "totaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>[BlackMirror]</td>\n",
       "      <td>o m g Shut Up And Dance though #BlackMirror &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>[twitch, Destinybeta, Destiny, Destiny2, Desti...</td>\n",
       "      <td>On #twitch &lt;LH&gt; on the #Destinybeta #Destiny #...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0x1c7f14</td>\n",
       "      <td>[]</td>\n",
       "      <td>A nice sunny wak this morning not many &lt;LH&gt; ar...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0x1c7f15</td>\n",
       "      <td>[Confession, NationalCandyCornDay, CouldEatThe...</td>\n",
       "      <td>I'm one of those people who love candy corn......</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0x1c7f16</td>\n",
       "      <td>[]</td>\n",
       "      <td>@metmuseum What are these? They look like some...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867529</td>\n",
       "      <td>0x38fe18</td>\n",
       "      <td>[]</td>\n",
       "      <td>@LJPBR @FifthHarmony Um  My vote For @FifthHar...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867530</td>\n",
       "      <td>0x38fe19</td>\n",
       "      <td>[WesHoolahan, WALvIRL, COYBIG]</td>\n",
       "      <td>Where is #WesHoolahan?!  #WALvIRL #COYBIG &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867531</td>\n",
       "      <td>0x38fe1a</td>\n",
       "      <td>[not, maga]</td>\n",
       "      <td>@mattmfm Fake news! &lt;LH&gt; propagated by Tumpkin...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867533</td>\n",
       "      <td>0x38fe1c</td>\n",
       "      <td>[]</td>\n",
       "      <td>..today was brutal  ..#Hungover</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867534</td>\n",
       "      <td>0x38fe1d</td>\n",
       "      <td>[redheadproblems, ouch, burnt]</td>\n",
       "      <td>Love it when I sun burn my forehead!! NOT!! ðŸ˜«ðŸ˜±...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                           hashtags  \\\n",
       "1        0x1c7f10                                      [BlackMirror]   \n",
       "2        0x1c7f11  [twitch, Destinybeta, Destiny, Destiny2, Desti...   \n",
       "5        0x1c7f14                                                 []   \n",
       "6        0x1c7f15  [Confession, NationalCandyCornDay, CouldEatThe...   \n",
       "7        0x1c7f16                                                 []   \n",
       "...           ...                                                ...   \n",
       "1867529  0x38fe18                                                 []   \n",
       "1867530  0x38fe19                     [WesHoolahan, WALvIRL, COYBIG]   \n",
       "1867531  0x38fe1a                                        [not, maga]   \n",
       "1867533  0x38fe1c                                                 []   \n",
       "1867534  0x38fe1d                     [redheadproblems, ouch, burnt]   \n",
       "\n",
       "                                                      text identification  \n",
       "1         o m g Shut Up And Dance though #BlackMirror <LH>          train  \n",
       "2        On #twitch <LH> on the #Destinybeta #Destiny #...          train  \n",
       "5        A nice sunny wak this morning not many <LH> ar...          train  \n",
       "6        I'm one of those people who love candy corn......          train  \n",
       "7        @metmuseum What are these? They look like some...          train  \n",
       "...                                                    ...            ...  \n",
       "1867529  @LJPBR @FifthHarmony Um  My vote For @FifthHar...          train  \n",
       "1867530     Where is #WesHoolahan?!  #WALvIRL #COYBIG <LH>          train  \n",
       "1867531  @mattmfm Fake news! <LH> propagated by Tumpkin...          train  \n",
       "1867533                    ..today was brutal  ..#Hungover          train  \n",
       "1867534  Love it when I sun burn my forehead!! NOT!! ðŸ˜«ðŸ˜±...          train  \n",
       "\n",
       "[1455563 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then cut the file into 2 separate dataset by its identification\n",
    "#Cut the file for training set first\n",
    "traindf = totaldf[totaldf['identification']=='train']\n",
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1455563 entries, 1 to 1867534\n",
      "Data columns (total 4 columns):\n",
      "id                1455563 non-null object\n",
      "hashtags          1455563 non-null object\n",
      "text              1455563 non-null object\n",
      "identification    1455563 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 55.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#Then print its' basic info to see\n",
    "traindf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>[]</td>\n",
       "      <td>@JZED74 While inappropriate AF, he likely wasn...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>[]</td>\n",
       "      <td>I tried to figure out why you mean so much to ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>[auspol, fizza]</td>\n",
       "      <td>The only â€œbig planâ€ you ever had in your life,...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0x1c7f17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Looking back on situations old &amp; new, recent o...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0x1c7f18</td>\n",
       "      <td>[]</td>\n",
       "      <td>@jasoninthehouse Why do you insist on talking ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867509</td>\n",
       "      <td>0x38fe04</td>\n",
       "      <td>[traitor, treason]</td>\n",
       "      <td>\"The Grand Bargain\" The Great American Betraya...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867511</td>\n",
       "      <td>0x38fe06</td>\n",
       "      <td>[FosterCare, roadtoadoption, Adoption]</td>\n",
       "      <td>I get to be a 1 year old girl's new mama start...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867524</td>\n",
       "      <td>0x38fe13</td>\n",
       "      <td>[artworld]</td>\n",
       "      <td>Asian dude with dangly gold earrings is back &amp;...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867525</td>\n",
       "      <td>0x38fe14</td>\n",
       "      <td>[nba, cantmakeaJ]</td>\n",
       "      <td>I think @kostakoufos might be the worst player...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867532</td>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>[]</td>\n",
       "      <td>I told myself I'd be twitter famous. twitter m...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                hashtags  \\\n",
       "0        0x1c7f0f                                      []   \n",
       "3        0x1c7f12                                      []   \n",
       "4        0x1c7f13                         [auspol, fizza]   \n",
       "8        0x1c7f17                                      []   \n",
       "9        0x1c7f18                                      []   \n",
       "...           ...                                     ...   \n",
       "1867509  0x38fe04                      [traitor, treason]   \n",
       "1867511  0x38fe06  [FosterCare, roadtoadoption, Adoption]   \n",
       "1867524  0x38fe13                              [artworld]   \n",
       "1867525  0x38fe14                       [nba, cantmakeaJ]   \n",
       "1867532  0x38fe1b                                      []   \n",
       "\n",
       "                                                      text identification  \n",
       "0        @JZED74 While inappropriate AF, he likely wasn...           test  \n",
       "3        I tried to figure out why you mean so much to ...           test  \n",
       "4        The only â€œbig planâ€ you ever had in your life,...           test  \n",
       "8        Looking back on situations old & new, recent o...           test  \n",
       "9        @jasoninthehouse Why do you insist on talking ...           test  \n",
       "...                                                    ...            ...  \n",
       "1867509  \"The Grand Bargain\" The Great American Betraya...           test  \n",
       "1867511  I get to be a 1 year old girl's new mama start...           test  \n",
       "1867524  Asian dude with dangly gold earrings is back &...           test  \n",
       "1867525  I think @kostakoufos might be the worst player...           test  \n",
       "1867532  I told myself I'd be twitter famous. twitter m...           test  \n",
       "\n",
       "[411972 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then cut the file for testing dataset\n",
    "testdf = totaldf[totaldf['identification']=='test']\n",
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 411972 entries, 0 to 1867532\n",
      "Data columns (total 4 columns):\n",
      "id                411972 non-null object\n",
      "hashtags          411972 non-null object\n",
      "text              411972 non-null object\n",
      "identification    411972 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 15.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#Then print its' basic info to see\n",
    "testdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>[BlackMirror]</td>\n",
       "      <td>o m g Shut Up And Dance though #BlackMirror &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>[twitch, Destinybeta, Destiny, Destiny2, Desti...</td>\n",
       "      <td>On #twitch &lt;LH&gt; on the #Destinybeta #Destiny #...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x1c7f14</td>\n",
       "      <td>[]</td>\n",
       "      <td>A nice sunny wak this morning not many &lt;LH&gt; ar...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x1c7f15</td>\n",
       "      <td>[Confession, NationalCandyCornDay, CouldEatThe...</td>\n",
       "      <td>I'm one of those people who love candy corn......</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x1c7f16</td>\n",
       "      <td>[]</td>\n",
       "      <td>@metmuseum What are these? They look like some...</td>\n",
       "      <td>train</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455558</td>\n",
       "      <td>0x38fe18</td>\n",
       "      <td>[]</td>\n",
       "      <td>@LJPBR @FifthHarmony Um  My vote For @FifthHar...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455559</td>\n",
       "      <td>0x38fe19</td>\n",
       "      <td>[WesHoolahan, WALvIRL, COYBIG]</td>\n",
       "      <td>Where is #WesHoolahan?!  #WALvIRL #COYBIG &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455560</td>\n",
       "      <td>0x38fe1a</td>\n",
       "      <td>[not, maga]</td>\n",
       "      <td>@mattmfm Fake news! &lt;LH&gt; propagated by Tumpkin...</td>\n",
       "      <td>train</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455561</td>\n",
       "      <td>0x38fe1c</td>\n",
       "      <td>[]</td>\n",
       "      <td>..today was brutal  ..#Hungover</td>\n",
       "      <td>train</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455562</td>\n",
       "      <td>0x38fe1d</td>\n",
       "      <td>[redheadproblems, ouch, burnt]</td>\n",
       "      <td>Love it when I sun burn my forehead!! NOT!! ðŸ˜«ðŸ˜±...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                           hashtags  \\\n",
       "0        0x1c7f10                                      [BlackMirror]   \n",
       "1        0x1c7f11  [twitch, Destinybeta, Destiny, Destiny2, Desti...   \n",
       "2        0x1c7f14                                                 []   \n",
       "3        0x1c7f15  [Confession, NationalCandyCornDay, CouldEatThe...   \n",
       "4        0x1c7f16                                                 []   \n",
       "...           ...                                                ...   \n",
       "1455558  0x38fe18                                                 []   \n",
       "1455559  0x38fe19                     [WesHoolahan, WALvIRL, COYBIG]   \n",
       "1455560  0x38fe1a                                        [not, maga]   \n",
       "1455561  0x38fe1c                                                 []   \n",
       "1455562  0x38fe1d                     [redheadproblems, ouch, burnt]   \n",
       "\n",
       "                                                      text identification  \\\n",
       "0         o m g Shut Up And Dance though #BlackMirror <LH>          train   \n",
       "1        On #twitch <LH> on the #Destinybeta #Destiny #...          train   \n",
       "2        A nice sunny wak this morning not many <LH> ar...          train   \n",
       "3        I'm one of those people who love candy corn......          train   \n",
       "4        @metmuseum What are these? They look like some...          train   \n",
       "...                                                    ...            ...   \n",
       "1455558  @LJPBR @FifthHarmony Um  My vote For @FifthHar...          train   \n",
       "1455559     Where is #WesHoolahan?!  #WALvIRL #COYBIG <LH>          train   \n",
       "1455560  @mattmfm Fake news! <LH> propagated by Tumpkin...          train   \n",
       "1455561                    ..today was brutal  ..#Hungover          train   \n",
       "1455562  Love it when I sun burn my forehead!! NOT!! ðŸ˜«ðŸ˜±...          train   \n",
       "\n",
       "              emotion  \n",
       "0                 joy  \n",
       "1        anticipation  \n",
       "2                 joy  \n",
       "3                 joy  \n",
       "4             disgust  \n",
       "...               ...  \n",
       "1455558       sadness  \n",
       "1455559  anticipation  \n",
       "1455560      surprise  \n",
       "1455561       disgust  \n",
       "1455562       sadness  \n",
       "\n",
       "[1455563 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then we can see that the number of row for the training data and the emotion (the result of prediction) is the same\n",
    "#Then we combine those two file together\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html\n",
    "traindf = pd.merge(traindf, emotion,on = None,sort = True)\n",
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'hashtags', 'text', 'identification', 'emotion'], dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum column hastags and text together for better train data\n",
    "traindf_=traindf[['hashtags', 'text']].astype(str).apply('-'.join, axis=1)\n",
    "#traindf['combined'] = traindf[['hashtags', 'text']].apply(lambda x: ''.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum column hastags and text together for better train data\n",
    "testdf_=testdf[['hashtags', 'text']].astype(str).apply('-'.join, axis=1)\n",
    "#testdf['combined'] = testdf[['hashtags', 'text']].apply(lambda x: ''.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>[BlackMirror]</td>\n",
       "      <td>o m g Shut Up And Dance though #BlackMirror &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>[twitch, Destinybeta, Destiny, Destiny2, Desti...</td>\n",
       "      <td>On #twitch &lt;LH&gt; on the #Destinybeta #Destiny #...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x1c7f14</td>\n",
       "      <td>[]</td>\n",
       "      <td>A nice sunny wak this morning not many &lt;LH&gt; ar...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x1c7f15</td>\n",
       "      <td>[Confession, NationalCandyCornDay, CouldEatThe...</td>\n",
       "      <td>I'm one of those people who love candy corn......</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x1c7f16</td>\n",
       "      <td>[]</td>\n",
       "      <td>@metmuseum What are these? They look like some...</td>\n",
       "      <td>train</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455558</td>\n",
       "      <td>0x38fe18</td>\n",
       "      <td>[]</td>\n",
       "      <td>@LJPBR @FifthHarmony Um  My vote For @FifthHar...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455559</td>\n",
       "      <td>0x38fe19</td>\n",
       "      <td>[WesHoolahan, WALvIRL, COYBIG]</td>\n",
       "      <td>Where is #WesHoolahan?!  #WALvIRL #COYBIG &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455560</td>\n",
       "      <td>0x38fe1a</td>\n",
       "      <td>[not, maga]</td>\n",
       "      <td>@mattmfm Fake news! &lt;LH&gt; propagated by Tumpkin...</td>\n",
       "      <td>train</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455561</td>\n",
       "      <td>0x38fe1c</td>\n",
       "      <td>[]</td>\n",
       "      <td>..today was brutal  ..#Hungover</td>\n",
       "      <td>train</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455562</td>\n",
       "      <td>0x38fe1d</td>\n",
       "      <td>[redheadproblems, ouch, burnt]</td>\n",
       "      <td>Love it when I sun burn my forehead!! NOT!! ðŸ˜«ðŸ˜±...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                           hashtags  \\\n",
       "0        0x1c7f10                                      [BlackMirror]   \n",
       "1        0x1c7f11  [twitch, Destinybeta, Destiny, Destiny2, Desti...   \n",
       "2        0x1c7f14                                                 []   \n",
       "3        0x1c7f15  [Confession, NationalCandyCornDay, CouldEatThe...   \n",
       "4        0x1c7f16                                                 []   \n",
       "...           ...                                                ...   \n",
       "1455558  0x38fe18                                                 []   \n",
       "1455559  0x38fe19                     [WesHoolahan, WALvIRL, COYBIG]   \n",
       "1455560  0x38fe1a                                        [not, maga]   \n",
       "1455561  0x38fe1c                                                 []   \n",
       "1455562  0x38fe1d                     [redheadproblems, ouch, burnt]   \n",
       "\n",
       "                                                      text identification  \\\n",
       "0         o m g Shut Up And Dance though #BlackMirror <LH>          train   \n",
       "1        On #twitch <LH> on the #Destinybeta #Destiny #...          train   \n",
       "2        A nice sunny wak this morning not many <LH> ar...          train   \n",
       "3        I'm one of those people who love candy corn......          train   \n",
       "4        @metmuseum What are these? They look like some...          train   \n",
       "...                                                    ...            ...   \n",
       "1455558  @LJPBR @FifthHarmony Um  My vote For @FifthHar...          train   \n",
       "1455559     Where is #WesHoolahan?!  #WALvIRL #COYBIG <LH>          train   \n",
       "1455560  @mattmfm Fake news! <LH> propagated by Tumpkin...          train   \n",
       "1455561                    ..today was brutal  ..#Hungover          train   \n",
       "1455562  Love it when I sun burn my forehead!! NOT!! ðŸ˜«ðŸ˜±...          train   \n",
       "\n",
       "              emotion  \n",
       "0                 joy  \n",
       "1        anticipation  \n",
       "2                 joy  \n",
       "3                 joy  \n",
       "4             disgust  \n",
       "...               ...  \n",
       "1455558       sadness  \n",
       "1455559  anticipation  \n",
       "1455560      surprise  \n",
       "1455561       disgust  \n",
       "1455562       sadness  \n",
       "\n",
       "[1455563 rows x 5 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>[]</td>\n",
       "      <td>@JZED74 While inappropriate AF, he likely wasn...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>[]</td>\n",
       "      <td>I tried to figure out why you mean so much to ...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>[auspol, fizza]</td>\n",
       "      <td>The only â€œbig planâ€ you ever had in your life,...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0x1c7f17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Looking back on situations old &amp; new, recent o...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0x1c7f18</td>\n",
       "      <td>[]</td>\n",
       "      <td>@jasoninthehouse Why do you insist on talking ...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867509</td>\n",
       "      <td>0x38fe04</td>\n",
       "      <td>[traitor, treason]</td>\n",
       "      <td>\"The Grand Bargain\" The Great American Betraya...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867511</td>\n",
       "      <td>0x38fe06</td>\n",
       "      <td>[FosterCare, roadtoadoption, Adoption]</td>\n",
       "      <td>I get to be a 1 year old girl's new mama start...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867524</td>\n",
       "      <td>0x38fe13</td>\n",
       "      <td>[artworld]</td>\n",
       "      <td>Asian dude with dangly gold earrings is back &amp;...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867525</td>\n",
       "      <td>0x38fe14</td>\n",
       "      <td>[nba, cantmakeaJ]</td>\n",
       "      <td>I think @kostakoufos might be the worst player...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867532</td>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>[]</td>\n",
       "      <td>I told myself I'd be twitter famous. twitter m...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                hashtags  \\\n",
       "0        0x1c7f0f                                      []   \n",
       "3        0x1c7f12                                      []   \n",
       "4        0x1c7f13                         [auspol, fizza]   \n",
       "8        0x1c7f17                                      []   \n",
       "9        0x1c7f18                                      []   \n",
       "...           ...                                     ...   \n",
       "1867509  0x38fe04                      [traitor, treason]   \n",
       "1867511  0x38fe06  [FosterCare, roadtoadoption, Adoption]   \n",
       "1867524  0x38fe13                              [artworld]   \n",
       "1867525  0x38fe14                       [nba, cantmakeaJ]   \n",
       "1867532  0x38fe1b                                      []   \n",
       "\n",
       "                                                      text identification  \\\n",
       "0        @JZED74 While inappropriate AF, he likely wasn...           test   \n",
       "3        I tried to figure out why you mean so much to ...           test   \n",
       "4        The only â€œbig planâ€ you ever had in your life,...           test   \n",
       "8        Looking back on situations old & new, recent o...           test   \n",
       "9        @jasoninthehouse Why do you insist on talking ...           test   \n",
       "...                                                    ...            ...   \n",
       "1867509  \"The Grand Bargain\" The Great American Betraya...           test   \n",
       "1867511  I get to be a 1 year old girl's new mama start...           test   \n",
       "1867524  Asian dude with dangly gold earrings is back &...           test   \n",
       "1867525  I think @kostakoufos might be the worst player...           test   \n",
       "1867532  I told myself I'd be twitter famous. twitter m...           test   \n",
       "\n",
       "        emotion  \n",
       "0                \n",
       "3                \n",
       "4                \n",
       "8                \n",
       "9                \n",
       "...         ...  \n",
       "1867509          \n",
       "1867511          \n",
       "1867524          \n",
       "1867525          \n",
       "1867532          \n",
       "\n",
       "[411972 rows x 5 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We got the dataframe ready to use for the next stage\n",
    "#the total dataframe is  >> totaldf\n",
    "#the training dataset is >> traindf\n",
    "#the testing dataset is  >> testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                (The amoung of missing records is: , 0)\n",
       "hashtags          (The amoung of missing records is: , 0)\n",
       "text              (The amoung of missing records is: , 0)\n",
       "identification    (The amoung of missing records is: , 0)\n",
       "emotion           (The amoung of missing records is: , 0)\n",
       "dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for the missing value and duplicate data\n",
    "traindf.isnull().apply(lambda x: dmh.check_missing_values(traindf))\n",
    "\n",
    "#There is no missing data in the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tokenize the 'text'\n",
    "#traindf['unigrams'] = traindf['text'].apply(lambda x: dmh.tokenize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1          [o, m, g, Shut, Up, And, Dance, though, #, Bla...\n",
       "2          [On, #, twitch, <, LH, >, on, the, #, Destinyb...\n",
       "5          [A, nice, sunny, wak, this, morning, not, many...\n",
       "6          [I, 'm, one, of, those, people, who, love, can...\n",
       "7          [@, metmuseum, What, are, these, ?, They, look...\n",
       "                                 ...                        \n",
       "1867529    [@, LJPBR, @, FifthHarmony, Um, My, vote, For,...\n",
       "1867530    [Where, is, #, WesHoolahan, ?, !, #, WALvIRL, ...\n",
       "1867531    [@, mattmfm, Fake, news, !, <, LH, >, propagat...\n",
       "1867533              [..today, was, brutal, .., #, Hungover]\n",
       "1867534    [Love, it, when, I, sun, burn, my, forehead, !...\n",
       "Name: unigrams, Length: 1455563, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#traindf['unigrams']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# build analyzers (bag-of-words)\n",
    "BOW_vectorizer = CountVectorizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Learn a vocabulary dictionary of all tokens in the raw documents.\n",
    "BOW_vectorizer.fit(traindf['text'])\n",
    "\n",
    "# 2. Transform documents to document-term matrix.\n",
    "train_data_BOW_features = BOW_vectorizer.transform(traindf['text'])\n",
    "test_data_BOW_features = BOW_vectorizer.transform(testdf['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1455563x794247 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 18849355 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result\n",
    "train_data_BOW_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data_BOW_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455563, 794247)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the dimension\n",
    "train_data_BOW_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['005',\n",
       " '00533321',\n",
       " '00575',\n",
       " '00578',\n",
       " '005796',\n",
       " '005e5n',\n",
       " '006',\n",
       " '0060',\n",
       " '007',\n",
       " '00786mujahid']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe some feature names\n",
    "feature_names = BOW_vectorizer.get_feature_names()\n",
    "feature_names[100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X_train = BOW_500.transform(traindf['text'])\n",
    "y_train = traindf['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = BOW_500.transform(testdf['text'])\n",
    "y_test = testdf['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (1455563, 500)\n",
      "y_train.shape:  (1455563,)\n",
      "X_test.shape:  (411972, 500)\n",
      "y_test.shape:  (411972,)\n"
     ]
    }
   ],
   "source": [
    "## take a look at data dimension is a good habbit  :)\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build DecisionTree model\n",
    "DT_model = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training!\n",
    "DT_model = DT_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict!\n",
    "y_train_pred = DT_model.predict(X_train)\n",
    "y_test_pred = DT_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'disgust', 'trust', 'joy', 'surprise', 'joy', 'sadness',\n",
       "       'joy', 'anticipation', 'trust'], dtype=object)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## so we get the pred result\n",
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.97\n",
      "testing accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "## accuracy testing on decision tree model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "acc_test = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train, 2)))\n",
    "print('testing accuracy: {}'.format(round(acc_test, 2)))\n",
    "\n",
    "#at first I will submit the result, but after checking it, i will let it go~\n",
    "#it is cleary that the model is overfitting.\n",
    "#I know that there is the problem before trying the model but I just want to see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'disgust', 'trust', 'joy', 'surprise', 'joy', 'sadness',\n",
       "       'joy', 'anticipation', 'trust'], dtype=object)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred2 = DT_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'disgust', 'trust', 'joy', 'surprise', 'joy', 'sadness',\n",
       "       'joy', 'anticipation', 'trust'], dtype=object)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred2[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = testdf.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listOfTuples(test_id, y_test_pred2): \n",
    "    return list(map(lambda x, y:(x,y), test_id, y_test_pred2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalresult = (listOfTuples(test_id, y_test_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0x1c7f0f', 'sadness')]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalresult[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfresult = pd.DataFrame(finalresult) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x1c7f17</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x1c7f18</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411967</td>\n",
       "      <td>0x38fe04</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411968</td>\n",
       "      <td>0x38fe06</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411969</td>\n",
       "      <td>0x38fe13</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411970</td>\n",
       "      <td>0x38fe14</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411971</td>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1\n",
       "0       0x1c7f0f   sadness\n",
       "1       0x1c7f12   disgust\n",
       "2       0x1c7f13     trust\n",
       "3       0x1c7f17       joy\n",
       "4       0x1c7f18  surprise\n",
       "...          ...       ...\n",
       "411967  0x38fe04   sadness\n",
       "411968  0x38fe06     trust\n",
       "411969  0x38fe13       joy\n",
       "411970  0x38fe14     trust\n",
       "411971  0x38fe1b       joy\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign header names\n",
    "dfresult.columns = ['id','emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x1c7f17</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x1c7f18</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411967</td>\n",
       "      <td>0x38fe04</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411968</td>\n",
       "      <td>0x38fe06</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411969</td>\n",
       "      <td>0x38fe13</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411970</td>\n",
       "      <td>0x38fe14</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411971</td>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id   emotion\n",
       "0       0x1c7f0f   sadness\n",
       "1       0x1c7f12   disgust\n",
       "2       0x1c7f13     trust\n",
       "3       0x1c7f17       joy\n",
       "4       0x1c7f18  surprise\n",
       "...          ...       ...\n",
       "411967  0x38fe04   sadness\n",
       "411968  0x38fe06     trust\n",
       "411969  0x38fe13       joy\n",
       "411970  0x38fe14     trust\n",
       "411971  0x38fe1b       joy\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id   emotion\n",
      "0       0x1c7f0f   sadness\n",
      "1       0x1c7f12   disgust\n",
      "2       0x1c7f13     trust\n",
      "3       0x1c7f17       joy\n",
      "4       0x1c7f18  surprise\n",
      "...          ...       ...\n",
      "411967  0x38fe04   sadness\n",
      "411968  0x38fe06     trust\n",
      "411969  0x38fe13       joy\n",
      "411970  0x38fe14     trust\n",
      "411971  0x38fe1b       joy\n",
      "\n",
      "[411972 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#save the file to csv format\n",
    "exportcsv = dfresult.to_csv (r'C:\\Users\\User\\Data Mining_NTHU\\DMlab2x\\DM19-Lab2-Homework\\Dataset_Twitter_re.csv', index = None, header=True) \n",
    "\n",
    "print (dfresult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vector for train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the vectorizer for the training and testing set\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "trainvec = vectorizer.fit_transform(traindf.text)\n",
    "testvec = vectorizer.fit_transform(testdf.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1455563x794247 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 18849355 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<411972x283626 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6456093 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testdf['emotion'] = df.apply(lambda _: '', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>[]</td>\n",
       "      <td>@JZED74 While inappropriate AF, he likely wasn...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>[]</td>\n",
       "      <td>I tried to figure out why you mean so much to ...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>[auspol, fizza]</td>\n",
       "      <td>The only â€œbig planâ€ you ever had in your life,...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0x1c7f17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Looking back on situations old &amp; new, recent o...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0x1c7f18</td>\n",
       "      <td>[]</td>\n",
       "      <td>@jasoninthehouse Why do you insist on talking ...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867509</td>\n",
       "      <td>0x38fe04</td>\n",
       "      <td>[traitor, treason]</td>\n",
       "      <td>\"The Grand Bargain\" The Great American Betraya...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867511</td>\n",
       "      <td>0x38fe06</td>\n",
       "      <td>[FosterCare, roadtoadoption, Adoption]</td>\n",
       "      <td>I get to be a 1 year old girl's new mama start...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867524</td>\n",
       "      <td>0x38fe13</td>\n",
       "      <td>[artworld]</td>\n",
       "      <td>Asian dude with dangly gold earrings is back &amp;...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867525</td>\n",
       "      <td>0x38fe14</td>\n",
       "      <td>[nba, cantmakeaJ]</td>\n",
       "      <td>I think @kostakoufos might be the worst player...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867532</td>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>[]</td>\n",
       "      <td>I told myself I'd be twitter famous. twitter m...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                hashtags  \\\n",
       "0        0x1c7f0f                                      []   \n",
       "3        0x1c7f12                                      []   \n",
       "4        0x1c7f13                         [auspol, fizza]   \n",
       "8        0x1c7f17                                      []   \n",
       "9        0x1c7f18                                      []   \n",
       "...           ...                                     ...   \n",
       "1867509  0x38fe04                      [traitor, treason]   \n",
       "1867511  0x38fe06  [FosterCare, roadtoadoption, Adoption]   \n",
       "1867524  0x38fe13                              [artworld]   \n",
       "1867525  0x38fe14                       [nba, cantmakeaJ]   \n",
       "1867532  0x38fe1b                                      []   \n",
       "\n",
       "                                                      text identification  \\\n",
       "0        @JZED74 While inappropriate AF, he likely wasn...           test   \n",
       "3        I tried to figure out why you mean so much to ...           test   \n",
       "4        The only â€œbig planâ€ you ever had in your life,...           test   \n",
       "8        Looking back on situations old & new, recent o...           test   \n",
       "9        @jasoninthehouse Why do you insist on talking ...           test   \n",
       "...                                                    ...            ...   \n",
       "1867509  \"The Grand Bargain\" The Great American Betraya...           test   \n",
       "1867511  I get to be a 1 year old girl's new mama start...           test   \n",
       "1867524  Asian dude with dangly gold earrings is back &...           test   \n",
       "1867525  I think @kostakoufos might be the worst player...           test   \n",
       "1867532  I told myself I'd be twitter famous. twitter m...           test   \n",
       "\n",
       "        emotion  \n",
       "0                \n",
       "3                \n",
       "4                \n",
       "8                \n",
       "9                \n",
       "...         ...  \n",
       "1867509          \n",
       "1867511          \n",
       "1867524          \n",
       "1867525          \n",
       "1867532          \n",
       "\n",
       "[411972 rows x 5 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset into training and testing dataset \n",
    "#random_state=1 for reproducibility\n",
    "\n",
    "\n",
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X_train = trainvec\n",
    "y_train = traindf['emotion']\n",
    "\n",
    "X_test = testvec\n",
    "y_test = testdf['emotion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MulNB = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1455563, 500)\n",
      "(411972, 500)\n",
      "(1455563,)\n",
      "(411972,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MulNB = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "MulNB.fit(X_train, y_train)\n",
    "MulNB.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1455563, 794247)\n",
      "(411972, 283626)\n",
      "(1455563,)\n",
      "(411972,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input with 794247 features, got 283626 instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-52385221f599>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBernoulliNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinarize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    355\u001b[0m         \"\"\"\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \"\"\"\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features_X\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m             raise ValueError(\"Expected input with %d features, got %d instead\"\n\u001b[1;32m--> 953\u001b[1;33m                              % (n_features, n_features_X))\n\u001b[0m\u001b[0;32m    954\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m         \u001b[0mneg_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_log_prob_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input with 794247 features, got 283626 instead"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB(binarize=0.0)\n",
    "bnb.fit(X_train, y_train)\n",
    "bnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model with the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'sadness', 'anticipation', 'anticipation', 'disgust',\n",
       "       'joy', 'sadness', 'joy', 'anticipation', 'sadness'], dtype='<U12')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build the model\n",
    "MNBmodel = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "\n",
    "#Train the data\n",
    "MNBmodel = MNBmodel.fit(X_train, y_train)\n",
    "\n",
    "#Predict the result\n",
    "Xtrain1 = MNBmodel.predict(X_train)\n",
    "Xtest1 = MNBmodel.predict(X_test)\n",
    "\n",
    "## then we get the pred result\n",
    "Xtest1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the result by using testing dataset\n",
    "Xtesttest = MNBmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Predict the result by using the test dataset\n",
    "Testontest = MNBmodel.predict(testvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input with 794247 features, got 283626 instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-440b84e77756>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#Predict the result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mXtrain2\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mbnbmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mXtest2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbnbmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m## then we get the pred result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \"\"\"\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features_X\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m             raise ValueError(\"Expected input with %d features, got %d instead\"\n\u001b[1;32m--> 953\u001b[1;33m                              % (n_features, n_features_X))\n\u001b[0m\u001b[0;32m    954\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m         \u001b[0mneg_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_log_prob_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input with 794247 features, got 283626 instead"
     ]
    }
   ],
   "source": [
    "#Renew testing the model again\n",
    "#Then test the result\n",
    "bnbmodel = BernoulliNB(binarize=0.0)\n",
    "\n",
    "#Train the data\n",
    "bnbmodel = bnbmodel.fit(X_train, y_train)\n",
    "\n",
    "#Predict the result\n",
    "Xtrain2  = bnbmodel.predict(X_train)\n",
    "Xtest2 = bnbmodel.predict(X_test)\n",
    "\n",
    "## then we get the pred result\n",
    "Xtest2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the result by using the test dataset\n",
    "bnbmodel = bnbmodel.predict(testvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vector for train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the vectorizer for the training and testing set\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "trainvec = vectorizer.fit_transform(traindf.text)\n",
    "testvec = vectorizer.fit_transform(testdf.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1455563x794247 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 18849355 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<411972x283626 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6456093 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testdf['emotion'] = df.apply(lambda _: '', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>[]</td>\n",
       "      <td>@JZED74 While inappropriate AF, he likely wasn...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>[]</td>\n",
       "      <td>I tried to figure out why you mean so much to ...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>[auspol, fizza]</td>\n",
       "      <td>The only â€œbig planâ€ you ever had in your life,...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0x1c7f17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Looking back on situations old &amp; new, recent o...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0x1c7f18</td>\n",
       "      <td>[]</td>\n",
       "      <td>@jasoninthehouse Why do you insist on talking ...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867509</td>\n",
       "      <td>0x38fe04</td>\n",
       "      <td>[traitor, treason]</td>\n",
       "      <td>\"The Grand Bargain\" The Great American Betraya...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867511</td>\n",
       "      <td>0x38fe06</td>\n",
       "      <td>[FosterCare, roadtoadoption, Adoption]</td>\n",
       "      <td>I get to be a 1 year old girl's new mama start...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867524</td>\n",
       "      <td>0x38fe13</td>\n",
       "      <td>[artworld]</td>\n",
       "      <td>Asian dude with dangly gold earrings is back &amp;...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867525</td>\n",
       "      <td>0x38fe14</td>\n",
       "      <td>[nba, cantmakeaJ]</td>\n",
       "      <td>I think @kostakoufos might be the worst player...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867532</td>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>[]</td>\n",
       "      <td>I told myself I'd be twitter famous. twitter m...</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                hashtags  \\\n",
       "0        0x1c7f0f                                      []   \n",
       "3        0x1c7f12                                      []   \n",
       "4        0x1c7f13                         [auspol, fizza]   \n",
       "8        0x1c7f17                                      []   \n",
       "9        0x1c7f18                                      []   \n",
       "...           ...                                     ...   \n",
       "1867509  0x38fe04                      [traitor, treason]   \n",
       "1867511  0x38fe06  [FosterCare, roadtoadoption, Adoption]   \n",
       "1867524  0x38fe13                              [artworld]   \n",
       "1867525  0x38fe14                       [nba, cantmakeaJ]   \n",
       "1867532  0x38fe1b                                      []   \n",
       "\n",
       "                                                      text identification  \\\n",
       "0        @JZED74 While inappropriate AF, he likely wasn...           test   \n",
       "3        I tried to figure out why you mean so much to ...           test   \n",
       "4        The only â€œbig planâ€ you ever had in your life,...           test   \n",
       "8        Looking back on situations old & new, recent o...           test   \n",
       "9        @jasoninthehouse Why do you insist on talking ...           test   \n",
       "...                                                    ...            ...   \n",
       "1867509  \"The Grand Bargain\" The Great American Betraya...           test   \n",
       "1867511  I get to be a 1 year old girl's new mama start...           test   \n",
       "1867524  Asian dude with dangly gold earrings is back &...           test   \n",
       "1867525  I think @kostakoufos might be the worst player...           test   \n",
       "1867532  I told myself I'd be twitter famous. twitter m...           test   \n",
       "\n",
       "        emotion  \n",
       "0                \n",
       "3                \n",
       "4                \n",
       "8                \n",
       "9                \n",
       "...         ...  \n",
       "1867509          \n",
       "1867511          \n",
       "1867524          \n",
       "1867525          \n",
       "1867532          \n",
       "\n",
       "[411972 rows x 5 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset into training and testing dataset \n",
    "#random_state=1 for reproducibility\n",
    "\n",
    "\n",
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X_train = trainvec\n",
    "y_train = traindf['emotion']\n",
    "\n",
    "X_test = testvec\n",
    "y_test = testdf['emotion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MulNB = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1455563, 500)\n",
      "(411972, 500)\n",
      "(1455563,)\n",
      "(411972,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MulNB = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "MulNB.fit(X_train, y_train)\n",
    "MulNB.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1455563, 794247)\n",
      "(411972, 283626)\n",
      "(1455563,)\n",
      "(411972,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input with 794247 features, got 283626 instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-52385221f599>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBernoulliNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinarize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    355\u001b[0m         \"\"\"\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \"\"\"\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features_X\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m             raise ValueError(\"Expected input with %d features, got %d instead\"\n\u001b[1;32m--> 953\u001b[1;33m                              % (n_features, n_features_X))\n\u001b[0m\u001b[0;32m    954\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m         \u001b[0mneg_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_log_prob_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input with 794247 features, got 283626 instead"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB(binarize=0.0)\n",
    "bnb.fit(X_train, y_train)\n",
    "bnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model with the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-4b73073e61e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#Predict the result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mXtrain1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMNBmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mXtest1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMNBmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m## then we get the pred result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \"\"\"\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m         return (safe_sparse_dot(X, self.feature_log_prob_.T) +\n\u001b[0m\u001b[0;32m    738\u001b[0m                 self.class_log_prior_)\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \"\"\"\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"toarray\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: dimension mismatch"
     ]
    }
   ],
   "source": [
    "#Build the model\n",
    "MNBmodel = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "\n",
    "#Train the data\n",
    "MNBmodel = MNBmodel.fit(X_train, y_train)\n",
    "\n",
    "#Predict the result\n",
    "Xtrain1 = MNBmodel.predict(X_train)\n",
    "Xtest1 = MNBmodel.predict(X_test)\n",
    "\n",
    "## then we get the pred result\n",
    "Xtest1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-df0a9fcbd8b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Predict the result by using testing dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mXtesttest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMNBmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \"\"\"\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m         return (safe_sparse_dot(X, self.feature_log_prob_.T) +\n\u001b[0m\u001b[0;32m    738\u001b[0m                 self.class_log_prior_)\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \"\"\"\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"toarray\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: dimension mismatch"
     ]
    }
   ],
   "source": [
    "#Predict the result by using testing dataset\n",
    "Xtesttest = MNBmodel.predict(testvec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Predict the result by using the test dataset\n",
    "Testontest = MNBmodel.predict(testvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input with 794247 features, got 283626 instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-440b84e77756>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#Predict the result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mXtrain2\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mbnbmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mXtest2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbnbmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m## then we get the pred result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \"\"\"\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features_X\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m             raise ValueError(\"Expected input with %d features, got %d instead\"\n\u001b[1;32m--> 953\u001b[1;33m                              % (n_features, n_features_X))\n\u001b[0m\u001b[0;32m    954\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m         \u001b[0mneg_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_log_prob_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input with 794247 features, got 283626 instead"
     ]
    }
   ],
   "source": [
    "#Renew testing the model again\n",
    "#Then test the result\n",
    "bnbmodel = BernoulliNB(binarize=0.0)\n",
    "\n",
    "#Train the data\n",
    "bnbmodel = bnbmodel.fit(X_train, y_train)\n",
    "\n",
    "#Predict the result\n",
    "Xtrain2  = bnbmodel.predict(X_train)\n",
    "Xtest2 = bnbmodel.predict(X_test)\n",
    "\n",
    "## then we get the pred result\n",
    "Xtest2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the result by using the test dataset\n",
    "bnbmodel = bnbmodel.predict(testvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
