{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LbGWrwyd2Drw"
   },
   "source": [
    "<div style='background: #e1ff00'> <h1>Student Information</h1>  \n",
    "    \n",
    "Name: Miss Pattamon Rattanapan\n",
    "\n",
    "Student ID: 108065436\n",
    "\n",
    "GitHub ID: https://github.com/mon826\n",
    "\n",
    "Kaggle name:Username : mon826 (display name TheRicky, account ID 2514034)\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "[Snapshot](img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5nx8GBXgTo6V"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "PbEbut6JtYCc",
    "outputId": "cdeccd4e-6349-4e4b-abc8-c12c055a8077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import os\n",
    "import math\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "print(tf.__version__)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import helpers.data_mining_helpers as dmh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import prepared dataset\n",
    "\n",
    "traindf = pd.read_csv('traindf.csv')\n",
    "\n",
    "testdf = pd.read_csv('testdf.csv')\n",
    "testdf['emotion'] = testdf.apply(lambda _: '', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ygzHAY6aqUME"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "\"\"\"\n",
    "Helper functions for data mining lab session 2018 Fall Semester\n",
    "Author: Elvis Saravia\n",
    "Email: ellfae@gmail.com\n",
    "\"\"\"\n",
    "\n",
    "def format_rows(docs):\n",
    "    \"\"\" format the text field and strip special characters \"\"\"\n",
    "    D = []\n",
    "    for d in docs.data:\n",
    "        temp_d = \" \".join(d.split(\"\\n\")).strip('\\n\\t')\n",
    "        D.append([temp_d])\n",
    "    return D\n",
    "\n",
    "def format_labels(target, docs):\n",
    "    \"\"\" format the labels \"\"\"\n",
    "    return docs.target_names[target]\n",
    "\n",
    "def check_missing_values(row):\n",
    "    \"\"\" functions that check and verifies if there are missing values in dataframe \"\"\"\n",
    "    counter = 0\n",
    "    for element in row:\n",
    "        if element == True:\n",
    "            counter+=1\n",
    "    return (\"The amoung of missing records is: \", counter)\n",
    "\n",
    "def tokenize_text(text, remove_stopwords=False):\n",
    "    \"\"\"\n",
    "    Tokenize text using the nltk library\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    for d in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(d, language='english'):\n",
    "            # filters here\n",
    "            tokens.append(word)\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "niRH7jFmt3qp"
   },
   "outputs": [],
   "source": [
    "#Print the import data to see how it looks like\n",
    "'''data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bqeLcnypwTyN"
   },
   "outputs": [],
   "source": [
    "#Then print out the data as list to see\n",
    "'''\n",
    "data[1]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g5I17SCtzszj"
   },
   "outputs": [],
   "source": [
    "#  Put it in pandas dataframe\n",
    "#pass the data into panda dataframe\n",
    "'''\n",
    "ddata = pd.DataFrame(data)\n",
    "ddata\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E3WwBkdJzs-T"
   },
   "outputs": [],
   "source": [
    "#Then add the new column to the dataframe by bringing the data from its' list\n",
    "'''\n",
    "ddata['id'] = ddata['_source'].apply(lambda x: x['tweet']['tweet_id'])\n",
    "ddata['hashtag'] = ddata['_source'].apply(lambda x: x['tweet']['hashtags'])\n",
    "ddata['text'] = ddata['_source'].apply(lambda x: x['tweet']['text'])\n",
    "ddata\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lA1sOqJyztGO"
   },
   "outputs": [],
   "source": [
    "#  Split the column and rearrange\n",
    "#Split the colum _crawldate to two separate columns which are date and time\n",
    "'''\n",
    "ddata[['date','time']] = ddata._crawldate.str.split(' ',expand=True)\n",
    "\n",
    "#Then we print to see how the data look like\n",
    "ddata\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NsOlAY2kztPG"
   },
   "outputs": [],
   "source": [
    "#delete the column\n",
    "'''\n",
    "ddata.drop(columns = '_index',inplace = True)\n",
    "ddata.drop(columns = '_source',inplace = True)\n",
    "ddata.drop(columns = '_type',inplace = True)\n",
    "ddata\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MmYKbb2NztaK"
   },
   "outputs": [],
   "source": [
    "#Rename the column to be easier to read and print the data to see \n",
    "#but the date and time is stored under the same column and the source is starting with {'tweet'{hastags'\n",
    "'''\n",
    "ddata.rename(columns={'_crawldate':'date&time'}, inplace = True)\n",
    "ddata.rename(columns={'_score':'score'}, inplace = True)\n",
    "ddata\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AuJPjUdgztq6"
   },
   "outputs": [],
   "source": [
    "#Rearrange the columns and print it to see how it looks like\n",
    "'''\n",
    "ddata = ddata[['id','score','hashtag','text','date&time','date','time']]\n",
    "\n",
    "#Finally get the data which is ready to use \n",
    "ddata\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cphNckCDz8Bw"
   },
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1C5ZkxZPztoZ"
   },
   "outputs": [],
   "source": [
    "#Import the file data identification by using pandas\n",
    "'''\n",
    "col_Names2=[\"id\", \"identification\"]\n",
    "dfid = pd.read_csv(r'C:\\Users\\User\\Data Mining_NTHU\\DMlab2x\\DM19-Lab2-Homework\\Data for Lab2_HW\\data_identification.csv',\n",
    "                      names =col_Names2, header =0)\n",
    "dfid\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2g8iYDYnztlP"
   },
   "outputs": [],
   "source": [
    "#Import the file emotion by using pandas\n",
    "'''\n",
    "col_Names=[\"id\", \"emotion\"]\n",
    "emotion = pd.read_csv(r'C:\\Users\\User\\Data Mining_NTHU\\DMlab2x\\DM19-Lab2-Homework\\Data for Lab2_HW\\emotion.csv', header = 0, names =col_Names)\n",
    "emotion\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XEsTZV2cztjm"
   },
   "outputs": [],
   "source": [
    "#Merge the ddate and emotion dataframe together \n",
    "#>>https://stackoverflow.com/questions/21435176/appending-two-dataframes-with-same-columns-different-order\n",
    "#But it's wrong it's vertically merged\n",
    "'''\n",
    "totaldf = pd.concat([ddata, dfid], ignore_index=True, sort=True)\n",
    "totaldf\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MBu2oIm6ztgE"
   },
   "outputs": [],
   "source": [
    "#Try again, Ok it works \n",
    "#>> https://stackoverflow.com/questions/43297589/merge-two-data-frames-based-on-common-column-values-in-pandas\n",
    "\n",
    "'''\n",
    "totaldf = pd.merge(ddata, dfid, on='id',sort = True)\n",
    "totaldf\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fH96CtPa0FPy"
   },
   "source": [
    "# Train dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ciPiQ1uTztdy"
   },
   "outputs": [],
   "source": [
    "#Then cut the file into 2 separate dataset by its identification\n",
    "#Cut the file for training set first\n",
    "'''\n",
    "traindf = totaldf[totaldf['identification']=='train']\n",
    "traindf\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i5S4HHLzztYD"
   },
   "outputs": [],
   "source": [
    "#Then print its' basic info to see\n",
    "'''\n",
    "traindf.info()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H1Ir9CVqztUw"
   },
   "outputs": [],
   "source": [
    "#Then we can see that the number of row for the training data and the emotion (the result of prediction) is the same\n",
    "#Then we combine those two file together\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html\n",
    "'''\n",
    "traindf = pd.merge(traindf, emotion, on = None,sort = True)\n",
    "traindf\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XX31IGqhztSi"
   },
   "outputs": [],
   "source": [
    "#Remove stop words and convert to lower case\n",
    "'''\n",
    "def remove_stop(traindf):\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    \n",
    "    #Remove the punctuation\n",
    "    #traindf = traindf.translate(str.maketrans('', '', string.punctuation)) \n",
    "    \n",
    "    #convert to lowercase chracter\n",
    "    traindf = traindf.lower()\n",
    "    word_tokens = word_tokenize(traindf) \n",
    "\n",
    "    filtered_traindf = [w for w in word_tokens if not w in stop_words] \n",
    "    filtered_traindf = ' '.join(filtered_traindf)\n",
    "    return filtered_traindf\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_CgGgpAztMN"
   },
   "outputs": [],
   "source": [
    "#Then add the remove stop words back to the dataframe\n",
    "'''\n",
    "traindf['filtered_traindf'] = traindf.text.apply(lambda x:remove_stop(x))\n",
    "traindf\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UyrC0Ag0ztKF"
   },
   "outputs": [],
   "source": [
    "#Remove the puntuation\n",
    "'''\n",
    "def punct(traindf):\n",
    "    traindf = traindf.translate(str.maketrans('', '', string.punctuation)) \n",
    " \n",
    "    filtered_traindf2 = [w for w in word_tokens if not w in stop_words] \n",
    "    filtered_traindf2 = ' '.join(filtered2_traindf)\n",
    "    return filtered_traindf2\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VCJTvtD6ztEw"
   },
   "outputs": [],
   "source": [
    "#Then add the remove stop words back to the dataframe\n",
    "'''\n",
    "traindf['filtered_traindf2'] = traindf.text.apply(lambda x:remove_stop(x))\n",
    "traindf\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6w5zfkmY18bM"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# the histogram of the data\n",
    "labels = traindf['emotion'].unique()\n",
    "post_total = len(traindf)\n",
    "df1 = traindf.groupby(['emotion']).count()['text']\n",
    "df1 = df1.apply(lambda x: round(x*100/post_total,3))\n",
    "\n",
    "#plot\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "plt.bar(df1.index,df1.values)\n",
    "\n",
    "#arrange\n",
    "plt.ylabel('% of instances')\n",
    "plt.xlabel('Emotion')\n",
    "plt.title('Emotion distribution')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zDBvz6vO3Cd9"
   },
   "source": [
    "###  For easier processing, I prepare the file from my laptop then import to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i01jfq0P2uqn"
   },
   "outputs": [],
   "source": [
    "traindf = pd.read_csv('traindf.csv')\n",
    "# Dataset is now stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 938
    },
    "colab_type": "code",
    "id": "GCXJtpoOkUUY",
    "outputId": "4ec4fb96-cc0c-4a53-b2b1-66c3d653ff75"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>text</th>\n",
       "      <th>date&amp;time</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "      <th>filtered_traindf</th>\n",
       "      <th>filtered_traindf2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>242</td>\n",
       "      <td>['BlackMirror']</td>\n",
       "      <td>o m g Shut Up And Dance though #BlackMirror &lt;LH&gt;</td>\n",
       "      <td>2015-05-16 10:36:47</td>\n",
       "      <td>2015-05-16</td>\n",
       "      <td>10:36:47</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>g shut dance though # blackmirror &lt; lh &gt;</td>\n",
       "      <td>g shut dance though # blackmirror &lt; lh &gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>915</td>\n",
       "      <td>['twitch', 'Destinybeta', 'Destiny', 'Destiny2...</td>\n",
       "      <td>On #twitch &lt;LH&gt; on the #Destinybeta #Destiny #...</td>\n",
       "      <td>2016-10-15 20:46:37</td>\n",
       "      <td>2016-10-15</td>\n",
       "      <td>20:46:37</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td># twitch &lt; lh &gt; # destinybeta # destiny # dest...</td>\n",
       "      <td># twitch &lt; lh &gt; # destinybeta # destiny # dest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x1c7f14</td>\n",
       "      <td>939</td>\n",
       "      <td>[]</td>\n",
       "      <td>A nice sunny wak this morning not many &lt;LH&gt; ar...</td>\n",
       "      <td>2016-07-04 07:22:56</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>07:22:56</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>nice sunny wak morning many &lt; lh &gt; aroud , whi...</td>\n",
       "      <td>nice sunny wak morning many &lt; lh &gt; aroud , whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x1c7f15</td>\n",
       "      <td>181</td>\n",
       "      <td>['Confession', 'NationalCandyCornDay', 'CouldE...</td>\n",
       "      <td>I'm one of those people who love candy corn......</td>\n",
       "      <td>2016-04-16 12:53:40</td>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>12:53:40</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>'m one people love candy corn ... lot . 😁😂 # c...</td>\n",
       "      <td>'m one people love candy corn ... lot . 😁😂 # c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x1c7f16</td>\n",
       "      <td>970</td>\n",
       "      <td>[]</td>\n",
       "      <td>@metmuseum What are these? They look like some...</td>\n",
       "      <td>2017-04-22 17:50:28</td>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>17:50:28</td>\n",
       "      <td>train</td>\n",
       "      <td>disgust</td>\n",
       "      <td>@ metmuseum ? look like something toddlers mak...</td>\n",
       "      <td>@ metmuseum ? look like something toddlers mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455558</td>\n",
       "      <td>0x38fe18</td>\n",
       "      <td>922</td>\n",
       "      <td>[]</td>\n",
       "      <td>@LJPBR @FifthHarmony Um  My vote For @FifthHar...</td>\n",
       "      <td>2016-12-06 11:10:57</td>\n",
       "      <td>2016-12-06</td>\n",
       "      <td>11:10:57</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "      <td>@ ljpbr @ fifthharmony um vote @ fifthharmony ...</td>\n",
       "      <td>@ ljpbr @ fifthharmony um vote @ fifthharmony ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455559</td>\n",
       "      <td>0x38fe19</td>\n",
       "      <td>77</td>\n",
       "      <td>['WesHoolahan', 'WALvIRL', 'COYBIG']</td>\n",
       "      <td>Where is #WesHoolahan?!  #WALvIRL #COYBIG &lt;LH&gt;</td>\n",
       "      <td>2015-02-01 18:04:28</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>18:04:28</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td># weshoolahan ? ! # walvirl # coybig &lt; lh &gt;</td>\n",
       "      <td># weshoolahan ? ! # walvirl # coybig &lt; lh &gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455560</td>\n",
       "      <td>0x38fe1a</td>\n",
       "      <td>25</td>\n",
       "      <td>['not', 'maga']</td>\n",
       "      <td>@mattmfm Fake news! &lt;LH&gt; propagated by Tumpkin...</td>\n",
       "      <td>2016-12-20 17:19:58</td>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>17:19:58</td>\n",
       "      <td>train</td>\n",
       "      <td>surprise</td>\n",
       "      <td>@ mattmfm fake news ! &lt; lh &gt; propagated tumpki...</td>\n",
       "      <td>@ mattmfm fake news ! &lt; lh &gt; propagated tumpki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455561</td>\n",
       "      <td>0x38fe1c</td>\n",
       "      <td>639</td>\n",
       "      <td>[]</td>\n",
       "      <td>..today was brutal  ..#Hungover</td>\n",
       "      <td>2016-09-13 06:31:27</td>\n",
       "      <td>2016-09-13</td>\n",
       "      <td>06:31:27</td>\n",
       "      <td>train</td>\n",
       "      <td>disgust</td>\n",
       "      <td>..today brutal .. # hungover</td>\n",
       "      <td>..today brutal .. # hungover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455562</td>\n",
       "      <td>0x38fe1d</td>\n",
       "      <td>630</td>\n",
       "      <td>['redheadproblems', 'ouch', 'burnt']</td>\n",
       "      <td>Love it when I sun burn my forehead!! NOT!! 😫😱...</td>\n",
       "      <td>2016-09-19 14:35:01</td>\n",
       "      <td>2016-09-19</td>\n",
       "      <td>14:35:01</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "      <td>love sun burn forehead ! ! ! ! 😫😱🙄🤦🏼‍♀️☀️ # re...</td>\n",
       "      <td>love sun burn forehead ! ! ! ! 😫😱🙄🤦🏼‍♀️☀️ # re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  score                                            hashtag  \\\n",
       "0        0x1c7f10    242                                    ['BlackMirror']   \n",
       "1        0x1c7f11    915  ['twitch', 'Destinybeta', 'Destiny', 'Destiny2...   \n",
       "2        0x1c7f14    939                                                 []   \n",
       "3        0x1c7f15    181  ['Confession', 'NationalCandyCornDay', 'CouldE...   \n",
       "4        0x1c7f16    970                                                 []   \n",
       "...           ...    ...                                                ...   \n",
       "1455558  0x38fe18    922                                                 []   \n",
       "1455559  0x38fe19     77               ['WesHoolahan', 'WALvIRL', 'COYBIG']   \n",
       "1455560  0x38fe1a     25                                    ['not', 'maga']   \n",
       "1455561  0x38fe1c    639                                                 []   \n",
       "1455562  0x38fe1d    630               ['redheadproblems', 'ouch', 'burnt']   \n",
       "\n",
       "                                                      text  \\\n",
       "0         o m g Shut Up And Dance though #BlackMirror <LH>   \n",
       "1        On #twitch <LH> on the #Destinybeta #Destiny #...   \n",
       "2        A nice sunny wak this morning not many <LH> ar...   \n",
       "3        I'm one of those people who love candy corn......   \n",
       "4        @metmuseum What are these? They look like some...   \n",
       "...                                                    ...   \n",
       "1455558  @LJPBR @FifthHarmony Um  My vote For @FifthHar...   \n",
       "1455559     Where is #WesHoolahan?!  #WALvIRL #COYBIG <LH>   \n",
       "1455560  @mattmfm Fake news! <LH> propagated by Tumpkin...   \n",
       "1455561                    ..today was brutal  ..#Hungover   \n",
       "1455562  Love it when I sun burn my forehead!! NOT!! 😫😱...   \n",
       "\n",
       "                   date&time        date      time identification  \\\n",
       "0        2015-05-16 10:36:47  2015-05-16  10:36:47          train   \n",
       "1        2016-10-15 20:46:37  2016-10-15  20:46:37          train   \n",
       "2        2016-07-04 07:22:56  2016-07-04  07:22:56          train   \n",
       "3        2016-04-16 12:53:40  2016-04-16  12:53:40          train   \n",
       "4        2017-04-22 17:50:28  2017-04-22  17:50:28          train   \n",
       "...                      ...         ...       ...            ...   \n",
       "1455558  2016-12-06 11:10:57  2016-12-06  11:10:57          train   \n",
       "1455559  2015-02-01 18:04:28  2015-02-01  18:04:28          train   \n",
       "1455560  2016-12-20 17:19:58  2016-12-20  17:19:58          train   \n",
       "1455561  2016-09-13 06:31:27  2016-09-13  06:31:27          train   \n",
       "1455562  2016-09-19 14:35:01  2016-09-19  14:35:01          train   \n",
       "\n",
       "              emotion                                   filtered_traindf  \\\n",
       "0                 joy           g shut dance though # blackmirror < lh >   \n",
       "1        anticipation  # twitch < lh > # destinybeta # destiny # dest...   \n",
       "2                 joy  nice sunny wak morning many < lh > aroud , whi...   \n",
       "3                 joy  'm one people love candy corn ... lot . 😁😂 # c...   \n",
       "4             disgust  @ metmuseum ? look like something toddlers mak...   \n",
       "...               ...                                                ...   \n",
       "1455558       sadness  @ ljpbr @ fifthharmony um vote @ fifthharmony ...   \n",
       "1455559  anticipation        # weshoolahan ? ! # walvirl # coybig < lh >   \n",
       "1455560      surprise  @ mattmfm fake news ! < lh > propagated tumpki...   \n",
       "1455561       disgust                       ..today brutal .. # hungover   \n",
       "1455562       sadness  love sun burn forehead ! ! ! ! 😫😱🙄🤦🏼‍♀️☀️ # re...   \n",
       "\n",
       "                                         filtered_traindf2  \n",
       "0                 g shut dance though # blackmirror < lh >  \n",
       "1        # twitch < lh > # destinybeta # destiny # dest...  \n",
       "2        nice sunny wak morning many < lh > aroud , whi...  \n",
       "3        'm one people love candy corn ... lot . 😁😂 # c...  \n",
       "4        @ metmuseum ? look like something toddlers mak...  \n",
       "...                                                    ...  \n",
       "1455558  @ ljpbr @ fifthharmony um vote @ fifthharmony ...  \n",
       "1455559        # weshoolahan ? ! # walvirl # coybig < lh >  \n",
       "1455560  @ mattmfm fake news ! < lh > propagated tumpki...  \n",
       "1455561                       ..today brutal .. # hungover  \n",
       "1455562  love sun burn forehead ! ! ! ! 😫😱🙄🤦🏼‍♀️☀️ # re...  \n",
       "\n",
       "[1455563 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "id": "tR0wIB-dk7cN",
    "outputId": "5db64728-e6c3-471b-e6ba-d35e965834c8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# the histogram of the data\n",
    "labels = traindf['emotion'].unique()\n",
    "post_total = len(traindf)\n",
    "traindf = traindf.groupby(['emotion']).count()['text']\n",
    "traindf = traindf.apply(lambda x: round(x*100/post_total,3))\n",
    "\n",
    "#plot\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "plt.bar(traindf.index,traindf.values)\n",
    "\n",
    "#arrange\n",
    "plt.ylabel('% of instances')\n",
    "plt.xlabel('Emotion')\n",
    "plt.title('Emotion distribution')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NSVMvdTO0Q1P"
   },
   "source": [
    "# Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rAVsZZ09l58f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntestdf = totaldf[totaldf['identification']=='test']\\ntestdf\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then cut the file for testing dataset\n",
    "'''\n",
    "testdf = totaldf[totaldf['identification']=='test']\n",
    "testdf\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zo8pyGQ2mHPS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntestdf['emotion'] = testdf.apply(lambda _: '', axis=1)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "testdf['emotion'] = testdf.apply(lambda _: '', axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RahpGtY9mHh_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntestdf.info()\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then print its' basic info to see\n",
    "'''\n",
    "testdf.info()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CkI-hy6smofj"
   },
   "source": [
    "###  For easier processing, I prepare the file from my laptop then import to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NjcQT_1ErANl"
   },
   "outputs": [],
   "source": [
    "testdf = pd.read_csv('testdf.csv')\n",
    "# Dataset is now stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XdZ4FWOXzs78"
   },
   "outputs": [],
   "source": [
    "testdf['emotion'] = testdf.apply(lambda _: '', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 831
    },
    "colab_type": "code",
    "id": "35rv6lZEzs5k",
    "outputId": "f4b3802b-ae38-4f1f-aebf-581da5ccb433",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 411972 entries, 0 to 411971\n",
      "Data columns (total 9 columns):\n",
      "id                411972 non-null object\n",
      "score             411972 non-null int64\n",
      "hashtag           411972 non-null object\n",
      "text              411972 non-null object\n",
      "date&time         411972 non-null object\n",
      "date              411972 non-null object\n",
      "time              411972 non-null object\n",
      "identification    411972 non-null object\n",
      "emotion           411972 non-null object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 28.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>text</th>\n",
       "      <th>date&amp;time</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>62</td>\n",
       "      <td>[]</td>\n",
       "      <td>@JZED74 While inappropriate AF, he likely wasn...</td>\n",
       "      <td>2017-05-14 11:39:43</td>\n",
       "      <td>2017-05-14</td>\n",
       "      <td>11:39:43</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>756</td>\n",
       "      <td>[]</td>\n",
       "      <td>I tried to figure out why you mean so much to ...</td>\n",
       "      <td>2016-02-14 15:55:45</td>\n",
       "      <td>2016-02-14</td>\n",
       "      <td>15:55:45</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>213</td>\n",
       "      <td>['auspol', 'fizza']</td>\n",
       "      <td>The only “big plan” you ever had in your life,...</td>\n",
       "      <td>2016-07-25 17:05:35</td>\n",
       "      <td>2016-07-25</td>\n",
       "      <td>17:05:35</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x1c7f17</td>\n",
       "      <td>603</td>\n",
       "      <td>[]</td>\n",
       "      <td>Looking back on situations old &amp; new, recent o...</td>\n",
       "      <td>2017-01-21 19:25:33</td>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>19:25:33</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x1c7f18</td>\n",
       "      <td>609</td>\n",
       "      <td>[]</td>\n",
       "      <td>@jasoninthehouse Why do you insist on talking ...</td>\n",
       "      <td>2017-04-25 16:36:47</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>16:36:47</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411967</td>\n",
       "      <td>0x38fe04</td>\n",
       "      <td>497</td>\n",
       "      <td>['traitor', 'treason']</td>\n",
       "      <td>\"The Grand Bargain\" The Great American Betraya...</td>\n",
       "      <td>2016-12-05 19:57:34</td>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>19:57:34</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411968</td>\n",
       "      <td>0x38fe06</td>\n",
       "      <td>187</td>\n",
       "      <td>['FosterCare', 'roadtoadoption', 'Adoption']</td>\n",
       "      <td>I get to be a 1 year old girl's new mama start...</td>\n",
       "      <td>2017-07-15 19:43:46</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>19:43:46</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411969</td>\n",
       "      <td>0x38fe13</td>\n",
       "      <td>139</td>\n",
       "      <td>['artworld']</td>\n",
       "      <td>Asian dude with dangly gold earrings is back &amp;...</td>\n",
       "      <td>2017-07-13 07:01:50</td>\n",
       "      <td>2017-07-13</td>\n",
       "      <td>07:01:50</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411970</td>\n",
       "      <td>0x38fe14</td>\n",
       "      <td>251</td>\n",
       "      <td>['nba', 'cantmakeaJ']</td>\n",
       "      <td>I think @kostakoufos might be the worst player...</td>\n",
       "      <td>2016-08-22 22:13:06</td>\n",
       "      <td>2016-08-22</td>\n",
       "      <td>22:13:06</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411971</td>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>611</td>\n",
       "      <td>[]</td>\n",
       "      <td>I told myself I'd be twitter famous. twitter m...</td>\n",
       "      <td>2016-02-14 03:24:55</td>\n",
       "      <td>2016-02-14</td>\n",
       "      <td>03:24:55</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  score                                       hashtag  \\\n",
       "0       0x1c7f0f     62                                            []   \n",
       "1       0x1c7f12    756                                            []   \n",
       "2       0x1c7f13    213                           ['auspol', 'fizza']   \n",
       "3       0x1c7f17    603                                            []   \n",
       "4       0x1c7f18    609                                            []   \n",
       "...          ...    ...                                           ...   \n",
       "411967  0x38fe04    497                        ['traitor', 'treason']   \n",
       "411968  0x38fe06    187  ['FosterCare', 'roadtoadoption', 'Adoption']   \n",
       "411969  0x38fe13    139                                  ['artworld']   \n",
       "411970  0x38fe14    251                         ['nba', 'cantmakeaJ']   \n",
       "411971  0x38fe1b    611                                            []   \n",
       "\n",
       "                                                     text  \\\n",
       "0       @JZED74 While inappropriate AF, he likely wasn...   \n",
       "1       I tried to figure out why you mean so much to ...   \n",
       "2       The only “big plan” you ever had in your life,...   \n",
       "3       Looking back on situations old & new, recent o...   \n",
       "4       @jasoninthehouse Why do you insist on talking ...   \n",
       "...                                                   ...   \n",
       "411967  \"The Grand Bargain\" The Great American Betraya...   \n",
       "411968  I get to be a 1 year old girl's new mama start...   \n",
       "411969  Asian dude with dangly gold earrings is back &...   \n",
       "411970  I think @kostakoufos might be the worst player...   \n",
       "411971  I told myself I'd be twitter famous. twitter m...   \n",
       "\n",
       "                  date&time        date      time identification emotion  \n",
       "0       2017-05-14 11:39:43  2017-05-14  11:39:43           test          \n",
       "1       2016-02-14 15:55:45  2016-02-14  15:55:45           test          \n",
       "2       2016-07-25 17:05:35  2016-07-25  17:05:35           test          \n",
       "3       2017-01-21 19:25:33  2017-01-21  19:25:33           test          \n",
       "4       2017-04-25 16:36:47  2017-04-25  16:36:47           test          \n",
       "...                     ...         ...       ...            ...     ...  \n",
       "411967  2016-12-05 19:57:34  2016-12-05  19:57:34           test          \n",
       "411968  2017-07-15 19:43:46  2017-07-15  19:43:46           test          \n",
       "411969  2017-07-13 07:01:50  2017-07-13  07:01:50           test          \n",
       "411970  2016-08-22 22:13:06  2016-08-22  22:13:06           test          \n",
       "411971  2016-02-14 03:24:55  2016-02-14  03:24:55           test          \n",
       "\n",
       "[411972 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then print its' basic info to see\n",
    "testdf.info()\n",
    "\n",
    "testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cn2bNWtz0Vja"
   },
   "source": [
    "# Data Preprocessing\n",
    "## Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "colab_type": "code",
    "id": "MTT3p9U6wT61",
    "outputId": "725c0f1f-171f-43c3-de0f-356dae5d7237"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "anger           (The amoung of missing records is: , 0)\n",
       "anticipation    (The amoung of missing records is: , 0)\n",
       "disgust         (The amoung of missing records is: , 0)\n",
       "fear            (The amoung of missing records is: , 0)\n",
       "joy             (The amoung of missing records is: , 0)\n",
       "sadness         (The amoung of missing records is: , 0)\n",
       "surprise        (The amoung of missing records is: , 0)\n",
       "trust           (The amoung of missing records is: , 0)\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing\n",
    "#Checking for the missing value and duplicate data\n",
    "traindf.isnull().apply(lambda x: dmh.check_missing_values(traindf))\n",
    "\n",
    "#There is no missing data in the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2o5Q5RQywYwV"
   },
   "source": [
    "# Create Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "Kbtnfo0Gs9CZ",
    "outputId": "36d78ef4-3a9d-4ff6-9462-49d2c8574007"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455563, 500)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# build analyzers (bag-of-words)\n",
    "BOW_500 = CountVectorizer(max_features=500, tokenizer=nltk.word_tokenize) \n",
    "\n",
    "# apply analyzer to training data\n",
    "BOW_500.fit(traindf['text'])\n",
    "\n",
    "train_data_BOW_features_500 = BOW_500.transform(traindf['text'])\n",
    "\n",
    "## check dimension\n",
    "train_data_BOW_features_500.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "d0EldGtku8MH",
    "outputId": "130dd98c-d170-4112-8c95-6938932635ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  0, ...,  0,  0,  0],\n",
       "       [ 0, 12,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 1,  2,  0, ...,  0,  0,  0],\n",
       "       [ 0,  1,  0, ...,  0,  0,  0],\n",
       "       [ 4,  3,  0, ...,  0,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_BOW_features_500.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "AS9xtNtAujOg",
    "outputId": "179d6dc5-203c-4912-bf64-f8acb706791d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['change',\n",
       " 'christ',\n",
       " 'christmas',\n",
       " 'class',\n",
       " 'closed',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'coming',\n",
       " 'could',\n",
       " 'country']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe some feature names\n",
    "feature_names_500 = BOW_500.get_feature_names()\n",
    "feature_names_500[100:110]\n",
    "\n",
    "#random value 500 top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "783EOVJXwtuU"
   },
   "source": [
    "# Create Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "459HFckXvDGL"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# build analyzers (bag-of-words)\n",
    "BOW_vectorizer = CountVectorizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "colab_type": "code",
    "id": "H1CzaqdkvDI4",
    "outputId": "079fdfa3-6443-49dd-f17f-2994ab5c75a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Learn a vocabulary dictionary of all tokens in the raw documents.\n",
    "BOW_vectorizer.fit(traindf['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YAU8-uBDpZg9"
   },
   "outputs": [],
   "source": [
    "# 2. Transform documents to document-term matrix.\n",
    "train_data_BOW_features = BOW_vectorizer.transform(traindf['filtered_traindf'])\n",
    "test_data_BOW_features = BOW_vectorizer.transform(testdf['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b-dcVwXlvDLX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1455563x794247 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 12484170 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result\n",
    "train_data_BOW_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ah6uT4-XvDOF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data_BOW_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WlD4tcp6vDQr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455563, 794247)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the dimension\n",
    "train_data_BOW_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M4umFkiwvDTb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['005',\n",
       " '00533321',\n",
       " '00575',\n",
       " '00578',\n",
       " '005796',\n",
       " '005e5n',\n",
       " '006',\n",
       " '0060',\n",
       " '007',\n",
       " '00786mujahid']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe some feature names\n",
    "feature_names = BOW_vectorizer.get_feature_names()\n",
    "feature_names[100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SGudmC1Bw_FS"
   },
   "source": [
    "# Decision Trees Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-hJp0Pk7vDWc"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X_train = BOW_500.transform(traindf['text'])\n",
    "y_train = traindf['emotion']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hbY_O4VOvDZN"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "X_test = BOW_500.transform(testdf['text'])\n",
    "y_test = testdf['emotion']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNw6TJnTvDb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (1455563, 500)\n",
      "y_train.shape:  (1455563,)\n",
      "X_test.shape:  (411972, 500)\n",
      "y_test.shape:  (411972,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "## take a look at data dimension is a good habbit  :)\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EnsHe42jvDeu"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "## build DecisionTree model\n",
    "DT_model = DecisionTreeClassifier(random_state=0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UXpQ8AtPvDhb"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "## training!\n",
    "DT_model = DT_model.fit(X_train, y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BTUd-3TPvDkF"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "## predict!\n",
    "y_train_pred = DT_model.predict(X_train)\n",
    "y_test_pred = DT_model.predict(X_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ozoPAYYYxHWJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'disgust', 'trust', 'joy', 'surprise', 'joy', 'sadness',\n",
       "       'joy', 'anticipation', 'trust'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "## so we get the pred result\n",
    "y_test_pred[:10]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "baCanW4ixHZA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.97\n",
      "testing accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Check the accuracy\n",
    "\n",
    "## accuracy testing on decision tree model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "acc_test = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train, 2)))\n",
    "print('testing accuracy: {}'.format(round(acc_test, 2)))\n",
    "\n",
    "#at first I will submit the result, but after checking it, i will let it go~\n",
    "#it is cleary that the model is overfitting.\n",
    "#I know that there is the problem before trying the model but I just want to see the result\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IY4Rom4bxHbL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'disgust', 'trust', 'joy', 'surprise', 'joy', 'sadness',\n",
       "       'joy', 'anticipation', 'trust'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "y_test_pred[:10]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xs-Vb0ztxHd9"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "y_test_pred2 = DT_model.predict(X_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vq1UxrDfxHgY"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#Print the result - Decision Tree model\n",
    "test_id = testdf.id\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IjA6kpcDxHjC"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def listOfTuples(test_id, y_test_pred2): \n",
    "    return list(map(lambda x, y:(x,y), test_id, y_test_pred2)) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-6-bhg6-xHl2"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "finalresult = (listOfTuples(test_id, y_test_pred2))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jw_xyc4TxHoO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0x1c7f0f', 'sadness')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "finalresult[0:1]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qwY5KCOkxHqw"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "dfresult = pd.DataFrame(finalresult) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EjpOoDNwxmmE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x1c7f17</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x1c7f18</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411967</td>\n",
       "      <td>0x38fe04</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411968</td>\n",
       "      <td>0x38fe06</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411969</td>\n",
       "      <td>0x38fe13</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411970</td>\n",
       "      <td>0x38fe14</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411971</td>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1\n",
       "0       0x1c7f0f   sadness\n",
       "1       0x1c7f12   disgust\n",
       "2       0x1c7f13     trust\n",
       "3       0x1c7f17       joy\n",
       "4       0x1c7f18  surprise\n",
       "...          ...       ...\n",
       "411967  0x38fe04   sadness\n",
       "411968  0x38fe06     trust\n",
       "411969  0x38fe13       joy\n",
       "411970  0x38fe14     trust\n",
       "411971  0x38fe1b       joy\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "dfresult\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f8a1zn7cxmrc"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#assign header names\n",
    "dfresult.columns = ['id','emotion']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OcXwKCaBxmuK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x1c7f17</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x1c7f18</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411967</td>\n",
       "      <td>0x38fe04</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411968</td>\n",
       "      <td>0x38fe06</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411969</td>\n",
       "      <td>0x38fe13</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411970</td>\n",
       "      <td>0x38fe14</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411971</td>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id   emotion\n",
       "0       0x1c7f0f   sadness\n",
       "1       0x1c7f12   disgust\n",
       "2       0x1c7f13     trust\n",
       "3       0x1c7f17       joy\n",
       "4       0x1c7f18  surprise\n",
       "...          ...       ...\n",
       "411967  0x38fe04   sadness\n",
       "411968  0x38fe06     trust\n",
       "411969  0x38fe13       joy\n",
       "411970  0x38fe14     trust\n",
       "411971  0x38fe1b       joy\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "dfresult\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50OsFMvhxmwo"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 33-34: truncated \\UXXXXXXXX escape (<ipython-input-62-353974d216c0>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-62-353974d216c0>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    '''\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 33-34: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#save the file to csv format\n",
    "exportcsv = dfresult.to_csv (r'C:\\Users\\User\\Data Mining_NTHU\\DMlab2x\\DM19-Lab2-Homework\\Dataset_Twitter_re_Decision tRee.csv', index = None, header=True) \n",
    "\n",
    "print (dfresult)\n",
    "\n",
    "Submit score: 0.27xxxxxx ( I cannot remember the exact number)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r7v_iCjsyBUu"
   },
   "source": [
    "# Naive Bays Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kVZaMGKwxmzQ"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#Preparing data before feeding into the vectorizer\n",
    "#by combine hastag, text and score for both test and train dataset\n",
    "traincombined = traindf[['text','hashtag','score']].astype(str).apply('-'.join, axis=1)\n",
    "testcombined = testdf[['text','hashtag','score']].astype(str).apply('-'.join, axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s4rnvRaOxm4N"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Create the vectorizer \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "\n",
    "train_countvec = count_vect.fit_transform(traincombined)\n",
    "test_countvec = count_vect.transform(testcombined)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9qsIySqyUSC"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "X_train = train_countvec\n",
    "y_train = traindf['emotion']\n",
    "X_test = test_countvec\n",
    "y_test = testdf['emotion']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FHM_FGfuyUU5",
    "outputId": "59b0d337-b15c-4519-9a92-8542c193807d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Train the model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MulNB = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "MulNB.fit(X_train, y_train)\n",
    "MulNB.score(X_test, y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "k-5v7f7ayUXY",
    "outputId": "ae2ec605-0d6c-4da9-ac22-02e8567511ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'sadness', 'disgust', 'anticipation', 'sadness', 'joy',\n",
       "       'sadness', 'anticipation', 'anticipation', 'anticipation'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Test on the real data\n",
    "## build Naive Bayes model\n",
    "NV_model = MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "\n",
    "## training the data\n",
    "NV_model = NV_model.fit(X_train, y_train)\n",
    "\n",
    "## predict!\n",
    "y_train_pred = NV_model.predict(X_train)\n",
    "\n",
    "X_test_pred = test_countvec\n",
    "y_test_pred = NV_model.predict(test_countvec)\n",
    "\n",
    "## so we get the pred result\n",
    "y_test_pred[:10]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qcAUNscFyUa8",
    "outputId": "031f342f-6841-48b7-ebee-21e86cc5d8df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "## Result Evaluation /accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train1 = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "acc_test1 = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train1, 2)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "NH03XaedyUe5",
    "outputId": "1dc45977-9b7d-46e2-bce6-84c4ed420693"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'sadness', 'disgust', 'anticipation', 'sadness', 'joy',\n",
       "       'sadness', 'anticipation', 'anticipation', 'anticipation'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "y_test_pred2 = NV_model.predict(X_test)\n",
    "y_test_pred2[:10]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "n0fy8foeyUhp",
    "outputId": "b0ab62bf-6e44-4653-a61a-f56c355a7591"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0x1c7f0f', 'sadness'),\n",
       " ('0x1c7f12', 'sadness'),\n",
       " ('0x1c7f13', 'disgust'),\n",
       " ('0x1c7f17', 'anticipation'),\n",
       " ('0x1c7f18', 'sadness'),\n",
       " ('0x1c7f21', 'joy'),\n",
       " ('0x1c7f24', 'sadness'),\n",
       " ('0x1c7f29', 'anticipation'),\n",
       " ('0x1c7f2d', 'anticipation'),\n",
       " ('0x1c7f32', 'anticipation')]"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Print the result - Naive Bays model\n",
    "\n",
    "test_id = testdf.id\n",
    "def listOfTuples(test_id, y_test_pred2): \n",
    "    return list(map(lambda x, y:(x,y), test_id, y_test_pred2)) \n",
    "\n",
    "finalresult2 = (listOfTuples(test_id, y_test_pred2))\n",
    "finalresult2[0:10]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "colab_type": "code",
    "id": "lcISmR2YyUka",
    "outputId": "18493f6f-dacf-4fd0-ee37-113d098cd443"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1c7f17</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x1c7f18</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>0x38fe04</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>0x38fe06</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>0x38fe13</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>0x38fe14</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0             1\n",
       "0       0x1c7f0f       sadness\n",
       "1       0x1c7f12       sadness\n",
       "2       0x1c7f13       disgust\n",
       "3       0x1c7f17  anticipation\n",
       "4       0x1c7f18       sadness\n",
       "...          ...           ...\n",
       "411967  0x38fe04       sadness\n",
       "411968  0x38fe06           joy\n",
       "411969  0x38fe13           joy\n",
       "411970  0x38fe14       disgust\n",
       "411971  0x38fe1b           joy\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Pass the result into panda dataframe and print the result to see\n",
    "dfresult2 = pd.DataFrame(finalresult2) \n",
    "dfresult2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "colab_type": "code",
    "id": "4Z6vdOLmyUnJ",
    "outputId": "f7a68bcc-90a6-4c67-bd1f-408f15b87722"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1c7f17</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x1c7f18</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>0x38fe04</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>0x38fe06</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>0x38fe13</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>0x38fe14</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id       emotion\n",
       "0       0x1c7f0f       sadness\n",
       "1       0x1c7f12       sadness\n",
       "2       0x1c7f13       disgust\n",
       "3       0x1c7f17  anticipation\n",
       "4       0x1c7f18       sadness\n",
       "...          ...           ...\n",
       "411967  0x38fe04       sadness\n",
       "411968  0x38fe06           joy\n",
       "411969  0x38fe13           joy\n",
       "411970  0x38fe14       disgust\n",
       "411971  0x38fe1b           joy\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Then assign header names and print the data to see\n",
    "dfresult2.columns = ['id','emotion']\n",
    "dfresult2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "colab_type": "code",
    "id": "kK2zp5eJyUsi",
    "outputId": "7533eb55-5e57-4ed2-b957-fa7e42ef7763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id       emotion\n",
      "0       0x1c7f0f       sadness\n",
      "1       0x1c7f12       sadness\n",
      "2       0x1c7f13       disgust\n",
      "3       0x1c7f17  anticipation\n",
      "4       0x1c7f18       sadness\n",
      "...          ...           ...\n",
      "411967  0x38fe04       sadness\n",
      "411968  0x38fe06           joy\n",
      "411969  0x38fe13           joy\n",
      "411970  0x38fe14       disgust\n",
      "411971  0x38fe1b           joy\n",
      "\n",
      "[411972 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Then export the file \n",
    "\n",
    "exportcsv2 = dfresult2.to_csv (r'C:\\Users\\User\\Data Mining_NTHU\\DMlab2x\\DM19-Lab2-Homework\\Dataset_Twitter_re2.csv', \n",
    "                               index = None, header=True) \n",
    "\n",
    "print (dfresult2)\n",
    "\n",
    "Submit score: the highest submit score: 0.45008\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v8VGPkqly1JN"
   },
   "source": [
    "## Clustering: Word2Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "tNSlQBmJyUvH",
    "outputId": "c6949bd8-a56f-41a5-fdb2-559d9e73c35d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>o m g Shut Up And Dance though #BlackMirror &lt;LH&gt;</td>\n",
       "      <td>[o, m, g, Shut, Up, And, Dance, though, #, Bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>On #twitch &lt;LH&gt; on the #Destinybeta #Destiny #...</td>\n",
       "      <td>[On, #, twitch, &lt;, LH, &gt;, on, the, #, Destinyb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1c7f14</td>\n",
       "      <td>A nice sunny wak this morning not many &lt;LH&gt; ar...</td>\n",
       "      <td>[A, nice, sunny, wak, this, morning, not, many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1c7f15</td>\n",
       "      <td>I'm one of those people who love candy corn......</td>\n",
       "      <td>[I, 'm, one, of, those, people, who, love, can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x1c7f16</td>\n",
       "      <td>@metmuseum What are these? They look like some...</td>\n",
       "      <td>[@, metmuseum, What, are, these, ?, They, look...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  ...                                     text_tokenized\n",
       "0  0x1c7f10  ...  [o, m, g, Shut, Up, And, Dance, though, #, Bla...\n",
       "1  0x1c7f11  ...  [On, #, twitch, <, LH, >, on, the, #, Destinyb...\n",
       "2  0x1c7f14  ...  [A, nice, sunny, wak, this, morning, not, many...\n",
       "3  0x1c7f15  ...  [I, 'm, one, of, those, people, who, love, can...\n",
       "4  0x1c7f16  ...  [@, metmuseum, What, are, these, ?, They, look...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check library\n",
    "import gensim\n",
    "\n",
    "## ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# # if you want to see the training messages, you can use it\n",
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "## the input type\n",
    "traindf['text_tokenized'] = traindf['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "traindf[['id', 'text', 'text_tokenized']].head()\n",
    "\n",
    "#Take the text_tokenized to the training_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lzFK4jAhyUyh"
   },
   "outputs": [],
   "source": [
    "## create the training corpus\n",
    "training_corpus = traindf['text_tokenized'].values\n",
    "training_corpus[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NSgXatV5yU3r"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "## the input type\n",
    "traindf['text_tokenized'] = traindf['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "traindf[['id', 'text', 'text_tokenized']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0IpY-nuMyU67"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "## setting\n",
    "vector_dim = 100\n",
    "window_size = 5\n",
    "min_count = 1\n",
    "training_iter = 20\n",
    "\n",
    "## model\n",
    "word2vec_model = Word2Vec(sentences=training_corpus, \n",
    "                          size=vector_dim, window=window_size, \n",
    "                          min_count=min_count, iter=training_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q83lKdn7yU9p"
   },
   "outputs": [],
   "source": [
    "#Test the model with testdata\n",
    "word2vec_model_result = word2vec_model.most_similar('happy', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rv0nKY4ZyVAW"
   },
   "outputs": [],
   "source": [
    "### Generating word vector (embeddings): Word2Vector\n",
    "\n",
    "# get the corresponding vector of a word\n",
    "word_vec = word2vec_model.wv['happy']\n",
    "word_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4hAV2AWeyVDQ"
   },
   "outputs": [],
   "source": [
    "# Get the most similar words\n",
    "word = 'happy'\n",
    "topn = 10\n",
    "word2vec_model.most_similar(word, topn=topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8yIyf-AyVIc"
   },
   "outputs": [],
   "source": [
    "# clustering target\n",
    "target_list = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness', 'surprise','trust']\n",
    "print('target words: ', target_list)\n",
    "\n",
    "# convert to word vector\n",
    "X = [word2vec_model.wv[word] for word in target_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gGqE6xBkyVLn"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# we have to decide how many cluster (k) we want\n",
    "k = 2\n",
    "\n",
    "# k-means model\n",
    "kmeans_model = KMeans(n_clusters=k)\n",
    "kmeans_model.fit(X)\n",
    "\n",
    "# cluster result\n",
    "cluster_result = kmeans_model.labels_\n",
    "\n",
    "# show\n",
    "for i in range(len(target_list)):\n",
    "    print('word: {} \\t cluster: {}'.format(target_list[i], cluster_result[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gyRqwcGQyVOm"
   },
   "outputs": [],
   "source": [
    "#check cluster membership\n",
    "word = 'happy'\n",
    "word_vec = word2vec_model.wv[word]\n",
    "kmeans_result = kmeans_model.predict([word_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-jbOuGX0yVS3"
   },
   "outputs": [],
   "source": [
    "kmeans_result[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M4FED8Z30snJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQT4Rrm70sxy"
   },
   "source": [
    "# Deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5lELtySGyUqC"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-71f19e1fb1d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# standardize name (X, y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBOW_500\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraindf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'emotion'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    968\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 970\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    971\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m    350\u001b[0m                                                tokenize)\n\u001b[0;32m    351\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[1;32m--> 352\u001b[1;33m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     return [\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m     ]\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     return [\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m     ]\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\treebank.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mregexp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubstitution\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENDING_QUOTES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubstitution\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mregexp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCONTRACTIONS2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "\n",
    "# standardize name (X, y) \n",
    "X_train = BOW_500.transform(traindf['text'])\n",
    "y_train = train_df['emotion']\n",
    "\n",
    "X_test = BOW_500.transform(testdf['text'])\n",
    "y_test = test_df['emotion']\n",
    "\n",
    "## check dimension is a good habbit \n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wczJlt_Hxm17"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "## deal with label (string -> one-hot)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "print('check label: ', label_encoder.classes_)\n",
    "print('\\n## Before convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "y_test = label_encode(label_encoder, y_test)\n",
    "\n",
    "print('\\n\\n## After convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oGlx-2xF0zUg"
   },
   "outputs": [],
   "source": [
    "#Build the model\n",
    "# I/O check\n",
    "input_shape = X_train.shape[1]\n",
    "print('input_shape: ', input_shape)\n",
    "\n",
    "output_shape = len(label_encoder.classes_)\n",
    "print('output_shape: ', output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CAGvOPVL0zgb"
   },
   "outputs": [],
   "source": [
    "#Create the model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import ReLU, Softmax\n",
    "\n",
    "# input layer\n",
    "model_input = Input(shape=(input_shape, ))  # 500\n",
    "X = model_input\n",
    "\n",
    "# 1st hidden layer\n",
    "X_W1 = Dense(units=64)(X)  # 64\n",
    "H1 = ReLU()(X_W1)\n",
    "\n",
    "# 2nd hidden layer\n",
    "H1_W2 = Dense(units=64)(H1)  # 64\n",
    "H2 = ReLU()(H1_W2)\n",
    "\n",
    "# output layer\n",
    "H2_W3 = Dense(units=output_shape)(H2)  # 4\n",
    "H3 = Softmax()(H2_W3)\n",
    "\n",
    "model_output = H3\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[model_input], outputs=[model_output])\n",
    "\n",
    "# loss function & optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# show model construction\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f6ZutYYu0zdX"
   },
   "outputs": [],
   "source": [
    "#Train\n",
    "## Training to see the accuracy of prediction >> accuracy = accuracy on training set and val_accuracy = accuracy on testing set\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('logs/training_log.csv')\n",
    "\n",
    "# training setting\n",
    "epochs = 25\n",
    "batch_size = 32\n",
    "\n",
    "# training!\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=[csv_logger],\n",
    "                    validation_data = (X_test, y_test))\n",
    "print('training finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UenyL5yI0zac"
   },
   "outputs": [],
   "source": [
    "#Predict the data on testset\n",
    "\n",
    "#predict on testing result, this is the generation for vector but the result is unreable by human\n",
    "#While predict, we use the X_test\n",
    "## predict\n",
    "pred_result = model.predict(X_test, batch_size=128)\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FzcrCjFb0zYK"
   },
   "outputs": [],
   "source": [
    "#Then we make it readable here>> the first one the predicable is sadness, the next one is fear and etc.\n",
    "pred_result = label_decode(label_encoder, pred_result)\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ln9r4ejN0zSI"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('testing accuracy: {}'.format(round(accuracy_score(label_decode(label_encoder, y_test), pred_result), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2bQtr-Oa0zPT"
   },
   "outputs": [],
   "source": [
    "#Let's take a look at the training log\n",
    "training_log = pd.DataFrame()\n",
    "training_log = pd.read_csv(\"logs/training_log.csv\")\n",
    "training_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LE7uAMO0zMi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FIdzEkF1xmot"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#References: https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    #text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['text'] = traindf['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['hashtag'] = traindf['hashtag'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                           g shut dance though #blackmirror\n",
      "1          #twitch #destinybeta #destiny #destiny2 #desti...\n",
      "2          nice sunny wak morning many aroud whites time ...\n",
      "3          im one people love candy corn lot #confession ...\n",
      "4          metmuseum look like something toddlers make su...\n",
      "                                 ...                        \n",
      "1455558    ljpbr fifthharmony um vote fifthharmony song s...\n",
      "1455559                        #weshoolahan #walvirl #coybig\n",
      "1455560     mattmfm fake news propagated tumpkins #not #maga\n",
      "1455561                               today brutal #hungover\n",
      "1455562    love sun burn forehead #redheadproblems #ouch ...\n",
      "Name: text, Length: 1455563, dtype: object\n",
      "0                                                  lackirror\n",
      "1          twitch estinybeta estiny estiny2 estinytheame ...\n",
      "2                                                           \n",
      "3          onfession ationalandyornay ouldathemllay ohame...\n",
      "4                                                           \n",
      "                                 ...                        \n",
      "1455558                                                     \n",
      "1455559                                          esoolahan v\n",
      "1455560                                                 maga\n",
      "1455561                                                     \n",
      "1455562                           redheadproblems ouch burnt\n",
      "Name: hashtag, Length: 1455563, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(traindf['text'])\n",
    "print(traindf['hashtag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2202529"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf['text'].apply(lambda x: len(x.split(' '))).sum()\n",
    "traindf['hashtag'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing data before feeding into the vectorizer\n",
    "#by combine hastag, text and score for both test and train dataset\n",
    "traincombined = traindf[['text','hashtag','score']].astype(str).apply('-'.join, axis=1)\n",
    "testcombined = testdf[['text','hashtag','score']].astype(str).apply('-'.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()#stop_words='english')\n",
    "\n",
    "train_countvec = count_vect.fit_transform(traincombined)\n",
    "test_countvec = count_vect.transform(testcombined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_countvec\n",
    "y_train = traindf['emotion']\n",
    "X_test = test_countvec\n",
    "y_test = testdf['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MulNB = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "MulNB.fit(X_train, y_train)\n",
    "MulNB.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'joy', 'anticipation', 'anticipation', 'sadness', 'joy',\n",
       "       'joy', 'anticipation', 'anticipation', 'joy'], dtype='<U12')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test on the real data\n",
    "## build Naive Bayes model\n",
    "NV_model = MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "\n",
    "## training the data\n",
    "NV_model = NV_model.fit(X_train, y_train)\n",
    "\n",
    "## predict!\n",
    "y_train_pred = NV_model.predict(X_train)\n",
    "\n",
    "X_test_pred = test_countvec\n",
    "y_test_pred = NV_model.predict(test_countvec)\n",
    "\n",
    "## so we get the pred result\n",
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.650292704609831\n"
     ]
    }
   ],
   "source": [
    "## Result Evaluation /accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train1 = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "acc_test1 = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train1, 15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0x1c7f0f', 'sadness'),\n",
       " ('0x1c7f12', 'joy'),\n",
       " ('0x1c7f13', 'anticipation'),\n",
       " ('0x1c7f17', 'anticipation'),\n",
       " ('0x1c7f18', 'sadness'),\n",
       " ('0x1c7f21', 'joy'),\n",
       " ('0x1c7f24', 'joy'),\n",
       " ('0x1c7f29', 'anticipation'),\n",
       " ('0x1c7f2d', 'anticipation'),\n",
       " ('0x1c7f32', 'joy')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the result - Naive Bays model\n",
    "\n",
    "test_id = testdf.id\n",
    "def listOfTuples(test_id, y_test_pred): \n",
    "    return list(map(lambda x, y:(x,y), test_id, y_test_pred)) \n",
    "\n",
    "finalresult = (listOfTuples(test_id, y_test_pred))\n",
    "finalresult[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id       emotion\n",
      "0       0x1c7f0f       sadness\n",
      "1       0x1c7f12           joy\n",
      "2       0x1c7f13  anticipation\n",
      "3       0x1c7f17  anticipation\n",
      "4       0x1c7f18       sadness\n",
      "...          ...           ...\n",
      "411967  0x38fe04       sadness\n",
      "411968  0x38fe06           joy\n",
      "411969  0x38fe13           joy\n",
      "411970  0x38fe14           joy\n",
      "411971  0x38fe1b           joy\n",
      "\n",
      "[411972 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Pass the result into panda dataframe and print the result to see\n",
    "dfresult = pd.DataFrame(finalresult) \n",
    "dfresult\n",
    "\n",
    "#Then assign header names and print the data to see\n",
    "dfresult.columns = ['id','emotion']\n",
    "dfresult\n",
    "\n",
    "#Then export the file \n",
    "exportcsv2 = dfresult.to_csv (r'C:\\Users\\User\\Data Mining_NTHU\\DMlab2x\\DM19-Lab2-Homework_Twitter - ทำไฟล์ตรงนี้ เวลาอัพไปอัพที่อื่น\\Dataset_Twitter_re31.csv', \n",
    "                               index = None, header=True) \n",
    "print (dfresult)\n",
    "\n",
    "\n",
    "Submit score: 0.38481\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX_train = traindf['text']\\ny_train = traindf['emotion']\\nX_test = testdf['text']\\ny_test = testdf['emotion']\\n\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Another tuning model\n",
    "'''\n",
    "X_train = traindf['text']\n",
    "y_train = traindf['emotion']\n",
    "X_test = testdf['text']\n",
    "y_test = testdf['emotion']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'joy', 'anticipation', 'anticipation', 'sadness', 'joy',\n",
       "       'joy', 'anticipation', 'anticipation', 'joy'], dtype='<U12')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "nb_model = Pipeline([('vect', CountVectorizer()),\n",
    "               #('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)),\n",
    "              ])\n",
    "\n",
    "## training the data\n",
    "nb_model = nb_model.fit(X_train, y_train)\n",
    "\n",
    "## predict!\n",
    "y_train_pred = nb_model.predict(X_train)\n",
    "\n",
    "X_test_pred = X_test\n",
    "y_test_pred = nb_model.predict(X_test)\n",
    "\n",
    "## so we get the pred result\n",
    "y_test_pred[:10]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n## Result Evaluation /accuracy\\nfrom sklearn.metrics import accuracy_score\\n\\nacc_train1 = accuracy_score(y_true=y_train, y_pred=y_train_pred)\\nacc_test1 = accuracy_score(y_true=y_test, y_pred=y_test_pred)\\n\\nprint('training accuracy: {}'.format(round(acc_train1, 15)))\\n\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "## Result Evaluation /accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train1 = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "acc_test1 = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train1, 15)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0x1c7f0f', 'sadness'),\n",
       " ('0x1c7f12', 'joy'),\n",
       " ('0x1c7f13', 'anticipation'),\n",
       " ('0x1c7f17', 'anticipation'),\n",
       " ('0x1c7f18', 'sadness'),\n",
       " ('0x1c7f21', 'joy'),\n",
       " ('0x1c7f24', 'joy'),\n",
       " ('0x1c7f29', 'anticipation'),\n",
       " ('0x1c7f2d', 'anticipation'),\n",
       " ('0x1c7f32', 'joy')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Print the result \n",
    "\n",
    "test_id = testdf.id\n",
    "def listOfTuples(test_id, y_test_pred): \n",
    "    return list(map(lambda x, y:(x,y), test_id, y_test_pred)) \n",
    "\n",
    "finalresult = (listOfTuples(test_id, y_test_pred))\n",
    "finalresult[0:10]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x1c7f17</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x1c7f18</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411967</td>\n",
       "      <td>0x38fe04</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411968</td>\n",
       "      <td>0x38fe06</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411969</td>\n",
       "      <td>0x38fe13</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411970</td>\n",
       "      <td>0x38fe14</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411971</td>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0             1\n",
       "0       0x1c7f0f       sadness\n",
       "1       0x1c7f12           joy\n",
       "2       0x1c7f13  anticipation\n",
       "3       0x1c7f17  anticipation\n",
       "4       0x1c7f18       sadness\n",
       "...          ...           ...\n",
       "411967  0x38fe04       sadness\n",
       "411968  0x38fe06           joy\n",
       "411969  0x38fe13           joy\n",
       "411970  0x38fe14           joy\n",
       "411971  0x38fe1b           joy\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Pass the result into panda dataframe and print the result to see\n",
    "dfresult = pd.DataFrame(finalresult) \n",
    "dfresult\n",
    "\n",
    "#Then assign header names and print the data to see\n",
    "dfresult.columns = ['id','emotion']\n",
    "dfresult\n",
    "\n",
    "#Then export the file \n",
    "exportcsv2 = dfresult.to_csv (r'C:\\Users\\User\\Data Mining_NTHU\\DMlab2x\\DM19-Lab2-Homework_Twitter - ทำไฟล์ตรงนี้ เวลาอัพไปอัพที่อื่น\\Dataset_Twitter_re30.csv', \n",
    "                               index = None, header=True) \n",
    "print (dfresult)\n",
    "\n",
    "submit score: 0.38481\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "'''\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                #('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "'''\n",
    "sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing data before feeding into the vectorizer\n",
    "#by combine hastag, text and score for both test and train dataset\n",
    "traincombined = traindf[['text','hashtag','score']].astype(str).apply('-'.join, axis=1)\n",
    "testcombined = testdf[['text','hashtag','score']].astype(str).apply('-'.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "\n",
    "train_countvec = count_vect.fit_transform(traincombined)\n",
    "test_countvec = count_vect.transform(testcombined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_countvec\n",
    "y_train = traindf['emotion']\n",
    "X_test = test_countvec\n",
    "y_test = testdf['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training the data\n",
    "sgd_model = sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['fear', 'joy', 'joy', 'anticipation', 'sadness', 'joy', 'sadness',\n",
       "       'surprise', 'trust', 'anticipation'], dtype='<U12')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict!\n",
    "%time\n",
    "y_train_pred_sgd_model = sgd_model.predict(X_train)\n",
    "\n",
    "X_test_pred_sgd_model = test_countvec\n",
    "y_test_pred_sgd_model = sgd_model.predict(test_countvec)\n",
    "\n",
    "## so we get the pred result\n",
    "y_test_pred_sgd_model[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.557639896040226\n"
     ]
    }
   ],
   "source": [
    "## Result Evaluation /accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train1 = accuracy_score(y_true=y_train, y_pred=y_train_pred_sgd_model)\n",
    "acc_test1 = accuracy_score(y_true=y_test, y_pred=y_test_pred_sgd_model)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train1, 15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0x1c7f0f', 'fear'),\n",
       " ('0x1c7f12', 'joy'),\n",
       " ('0x1c7f13', 'joy'),\n",
       " ('0x1c7f17', 'anticipation'),\n",
       " ('0x1c7f18', 'sadness'),\n",
       " ('0x1c7f21', 'joy'),\n",
       " ('0x1c7f24', 'sadness'),\n",
       " ('0x1c7f29', 'surprise'),\n",
       " ('0x1c7f2d', 'trust'),\n",
       " ('0x1c7f32', 'anticipation')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the result \n",
    "\n",
    "test_id = testdf.id\n",
    "def listOfTuples(test_id, y_test_pred_sgd_model): \n",
    "    return list(map(lambda x, y:(x,y), test_id, y_test_pred_sgd_model)) \n",
    "\n",
    "finalresult = (listOfTuples(test_id, y_test_pred_sgd_model))\n",
    "finalresult[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id       emotion\n",
      "0       0x1c7f0f          fear\n",
      "1       0x1c7f12           joy\n",
      "2       0x1c7f13           joy\n",
      "3       0x1c7f17  anticipation\n",
      "4       0x1c7f18       sadness\n",
      "...          ...           ...\n",
      "411967  0x38fe04       sadness\n",
      "411968  0x38fe06           joy\n",
      "411969  0x38fe13           joy\n",
      "411970  0x38fe14       disgust\n",
      "411971  0x38fe1b           joy\n",
      "\n",
      "[411972 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "#Pass the result into panda dataframe and print the result to see\n",
    "dfresult = pd.DataFrame(finalresult) \n",
    "dfresult\n",
    "\n",
    "#Then assign header names and print the data to see\n",
    "dfresult.columns = ['id','emotion']\n",
    "dfresult\n",
    "\n",
    "#Then export the file \n",
    "exportcsv2 = dfresult.to_csv (r'C:\\Users\\User\\Data Mining_NTHU\\DMlab2x\\DM19-Lab2-Homework_Twitter - ทำไฟล์ตรงนี้ เวลาอัพไปอัพที่อื่น\\Dataset_Twitter_re33.csv', \n",
    "                               index = None, header=True) \n",
    "print (dfresult)\n",
    "\n",
    "#submit score: 0.40721\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX_train = train_countvec\\ny_train = traindf['emotion']\\nX_test = test_countvec\\ny_test = testdf['emotion']\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#by combine hastag, text and score for both test and train dataset\n",
    "X_train = traindf[['text','hashtag','score']].astype(str).apply('-'.join, axis=1)\n",
    "y_train = traindf['emotion']\n",
    "X_test = testdf[['text','hashtag','score']].astype(str).apply('-'.join, axis=1)\n",
    "y_test = testdf['emotion']\n",
    "\n",
    "'''\n",
    "X_train = train_countvec\n",
    "y_train = traindf['emotion']\n",
    "X_test = test_countvec\n",
    "y_test = testdf['emotion']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning:\n",
      "\n",
      "Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['fear', 'sadness', 'disgust', 'anticipation', 'sadness', 'joy',\n",
       "       'sadness', 'anticipation', 'trust', 'joy'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict!\n",
    "%time\n",
    "y_train_pred_logreg_model = logreg_model.predict(X_train)\n",
    "\n",
    "#X_test_pred_logreg_model = test_countvec\n",
    "y_test_pred_logreg_model = logreg_model.predict(X_test)\n",
    "\n",
    "## so we get the pred result\n",
    "y_test_pred_logreg_model[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.805949313083666\n"
     ]
    }
   ],
   "source": [
    "## Result Evaluation /accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train1 = accuracy_score(y_true=y_train, y_pred=y_train_pred_logreg_model)\n",
    "acc_test1 = accuracy_score(y_true=y_test, y_pred=y_test_pred_logreg_model)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train1, 15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "%time\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0x1c7f0f', 'fear'),\n",
       " ('0x1c7f12', 'sadness'),\n",
       " ('0x1c7f13', 'disgust'),\n",
       " ('0x1c7f17', 'anticipation'),\n",
       " ('0x1c7f18', 'sadness'),\n",
       " ('0x1c7f21', 'joy'),\n",
       " ('0x1c7f24', 'sadness'),\n",
       " ('0x1c7f29', 'anticipation'),\n",
       " ('0x1c7f2d', 'trust'),\n",
       " ('0x1c7f32', 'joy')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the result \n",
    "\n",
    "test_id = testdf.id\n",
    "def listOfTuples(test_id, y_test_pred_logreg_model): \n",
    "    return list(map(lambda x, y:(x,y), test_id, y_test_pred_logreg_model)) \n",
    "\n",
    "finalresult = (listOfTuples(test_id, y_test_pred_logreg_model))\n",
    "finalresult[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id       emotion\n",
      "0       0x1c7f0f          fear\n",
      "1       0x1c7f12       sadness\n",
      "2       0x1c7f13       disgust\n",
      "3       0x1c7f17  anticipation\n",
      "4       0x1c7f18       sadness\n",
      "...          ...           ...\n",
      "411967  0x38fe04       disgust\n",
      "411968  0x38fe06           joy\n",
      "411969  0x38fe13           joy\n",
      "411970  0x38fe14       disgust\n",
      "411971  0x38fe1b           joy\n",
      "\n",
      "[411972 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Pass the result into panda dataframe and print the result to see\n",
    "dfresult = pd.DataFrame(finalresult) \n",
    "dfresult\n",
    "\n",
    "#Then assign header names and print the data to see\n",
    "dfresult.columns = ['id','emotion']\n",
    "dfresult\n",
    "\n",
    "#Then export the file \n",
    "exportcsv2 = dfresult.to_csv (r'C:\\Users\\User\\Data Mining_NTHU\\DMlab2x\\DM19-Lab2-Homework_Twitter - ทำไฟล์ตรงนี้ เวลาอัพไปอัพที่อื่น\\Dataset_Twitter_re34.csv', \n",
    "                               index = None, header=True) \n",
    "print (dfresult)\n",
    "\n",
    "#submit score: 0.43311\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec embedding and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "wv.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Memorial_Hospital',\n",
       " 'Seniors',\n",
       " 'memorandum',\n",
       " 'elephant',\n",
       " 'Trump',\n",
       " 'Census',\n",
       " 'pilgrims',\n",
       " 'De',\n",
       " 'Dogs',\n",
       " '###-####_ext',\n",
       " 'chaotic',\n",
       " 'forgive',\n",
       " 'scholar',\n",
       " 'Lottery',\n",
       " 'decreasing',\n",
       " 'Supervisor',\n",
       " 'fundamentally',\n",
       " 'Fitness',\n",
       " 'abundance',\n",
       " 'Hold']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "list(islice(wv.vocab, 13030, 13050))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        # FIXME: remove these examples in pre-processing\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#by combine hastag, text and score for both test and train dataset\n",
    "#X_train = traindf[['text','hashtag','score']].astype(str).apply('-'.join, axis=1)\n",
    "X_train = traindf['text']\n",
    "y_train = traindf['emotion']\n",
    "#X_test = testdf[['text','hashtag','score']].astype(str).apply('-'.join, axis=1)\n",
    "X_test = testdf['text']\n",
    "y_test = testdf['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train, test = train_test_split(df, test_size=0.3, random_state = 42)\n",
    "test_tokenized = testdf.apply(lambda r: w2v_tokenize_text(r['text']), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = traindf.apply(lambda r: w2v_tokenize_text(r['text']), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning:\n",
      "\n",
      "Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.vectors_norm instead).\n",
      "\n",
      "WARNING:root:cannot compute similarity with no input ['tgfad', '...', 'God👆st']\n",
      "WARNING:root:cannot compute similarity with no input [\"happy'self\"]\n",
      "WARNING:root:cannot compute similarity with no input ['ORNAMENT-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-', 'SILVER-CASE-FOR-IPHONE-6-6S-/152641558980']\n",
      "WARNING:root:cannot compute similarity with no input ['AwesometimeinHispresence', \"God'speople\", 'Beautifulpeople']\n",
      "WARNING:root:cannot compute similarity with no input ['DFunctionaL_', 'TRUST.THE.PROCESS']\n",
      "WARNING:root:cannot compute similarity with no input ['Happy👌black♥', 'day.💡😆😆😆😆😆😆']\n",
      "WARNING:root:cannot compute similarity with no input ['Happy.Birthday.pita.ji']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'K4-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237741']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'T2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260316']\n",
      "WARNING:root:cannot compute similarity with no input ['SEETHROUGH-', 'COOL-', '3D-', 'DESIGN-', 'CHROME-', 'SILVER-', 'CASE-FOR-IPHONE-6S-PLUS-/152676479659']\n",
      "WARNING:root:cannot compute similarity with no input ['crappy.girlfriend']\n",
      "WARNING:root:cannot compute similarity with no input ['WannaFlexOnMyWrestAndThenIPutSomeIceOnIt', 'ImmaMakeHerWetAndThenMaybePutSomeRiceOnIt', 'wtf😂']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'Y1-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237632']\n",
      "WARNING:root:cannot compute similarity with no input ['Idubbbz', 'idubbbz', 'wtf•youtube•are•you•fucking•serious•', 'with•this•shit']\n",
      "WARNING:root:cannot compute similarity with no input ['3D-', 'PRINTED-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'TPU-ROSE-GOLD-CASE-FOR-IPHONE-6-6S-/152641565058']\n",
      "WARNING:root:cannot compute similarity with no input ['C-', 'Black-', 'amp-', 'Clear-', 'Nice-', 'Creative-', 'Design-Chrome-iPhone-7-6S-Plus-5-SE-case-/152641535690']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'X4-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237605']\n",
      "WARNING:root:cannot compute similarity with no input ['dearclarissa', 'love-the-one-you', 're-with']\n",
      "WARNING:root:cannot compute similarity with no input ['OF-', 'SATURN-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640241862']\n",
      "WARNING:root:cannot compute similarity with no input ['Love-Yourself']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'G2-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237669']\n",
      "WARNING:root:cannot compute similarity with no input ['BOLD-', 'DENVER-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640269044']\n",
      "WARNING:root:cannot compute similarity with no input ['angry-moments']\n",
      "WARNING:root:cannot compute similarity with no input ['Goodmorning🙏🏽', 'Blessed✝️']\n",
      "WARNING:root:cannot compute similarity with no input ['RepJerryNadler', 'RepJohnConyers', 'HouseDemocrats', 'StateDept', 'realDonaldTrump', 'RepRoKhanna', 'dumb-ocrats']\n",
      "WARNING:root:cannot compute similarity with no input ['RealJamesWoods', 'Special-Interest']\n",
      "WARNING:root:cannot compute similarity with no input ['Goodmorning😂😂', 'Excited😊😊']\n",
      "WARNING:root:cannot compute similarity with no input ['YEEEEEEAAAAAASSSSS', '☺️😎🙌🏻❤️', 'MCGREGORisA🙌🏻BEAST', 'WHATisHEgoingTOdoNEXXXT😱', 'BALLSofSTEEL', 'MAD‼️RESPECT']\n",
      "WARNING:root:cannot compute similarity with no input ['HAPPY-CHILDRENs-DAY', 'CHILDRENSDAY-INDIA']\n",
      "WARNING:root:cannot compute similarity with no input ['POTTER-', 'INSPIRED-', 'LIGHTNING-', 'SCAR-', 'DESIGN-', 'ROSE-', 'GOLD-FOR-IPHONE-7-6-PLUS-/152640256967']\n",
      "WARNING:root:cannot compute similarity with no input ['Joy🔥', 'PickYouUp🔥ft', 'areece', 'rikyrickworld', 'Ep🔥🔥']\n",
      "WARNING:root:cannot compute similarity with no input ['💖❤LOVE💚LOVE💜LOVE💙LOVE💛LOVE💖', 'LOVE💖LOVE💛LOVE💙LOVE💜LOVE💚LOVE❤LOVE💚LOVE💜LOVE💙LOVE💛LOVE💖', 'LOVE💖LOVE💛LOVE💙LOVE💜LOVE💚LOVE❤LOVE💚LOVE💜LOVE💙LOVE💛LOVE❤💖']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'F1-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237676']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'L4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559177']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'X1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260017']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'L1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260036']\n",
      "WARNING:root:cannot compute similarity with no input ['happy-to-start-my-511th-film-anupam-kher-96209']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'M2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559105']\n",
      "WARNING:root:cannot compute similarity with no input ['girlfriendloved', 'arjunk26', 'Ignored🙄🙄🙄supremely', 'ignored😏😏😏']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'X4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260155']\n",
      "WARNING:root:cannot compute similarity with no input ['JCPOA', 'PersianGulf', 'for-ever']\n",
      "WARNING:root:cannot compute similarity with no input ['happy-Destruction']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'E2-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237783']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'W1-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640241965']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'J2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584157']\n",
      "WARNING:root:cannot compute similarity with no input ['BOHO-', 'STYLE-', 'COOL-', 'MAGMA-', 'SERIES-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237797']\n",
      "WARNING:root:cannot compute similarity with no input ['FAITH×HOLiC']\n",
      "WARNING:root:cannot compute similarity with no input ['GovtChurchMan=', 'GodsBride~Ep5:32Rv20:6', 'GodsWallet=', 'AllThingsInCommon', 'NOTmyWORDS', 'IJustReadBibleToU', 'Shame=', 'SameWordPastorsNeverRead~Ac4:32']\n",
      "WARNING:root:cannot compute similarity with no input ['scared/nervous']\n",
      "WARNING:root:cannot compute similarity with no input ['Bounceyboyy', 'chill-streams']\n",
      "WARNING:root:cannot compute similarity with no input ['goodmorning', 'blessed🙏🏽']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'F2-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237596']\n",
      "WARNING:root:cannot compute similarity with no input ['HoarseWisperer', 'pray-have']\n",
      "WARNING:root:cannot compute similarity with no input ['LINES-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'TITANIUM-', 'BLACK-CASE-FOR-IPHONE-7-6-PLUS-/152641532014']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'V2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641587002']\n",
      "WARNING:root:cannot compute similarity with no input ['WOLF-', 'COOL-', '3D-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641560415']\n",
      "WARNING:root:cannot compute similarity with no input ['WOLF-', 'COOL-', '3D-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640241864']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'H4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559223']\n",
      "WARNING:root:cannot compute similarity with no input ['STRIKE-', 'COOL-', '3D-', 'MAGMA-', 'SERIES-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237680']\n",
      "WARNING:root:cannot compute similarity with no input ['DISNEY-', 'QUOTE-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640257107']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cannot compute similarity with no input ['Happy-Defence-Day🚀✌', '6th-september💞🚁🚀', 'Pak-Zindabad❤']\n",
      "WARNING:root:cannot compute similarity with no input ['SKULL-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-', 'SILVER-CASE-FOR-IPHONE-6S-PLUS-/152641575557']\n",
      "WARNING:root:cannot compute similarity with no input ['happy-friendship_day_to_all_my_twitter_friends']\n",
      "WARNING:root:cannot compute similarity with no input ['HOPE☆LOVE1stAnniversary']\n",
      "WARNING:root:cannot compute similarity with no input ['Saturdaymorning', 'Afternoonbrunch🍖', 'familyfunday👪👪', 'Blessedday✌', \"God'skid☺\"]\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'G2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559238']\n",
      "WARNING:root:cannot compute similarity with no input ['happy-halloween']\n",
      "WARNING:root:cannot compute similarity with no input ['~BaBy_Ash', 'Love..God']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'V2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260304']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'H2-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237762']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'L3-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237782']\n",
      "WARNING:root:cannot compute similarity with no input ['STATE-', 'BUILDING-', 'SEETHROUGH-', 'COOL-', 'DESIGN-', 'ROSE-', 'GOLD-CASE-FOR-IPHONE-6-6S-/152641560391']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'X3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260197']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'G4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260013']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'K2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584253']\n",
      "WARNING:root:cannot compute similarity with no input ['ARROWS-', 'POINTING-', 'DOWN-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-7-6-PLUS-/152640256911']\n",
      "WARNING:root:cannot compute similarity with no input ['singlelife', 'love/hate']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'T2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559046']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'C2-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237635']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'W2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641586877']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'M4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584161']\n",
      "WARNING:root:cannot compute similarity with no input ['StitchSSB', 'sad-nigga-hours']\n",
      "WARNING:root:cannot compute similarity with no input ['EARS-', 'SCETCH-', 'ON-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-ROSE-GOLD-CASE-FOR-IPHONE-7-6-PLUS-/152640247282']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'Z4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260154']\n",
      "WARNING:root:cannot compute similarity with no input ['16', 'and', 'runnin💰🏃💯', 'blessed🙏']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'Z3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260275']\n",
      "WARNING:root:cannot compute similarity with no input ['DPoorRepublican', 'RealAlexJones', '^triggered', 'lost^', '^dreams', 'and', 'Trump2020']\n",
      "WARNING:root:cannot compute similarity with no input ['bannerite', 'davidaxelrod', 'squirrel🤡', 'sad💩legacy', 'of', 'bot45']\n",
      "WARNING:root:cannot compute similarity with no input ['BakeJailey7', 'jeffreybailey7', 'special💕timesloveit']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'S3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641586911']\n",
      "WARNING:root:cannot compute similarity with no input ['r.i.p', 'welcome-to-the-epic-general', 'fuck-2017.5']\n",
      "WARNING:root:cannot compute similarity with no input ['😍Choose', 'HAPPY😍']\n",
      "WARNING:root:cannot compute similarity with no input ['spooky👿Halloween💀fact', '☠my️👻initials🎃are🕯JQ️⚰️']\n",
      "WARNING:root:cannot compute similarity with no input ['Coffee+nfak+cold+rain=', 'perfect💯💞']\n",
      "WARNING:root:cannot compute similarity with no input ['░╔══╣╣┈', '┈┈┈', 'E┛', '░║░░░║░░░░█░█░█░░', 'Obama╩▓', '▔╲╱┈┈┈┈┈┈┈┈╭▏╭╮┊┊┊┊┊offeet', '░░☺║', 'LOVE┊SNALLOVE╔══╦══╠═']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'M1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260261']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'A1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640269136']\n",
      "WARNING:root:cannot compute similarity with no input ['slamofficial', 'mixmarathon', 'weekendvibes', 'love-iT']\n",
      "WARNING:root:cannot compute similarity with no input ['Pray.Spain']\n",
      "WARNING:root:cannot compute similarity with no input ['JoeGiglioSports', 'welcome-back-kotter']\n",
      "WARNING:root:cannot compute similarity with no input ['OF-', 'SHAPES-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237614']\n",
      "WARNING:root:cannot compute similarity with no input ['esischwiesisch', 'LOVE=LOVE=LOVE=']\n",
      "WARNING:root:cannot compute similarity with no input ['LOVE☆Queen']\n",
      "WARNING:root:cannot compute similarity with no input ['ConnyMikateko', 'DonaldMbhiza', 'Munghana', '326Thwii', \"God'swindow\", 'Connizer', '😃😃😃😃']\n",
      "WARNING:root:cannot compute similarity with no input ['AlexHolleyFOX29', 'PRETTY-IN-PINK-💟💟💟..', 'FROM-DARRELL']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'A1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584273']\n",
      "WARNING:root:cannot compute similarity with no input ['Blue👃PitBull']\n",
      "WARNING:root:cannot compute similarity with no input ['AlDescuido😄😃', 'Happy💕Happy😍😍']\n",
      "WARNING:root:cannot compute similarity with no input ['Love-Him/him/her-and-not-just-what-He/he/she-has']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'M2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260213']\n",
      "WARNING:root:cannot compute similarity with no input ['akaworldwide', \"God's_work\"]\n",
      "WARNING:root:cannot compute similarity with no input ['L-', 'Black-', 'amp-', 'Clear-', 'Nice-', 'Creative-', 'Design-Chrome-iPhone-7-6S-Plus-5-SE-case-/152641535793']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'W3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559147']\n",
      "WARNING:root:cannot compute similarity with no input ['WilliamSingePH', 'Rush💙💙', 'inlove']\n",
      "WARNING:root:cannot compute similarity with no input ['pretty🐱matter‼️']\n",
      "WARNING:root:cannot compute similarity with no input ['COOL-', 'MAGMA-', 'SERIES-', 'RED-', 'COLOR-', 'SHIFTING-', 'CASE-FOR-IPHONE-7-6-PLUS-/152640237622']\n",
      "WARNING:root:cannot compute similarity with no input ['Think-', 'Believe-', 'Change-', 'Develop-Think']\n",
      "WARNING:root:cannot compute similarity with no input ['RED-', 'BLUE-', 'CLEAR-', 'USA-', 'FLAG-', 'DESIGN-', 'CLEAR-CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640241914']\n",
      "WARNING:root:cannot compute similarity with no input ['Bamagurl48', 'LOVE.YOU', 'WORKAHOLIC']\n",
      "WARNING:root:cannot compute similarity with no input ['MANDALAS-', 'W-', 'LOGO-', 'CIRCLE-', '3D-', 'COOL-', 'DESIGN-ROSE-GOLD-CASE-FOR-IPHONE-6-6S-/152641561473']\n",
      "WARNING:root:cannot compute similarity with no input ['POTTER-', 'ICON-', 'ON-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-ROSE-GOLD-CASE-FOR-IPHONE-6-6S-/152641561402']\n",
      "WARNING:root:cannot compute similarity with no input ['NamCinema', 'NimmaYash', 'fabUloUs-looking..', '**BOSS**']\n",
      "WARNING:root:cannot compute similarity with no input ['Mohona36207730', 'YourKoel', 'Beautiful..', 'eyes..']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'F3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260211']\n",
      "WARNING:root:cannot compute similarity with no input ['timothysykes', 'Cool-boo-rate']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'A1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-TPU-CASE-FOR-IPHONE-7-/152641594361']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'B4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641558965']\n",
      "WARNING:root:cannot compute similarity with no input ['MANDALA-', 'COOL-', '3D-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260139']\n",
      "WARNING:root:cannot compute similarity with no input ['God-to-behere']\n",
      "WARNING:root:cannot compute similarity with no input ['GLASSES-', 'MUSTACHE-', 'DESIGN-', 'BLACK-', 'GOLD-', 'CASE-', 'FOR-IPHONE-6S-PLUS-GLASS-/152641564955']\n",
      "WARNING:root:cannot compute similarity with no input ['OCEAN-', 'WAVES-', 'SEETHROUGH-', 'COOL-', '3D-', 'DESIGN-', 'ROSE-GOLD-CASE-FOR-IPHONE-7-6-PLUS-/152640241880']\n",
      "WARNING:root:cannot compute similarity with no input ['beautiful-day-it-is']\n",
      "WARNING:root:cannot compute similarity with no input ['TIGER-', 'DESIGN-', '24K-', 'SERIES-', 'PREMIUM-', 'CASE-', 'FOR-IPHONE-6-6S-TEMPERED-GLASS-/152641539113']\n",
      "WARNING:root:cannot compute similarity with no input ['llcoolj', 'GendarmeCologne', '💜★', '💜★', '💜★', '💎✰', '💎✰', '💎✰', '💜★', '💜★', '💜★~', '💎✰', '💎✰', '💎✰', 'Gendarme✨Cologne~', '💟◈', '💟◈', '💟◈', 'Love✱', 'It~❥✨❥❥~']\n",
      "WARNING:root:cannot compute similarity with no input ['blessed-to-still-get-lovely-work-rishi-kapoor-93710']\n",
      "WARNING:root:cannot compute similarity with no input ['welcome-base2']\n",
      "WARNING:root:cannot compute similarity with no input ['Cagatay4ever', 'Aras_B_iynemli', 'cagatayulusoyy', 'happy-birthayy']\n",
      "WARNING:root:cannot compute similarity with no input ['POLKA-', 'DOTS-', 'COOL-', 'MAGMA-', 'RED-', 'COLOR-', 'SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-DDDDD-/152640237658']\n",
      "WARNING:root:cannot compute similarity with no input ['LOVE👌Love💋Love📿', 'Blk💎💋']\n",
      "WARNING:root:cannot compute similarity with no input ['love💖💖💖hurts']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'D3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559233']\n",
      "WARNING:root:cannot compute similarity with no input ['H-', 'Black-', 'amp-', 'Clear-', 'Nice-', 'Creative-', 'Design-Chrome-iPhone-7-6-S-Plus-5-SE-case-/152676479518']\n",
      "WARNING:root:cannot compute similarity with no input ['dbongino', 'Fricking', 'Beautiful🗽✨', 'ForceOptions', 'ReneeNal']\n",
      "WARNING:root:cannot compute similarity with no input ['AM-', 'STRONG-', 'QUOTE-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641560427']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'T2-', 'COOL-', '3D-', 'DESIGN-', 'WITH-', 'CLEAR-ROSE-GOLD-CASE-FOR-IPHONE-6-6S-/152641561466']\n",
      "WARNING:root:cannot compute similarity with no input ['POINTING-', 'DOWN-', 'MAGMA-', 'RED-', 'COLOR-', 'SHIFTING-', 'CASE-FOR-IPHONE-7-6-PLUS-/152640237662']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'Y4-', 'COOL-', 'SILVER-', 'IPHONE-', '6S-', 'PLUS-CASE-amp-TEMPERED-GLASS-PROTECTOR-/152641568296']\n",
      "WARNING:root:cannot compute similarity with no input ['love.bob.corker']\n",
      "WARNING:root:cannot compute similarity with no input ['Goodnight😞💕', 'sad😭']\n",
      "WARNING:root:cannot compute similarity with no input ['IssaRae', 'YvonneOrji', 'OKAYEEEE', 'iamcardib', 'BLESSED❗️🙏🏾']\n",
      "WARNING:root:cannot compute similarity with no input ['lost.soul/black.lungs']\n",
      "WARNING:root:cannot compute similarity with no input ['AND-', 'BLUE-', 'BOHO-', 'STYLE-', 'MAGMA-', 'BLACK-', 'RED-COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237707']\n",
      "WARNING:root:cannot compute similarity with no input ['happy.with.how.far.ive.come.2017']\n",
      "WARNING:root:cannot compute similarity with no input ['Love-tunelive2017']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'A4-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237592']\n",
      "WARNING:root:cannot compute similarity with no input ['Nighttt', 'Pray💯🙏']\n",
      "WARNING:root:cannot compute similarity with no input ['positive-morning✨']\n",
      "WARNING:root:cannot compute similarity with no input ['WHAT-', 'YOU-', 'LOVE-', 'QUOTE-', 'DESIGN-', 'BLACK-', 'RED-COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640241973']\n",
      "WARNING:root:cannot compute similarity with no input ['love-army', 'YoutubeHelpRohingya', 'LovearmyforRohingya']\n",
      "WARNING:root:cannot compute similarity with no input ['LusandaBeja_', \"'s\", 'performance😇🙌🙏', 'Blessed🙌', 'adecateofgospel', 'ONEGospel']\n",
      "WARNING:root:cannot compute similarity with no input ['Dream-Big', 'Start-Small']\n",
      "WARNING:root:cannot compute similarity with no input ['Love☆Queen']\n",
      "WARNING:root:cannot compute similarity with no input ['theashwaniarora', 'True😇😇', 'motivated😇']\n",
      "WARNING:root:cannot compute similarity with no input ['roadpoliceBCH', 'down-to-the-bump-stops']\n",
      "WARNING:root:cannot compute similarity with no input ['J-', 'Black-', 'amp-', 'Clear-', 'Nice-', 'Creative-', 'Design-Chrome-iPhone-7-6-S-Plus-5-SE-case-/152676479432']\n",
      "WARNING:root:cannot compute similarity with no input [\"God'sNotDead\"]\n",
      "WARNING:root:cannot compute similarity with no input ['RIPDellaReese', 'broken-hearted']\n",
      "WARNING:root:cannot compute similarity with no input ['Yerm', '❤️', 'Bizzle🖤', 'Blessed🙏🏾']\n",
      "WARNING:root:cannot compute similarity with no input ['BLUE-', 'PAISLEY-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260324']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'K3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-TPU-CASE-FOR-IPHONE-7-/152641594302']\n",
      "WARNING:root:cannot compute similarity with no input ['AND-', 'CHILL-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641556824']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'X3-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237760']\n",
      "WARNING:root:cannot compute similarity with no input ['PAISLEY-', 'COOL-', '3D-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641586843']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'Y3-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640241992']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'G3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584168']\n",
      "WARNING:root:cannot compute similarity with no input ['YoliMayor', 'AMAZING-voice']\n",
      "WARNING:root:cannot compute similarity with no input ['Believe💪🇮🇪COYBIG']\n",
      "WARNING:root:cannot compute similarity with no input ['GENERATIONS-', 'SILLHOUETTES-', 'DESIGN-', 'BLACK-', 'GOLD-', 'CASE-', 'FOR-IPHONE-6S-GLASS-/152641556613']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'T1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559064']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'W2-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640241936']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'X2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260251']\n",
      "WARNING:root:cannot compute similarity with no input ['workit', 'into-reality', 'happy-writing']\n",
      "WARNING:root:cannot compute similarity with no input ['Happy😊25th😘Birthday🎁🎊🎂Girl👯', 'Selena💋Gomez']\n",
      "WARNING:root:cannot compute similarity with no input ['RA_Parker', '*/Gamers*', 'Hungry🍽']\n",
      "WARNING:root:cannot compute similarity with no input ['MANDALA-', 'COOL-', '3D-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559128']\n",
      "WARNING:root:cannot compute similarity with no input ['30', 'lucky/deys']\n",
      "WARNING:root:cannot compute similarity with no input ['BLUE-', 'PAISLEY-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640242046']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'L3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260059']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'C1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260254']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'P3-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237606']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'M4-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237777']\n",
      "WARNING:root:cannot compute similarity with no input ['H-', 'Black-', 'amp-', 'Clear-', 'Nice-', 'Creative-', 'Design-Chrome-iPhone-7-6-S-Plus-5-SE-case-/152641535870']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'G1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559192']\n",
      "WARNING:root:cannot compute similarity with no input ['amazing🤠trip🚗', 'with_my_father👨\\u200d']\n",
      "WARNING:root:cannot compute similarity with no input ['👍👌😂', 'Better🌵🔫']\n",
      "WARNING:root:cannot compute similarity with no input ['Sisters❤️', 'blessed🙌🏻']\n",
      "WARNING:root:cannot compute similarity with no input ['Rob_Co1eman15', 'Love=badforhealthhumans']\n",
      "WARNING:root:cannot compute similarity with no input ['FLOWER-', 'SEETHROUGH-', 'COOL-', '3D-', 'DESIGN-', 'WITH-', 'ROSE-GOLD-CASE-FOR-IPHONE-6-6S-/152641560388']\n",
      "WARNING:root:cannot compute similarity with no input ['SEETHROUGH-', 'COOL-', '3D-', 'PRINTED-', 'DESIGN-', 'WITH-', 'ROSE-GOLD-CASE-FOR-IPHONE-7-6-PLUS-/152640241840']\n",
      "WARNING:root:cannot compute similarity with no input ['E_girls', 'Mステ', 'ツインタワー', '美脚ダンス', 'Love☆Queen']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'I3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559088']\n",
      "WARNING:root:cannot compute similarity with no input ['DavidCornDC', 'LindaAnnecrawf3', 'For~reals']\n",
      "WARNING:root:cannot compute similarity with no input ['POINTING-', 'DOWN-', 'BLACK-', 'RED-', 'COLOR-', 'SHIFTING-', 'CASE-FOR-IPHONE-7-6-PLUS-/152640242042']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'A1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559104']\n",
      "WARNING:root:cannot compute similarity with no input ['Meh-Clipse']\n",
      "WARNING:root:cannot compute similarity with no input ['PRAY.FOR.TEXAS']\n",
      "WARNING:root:cannot compute similarity with no input ['amazing✔️z↩️force']\n",
      "WARNING:root:cannot compute similarity with no input ['艦これから逃げる', '謙介何考えてんだ', 'どうしてくれんのこれ', 'love＆peace', '終わり閉廷解散！']\n",
      "WARNING:root:cannot compute similarity with no input ['DISNEY-', 'QUOTE-', '3D-', 'PRINTED-', 'COOL-', 'DESIGN-', 'TITANIUM-BLACK-CASE-FOR-IPHONE-7-6-PLUS-/152641532060']\n",
      "WARNING:root:cannot compute similarity with no input ['WannaFlexOnMyWristAndThenIPutSomeIceOnIt', 'ImmaMakeHerWetAndMaybePutSomeIceOnIt', 'wtf😂']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'T3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260302']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'R4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641586996']\n",
      "WARNING:root:cannot compute similarity with no input ['K-', 'Black-', 'amp-', 'Clear-', 'Nice-', 'Creative-', 'Design-Chrome-iPhone-7-6-S-Plus-5-SE-case-/152641535821']\n",
      "WARNING:root:cannot compute similarity with no input ['love-exercising-in-lingerie-hailey-baldwin-95402']\n",
      "WARNING:root:cannot compute similarity with no input ['LateUp😎😊😎', 'Pagod😭😱😛', 'Haggard😂🤣😛', 'Pero..', 'Cool😎💪🏻🍺👠💋', '..', 'HappyTimes😊😊😊', '..', 'GoodTimes😎😎😎']\n",
      "WARNING:root:cannot compute similarity with no input ['SKULL-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'TITANIUM-', 'BLACK-CASE-FOR-IPHONE-7-6-PLUS-/152641531818']\n",
      "WARNING:root:cannot compute similarity with no input ['BLessed👼']\n",
      "WARNING:root:cannot compute similarity with no input ['EGYPTIAN-', 'SYMBOLS-', 'DESIGN-', 'BLACK-', 'GOLD-', 'CASE-', 'FOR-IPHONE-6S-PLUS-GLASS-/152641564843']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'Q2-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237720']\n",
      "WARNING:root:cannot compute similarity with no input ['Love/Hate']\n",
      "WARNING:root:cannot compute similarity with no input ['LOVE💙TRUMPS', 'HATE.☮️💙☮️💙☮️💙☮️💙☮️💙☮️💙☮️💙☮️💙☮️💙☮️💙☮️💙☮️💙☮️💙☮️💙☮️💙☮️💙']\n",
      "WARNING:root:cannot compute similarity with no input ['NIGHT-', 'SKY-', 'Black-', 'amp-', 'Clear-', 'Cool-', 'Design-Chrome-iPhone-7-6-S-Plus-5-SE-case-/152676479556']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'F3-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237679']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'Q1-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237716']\n",
      "WARNING:root:cannot compute similarity with no input ['ShenelMeneses', 'yeah..', 'Blessed..']\n",
      "WARNING:root:cannot compute similarity with no input ['In👏1923👏1924👏the👏party👏was👏', 'overwhelmed👏by👏the👏flood👏of👏so👏called👏discussion👏against👏Trotskyism']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'R2-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640242026']\n",
      "WARNING:root:cannot compute similarity with no input ['PRAYER-', 'QUOTE-', 'COOL-', 'DESIGN-', 'COOL-', 'COOL-', 'DESIGN-ROSE-GOLD-CASE-FOR-IPHONE-6-6S-/152641561451']\n",
      "WARNING:root:cannot compute similarity with no input ['Ashleyeverett21', \"👏there's👏a👏copy👏in👏my👏notes👏\", 'blessed👏']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'F1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260145']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'P3-', 'COOL-', '3D-', 'DESIGN-', 'WITH-', 'CLEAR-ROSE-GOLD-CASE-FOR-IPHONE-7-6-PLUS-/152640247303']\n",
      "WARNING:root:cannot compute similarity with no input ['U2-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-', 'SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640242074']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'A2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559071']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'S2-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237584']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'I4-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237667']\n",
      "WARNING:root:cannot compute similarity with no input ['ShinobiNinja', 'Numb/Encore', 'R.I.P']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'G4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584251']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'T4-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640242066']\n",
      "WARNING:root:cannot compute similarity with no input ['RajivDhall', 'Hellooo😍💖', 'Love😍']\n",
      "WARNING:root:cannot compute similarity with no input ['DISNEY-', 'QUOTE-', 'COOL-', 'MAGMA-', 'SERIES-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237690']\n",
      "WARNING:root:cannot compute similarity with no input [\"lucky'sdaily\"]\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'C1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584181']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'H1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-TPU-CASE-FOR-IPHONE-7-/152641594310']\n",
      "WARNING:root:cannot compute similarity with no input ['shazzzBag', 'love-machines']\n",
      "WARNING:root:cannot compute similarity with no input ['nickyt206', 'Glad-You', 're-the-one-fan-who-attended-that-school']\n",
      "WARNING:root:cannot compute similarity with no input ['BTSHighligthReel', 'BTS_twt', 'LOVE-YOURSELF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'R2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260056']\n",
      "WARNING:root:cannot compute similarity with no input ['God=less', 'Anointing=less', 'InnerCourt=less', 'AnointingOil=less', 'GodsEquality=less', 'AllThingsInCommon=less', 'But=', 'UGotGodsTithe=', 'UMock=Ac4:32']\n",
      "WARNING:root:cannot compute similarity with no input ['goodeves😘', 'HAPPY😇']\n",
      "WARNING:root:cannot compute similarity with no input ['E-', 'Black-', 'amp-', 'Clear-', 'Nice-', 'Creative-', 'Design-Chrome-iPhone-7-6-S-Plus-5-SE-case-/152676479640']\n",
      "WARNING:root:cannot compute similarity with no input ['📍kinamat', 'chill🥂']\n",
      "WARNING:root:cannot compute similarity with no input ['GRADIENT-', 'TURQUOIS-', 'BLUE-', 'DESIGN-', 'TPU-', 'ROSE-', 'GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584140']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'M1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584329']\n",
      "WARNING:root:cannot compute similarity with no input ['G-', 'Black-', 'amp-', 'Clear-', 'Nice-', 'Creative-', 'Design-Chrome-iPhone-7-6-S-Plus-5-SE-case-/152641535829']\n",
      "WARNING:root:cannot compute similarity with no input ['highprincesslo', 'Lolol', 'guilty🙋🏼\\u200d♀️']\n",
      "WARNING:root:cannot compute similarity with no input ['ImStill🆙lookin', 'cute💃🏻💃🏻💃🏻💃🏻💃🏻💃🏻✌🏼😎']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'X2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559198']\n",
      "WARNING:root:cannot compute similarity with no input ['DungHill~Ph3:8', 'WhyUResisting=', 'FullOf', 'Dung~Rm1:28', 'UResistedGodSoLong', 'Ur=', 'Stiffnecked+', 'Constipated~Ac7:51', 'Spoiled~Jr4:13=', 'BastardsOfGrace']\n",
      "WARNING:root:cannot compute similarity with no input ['LOVE/HATE']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'D4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584320']\n",
      "WARNING:root:cannot compute similarity with no input ['AND-', 'CHILL-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237711']\n",
      "WARNING:root:cannot compute similarity with no input ['GRADIENT-', 'TURQUOIS-', 'BLUE-', 'DESIGN-', 'CHROME-', 'SILVER-', 'CASE-FOR-IPHONE-7-6-PLUS-/152640269068']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'G1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260230']\n",
      "WARNING:root:cannot compute similarity with no input ['angry-Little', 'liberals😂']\n",
      "WARNING:root:cannot compute similarity with no input ['FuerzaChapecoense', 'For¢aChape']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'G4-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237682']\n",
      "WARNING:root:cannot compute similarity with no input ['GoodMorning', 'Blessed✨']\n",
      "WARNING:root:cannot compute similarity with no input ['bynsny', \"God'sArmy\", 'TrumpTrain']\n",
      "WARNING:root:cannot compute similarity with no input ['HappyBirthdayVirat', 'happy.birthday.viratkohlie']\n",
      "WARNING:root:cannot compute similarity with no input ['AwesomemomentsinHisPresence', 'YouaretheAirWeBreathe', \"God'speople\", 'Beautifulpeople']\n",
      "WARNING:root:cannot compute similarity with no input ['lucky-to-get-offered-variety-of-films-says-akshaye-khanna-82742']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'S1-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640241974']\n",
      "WARNING:root:cannot compute similarity with no input ['Proud•to•be•a•Martinator🤘🏽❤️', 'emartineeez', 'imartinezp_']\n",
      "WARNING:root:cannot compute similarity with no input ['SKULL-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'TITANIUM-', 'BLACK-CASE-FOR-IPHONE-7-6-PLUS-/152641531879']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'X2-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237628']\n",
      "WARNING:root:cannot compute similarity with no input ['BLACK-', 'NEW-', 'MEXICO-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-ROSE-GOLD-CASE-FOR-IPHONE-7-6-PLUS-/152640247237']\n",
      "WARNING:root:cannot compute similarity with no input ['TheRickWilson', 'Rage-iscope']\n",
      "WARNING:root:cannot compute similarity with no input ['goodmorning☺️', 'blessed🙌🏾']\n",
      "WARNING:root:cannot compute similarity with no input ['3XFederal🔥🔥🔥Ughh', 'Ugggh', 'Ughhh', 'InSecure😎', 'MoneyBaggYo']\n",
      "WARNING:root:cannot compute similarity with no input ['lucky/deys']\n",
      "WARNING:root:cannot compute similarity with no input ['hurricanetrack', \"God'sArtWork\"]\n",
      "WARNING:root:cannot compute similarity with no input ['allabouthisPresence', \"God'speople\", 'Beautifulpeople']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'W3-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640241942']\n",
      "WARNING:root:cannot compute similarity with no input ['GOODMORNING', 'BLESSED😇']\n",
      "WARNING:root:cannot compute similarity with no input ['Happiest5WordSentence', \"God'sPromisesAlwaysComeTrue\"]\n",
      "WARNING:root:cannot compute similarity with no input ['AND-', 'MOON-', 'Black-', 'amp-', 'Clear-', 'Cool-', 'Space-Design-Chrome-iPhone-7-6S-Plus-5-se-case-/152676479535']\n",
      "WARNING:root:cannot compute similarity with no input ['SundayFamilyBond😌💓', 'Blessed😇']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'E1-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237565']\n",
      "WARNING:root:cannot compute similarity with no input ['TGFAD♥️', 'blessed..']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'M1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559114']\n",
      "WARNING:root:cannot compute similarity with no input ['LOVE-', 'NY-', 'NEW-', 'YORK-', 'CITY-', 'NYC-', 'VIEW-Premium-Chrome-iPhone-7-6-S-Plus-se-case-/152676479547']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'K3-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237661']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'H4-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237757']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'L1-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237559']\n",
      "WARNING:root:cannot compute similarity with no input ['mashallah', 'TGiF👊🏿', 'HappyNewMonth🇰🇪', 'GivThanks✊🏿', 'JAHplans🔝an', 'HouseHunting🔥', 'blessed🙏🏿settinz', 'outdeh', 'w/', 'TeamZUFAN™']\n",
      "WARNING:root:cannot compute similarity with no input ['Nena___sa', 'NakuulMehta', 'SurbhiChandna', 'Wowwwwwe', 'Beautiful😍😍😘😘']\n",
      "WARNING:root:cannot compute similarity with no input ['Larrypolya22', 'JacobAWohl', \"God'sChosenPeople\"]\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'J4-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237657']\n",
      "WARNING:root:cannot compute similarity with no input ['realDonaldTrump', 'TEAM.TRUMP', 'God.Sent😇']\n",
      "WARNING:root:cannot compute similarity with no input ['HBDGurujiTrivikram', 'Happy.Birthday.sir']\n",
      "WARNING:root:cannot compute similarity with no input ['SKULL-', 'COOL-', 'MAGMA-', 'SERIES-', 'RED-', 'COLOR-', 'SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640241993']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'G4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641558987']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'I3-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237723']\n",
      "WARNING:root:cannot compute similarity with no input ['KenTeaTime', 'Bitter＆Sweet', '巨大クロノグラフ', 'みせコド']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'K4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641558991']\n",
      "WARNING:root:cannot compute similarity with no input ['WINGS-', 'WERE-', 'READY-', 'BUT-', 'QUOTE-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237581']\n",
      "WARNING:root:cannot compute similarity with no input ['AND-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-', 'SILVER-CASE-FOR-IPHONE-6S-PLUS-/152641568460']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cannot compute similarity with no input ['🌺Aloha🏝I😇', \"PRAY🙏AllIsWell❗️💞I'mRecoveringFromACold❕🤒🙄🤧IStillOwe🥇\", 'HEROs🏆', 'Comey💙➕', 'Schumer🎨Graphics❗️✍🏽🖼💗', 'ItsBMcKnight❤', 'BrunoMars🚀', 'JustinBieber💜']\n",
      "WARNING:root:cannot compute similarity with no input ['LOVE-', 'NY-', 'B-', 'amp-', 'W-', 'EMPIRE-', 'ST-BLDG-DESIGN-CLEAR-CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640269048']\n",
      "WARNING:root:cannot compute similarity with no input ['ready-to-join-', 'hurriyat-mla-rashid-on-', 'geelani-s-offer']\n",
      "WARNING:root:cannot compute similarity with no input ['NowPlaying', 'S_C_', 'and', 'linkinpark', 'Numb/Encore']\n",
      "WARNING:root:cannot compute similarity with no input ['BruceElling10', 'FindAWay', \"God'sWay\", 'StagStrong', 'SpursUp']\n",
      "WARNING:root:cannot compute similarity with no input ['BLACK-', 'BOSTON-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640269238']\n",
      "WARNING:root:cannot compute similarity with no input ['Sundaaaaay💕🔥', 'Blessed😇']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'S1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260308']\n",
      "WARNING:root:cannot compute similarity with no input ['ᴬᴺᴼᵀᴴᴱᴿ', 'ᴰᴬᵞ', 'ᴬᴺᴼᵀᴴᴱᵀ', 'ᴮᴸᴱˢˢᴵᴺᴳ', 'ᴬᴺᴼᵀᴴᴱᴿ', 'ᴼᴾᴱᴿᵀᵁᴺᴵᵀᵞ', 'ᴬᴺᴼᵀᴴᴱᴿ', 'ᴿᴵˢᴷ', 'ᵀᴼ', 'ᵀᴬᴷᴱ', 'thankful🙏']\n",
      "WARNING:root:cannot compute similarity with no input [\"mad's_room\"]\n",
      "WARNING:root:cannot compute similarity with no input ['gurruchoudhary', 'Nice☺', 'Blessed..', '🙏🙏']\n",
      "WARNING:root:cannot compute similarity with no input ['awesome-answer', 'twitter-api']\n",
      "WARNING:root:cannot compute similarity with no input ['rovendetti', 'NaughtyBeyotch', 'Arc7Angle', 'Dumb-o-crats']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'J4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584265']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'B1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640269113']\n",
      "WARNING:root:cannot compute similarity with no input ['Love❤️Sports💯', 'Love❤️AllGoodPeople💯', 'Hate😤Politics💯']\n",
      "WARNING:root:cannot compute similarity with no input ['LOVE-', 'NEW-', 'YORK-', 'City-', 'That-', 'Never-', 'Sleeps-Design-Chrome-iPhone-7-6S-Plus-5-se-case-/152676479671']\n",
      "WARNING:root:cannot compute similarity with no input ['positive-energy', '❤️']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'K1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260182']\n",
      "WARNING:root:cannot compute similarity with no input [\"summer'17\", 'love❤️❤️❤️']\n",
      "WARNING:root:cannot compute similarity with no input ['proud-of-bsf-says-modi-on-raising-day-93562']\n",
      "WARNING:root:cannot compute similarity with no input ['Happy-childrens-day-', '...', '...', '...']\n",
      "WARNING:root:cannot compute similarity with no input ['directorsiva', 'Happy-Birthday', 'sir..']\n",
      "WARNING:root:cannot compute similarity with no input ['Love×love=Happiness']\n",
      "WARNING:root:cannot compute similarity with no input ['TBNRfrags', 'COOL😀vids']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'I4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559209']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'L2-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237789']\n",
      "WARNING:root:cannot compute similarity with no input ['GoodMorning', 'Blessed🙌🏾']\n",
      "WARNING:root:cannot compute similarity with no input ['SEETHROUGH-', 'COOL-', 'SILVER-', 'IPHONE-', '6S-', 'PLUS-', 'CASE-TEMPERED-GLASS-PROTECTOR-/152641575420']\n",
      "WARNING:root:cannot compute similarity with no input ['BLACK-', 'BOSTON-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237598']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'B1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-TPU-CASE-FOR-IPHONE-7-/152641594465']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'A4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640269157']\n",
      "WARNING:root:cannot compute similarity with no input ['TGFAD🙏🏾', 'Blessed🙏🏾💯']\n",
      "WARNING:root:cannot compute similarity with no input ['BOLD-', 'DENVER-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237708']\n",
      "WARNING:root:cannot compute similarity with no input ['joyreneoutsold', \"Joy'sExtension1stwin\"]\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'M1-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237617']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'A1-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237566']\n",
      "WARNING:root:cannot compute similarity with no input ['nycgov', 'home❤️', 'love❤️alwaysNYC']\n",
      "WARNING:root:cannot compute similarity with no input ['BigHitEnt', 'LoVe-YoUrSeLf']\n",
      "WARNING:root:cannot compute similarity with no input ['GO-', 'inspired-', 'Valor-', 'Red-', 'Team-', 'Design-', 'iPhone-7-6s-Plus-5-SE-Galaxy-slim-case-/152676479633']\n",
      "WARNING:root:cannot compute similarity with no input ['YOUR-', 'WINGS-', 'WERE-', 'READY-', '034-', 'Quote-', 'Premium-Chrome-iPhone-7-Plus-6-5-s-se-case-/152676479594']\n",
      "WARNING:root:cannot compute similarity with no input ['A-', 'Black-', 'amp-', 'Clear-', 'Nice-', 'Creative-', 'Design-Chrome-iPhone-7-6S-Plus-5-SE-case-/152641535629']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'V1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641558967']\n",
      "WARNING:root:cannot compute similarity with no input ['Love-Where']\n",
      "WARNING:root:cannot compute similarity with no input ['PINK-', 'MANDALA-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260271']\n",
      "WARNING:root:cannot compute similarity with no input ['grief-after-death-cant-be-measured-big-b-88606']\n",
      "WARNING:root:cannot compute similarity with no input ['MONSTA_X', 'DRAMARAMA', 'THE_CODE', '몬스타엑스', 'MONBEBE', 'PROUD🌟🐻🐰🐶🐹🐢🐝🐺🌟😍😍😍😘😘😘', 'FIGHTING✊✊✊']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'M4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559009']\n",
      "WARNING:root:cannot compute similarity with no input ['Sunday💕', 'blessed😇']\n",
      "WARNING:root:cannot compute similarity with no input ['AND-', 'BLUE-', 'MANDALAS-', 'W-', 'CIRCLE-', 'TITANIUM-', 'BLACK-CASE-FOR-IPHONE-7-6-PLUS-/152641533127']\n",
      "WARNING:root:cannot compute similarity with no input ['BeConsistent', 'BePositive', 'BeExtraordinary', 'CodeBlack18', 'Notor19us', 'Nasty☠Bunch', 'SMTTT', '🦅🔝']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'Z4-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237693']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'D3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260273']\n",
      "WARNING:root:cannot compute similarity with no input ['LOVE-', 'NY-', 'B-', 'amp-', 'W-', 'EMPIRE-', 'ST-BLDG-DESIGN-WITH-CLEAR-ROSE-GOLD-FOR-IPHONE-6-6S-PLUS-/152641584124']\n",
      "WARNING:root:cannot compute similarity with no input [\"happy'INDEPENDENCE'day\"]\n",
      "WARNING:root:cannot compute similarity with no input ['🔸Forever', 'Grateful✨💛🙌']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'T1-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237780']\n",
      "WARNING:root:cannot compute similarity with no input ['lucky-ali-papon-join-time-out-72-line-up-90848']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'L4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584191']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'U4-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237608']\n",
      "WARNING:root:cannot compute similarity with no input ['DalaiLama', 'warm-hearted']\n",
      "WARNING:root:cannot compute similarity with no input ['╟╨╖╙╖║╥╜j', '╲╰━╯┈┈┈┣▅━┫┏╮┃╱━╯┈┈', '┈╰╲┈┈┈╱┈┈▇┈┈▕▔▔▔▔┊', '╓░░░░HAPPY░', 'HAPPY░HA', '╭╮╭\\U0005dc0a🔷🔷🔷🔷🔷🔷🔷🔷🔷📕', '┈┃┈┈┏┛┗┻┊┻┗┛┗┻', '┻╰']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cannot compute similarity with no input [\"God'is'God\"]\n",
      "WARNING:root:cannot compute similarity with no input ['feelaliveuk', 'Alive⭐', 'DeskPlanner⭐', 'GetOrganised⭐', 'Pens⭐', 'Competition⭐', 'Giveaway⭐', '⭐Liked⭐', '⭐Retweeted⭐', '⭐📌📌📌📌⭐']\n",
      "WARNING:root:cannot compute similarity with no input ['Momsprincess_z', 'Happy\\u200bfriendshipday', 'aruntwitzzz', 'Dhandutwitzz', 'thangamagan100', 'preethitalks', 'SairSairam', 'thisispsrk']\n",
      "WARNING:root:cannot compute similarity with no input ['Dure_shahwar_WB', 'WaseemBadami', 'Shuuuukkkkkrrrrrriiiiyyyyyyaaaaaaaa', 'Dureeeeeeeeeeeee', '❤❤❤❤❤❤❤❤❤', 'Also😭😭😭😭😭😭😭😭😭', 'Blessed😇']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'L4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260045']\n",
      "WARNING:root:cannot compute similarity with no input ['Mikhail1888', 'pissed.com', '*childline', '😂😂😂']\n",
      "WARNING:root:cannot compute similarity with no input [\"God'sNotDead\", \"God'sNotDead2\"]\n",
      "WARNING:root:cannot compute similarity with no input ['rage☄', 'energy⚡']\n",
      "WARNING:root:cannot compute similarity with no input ['peplamb', 'peplamb', 'God.', '2/2']\n",
      "WARNING:root:cannot compute similarity with no input ['Malbrenbremal', 'vjmlloyd1', 'Kate1880', '*knee*', 'confused.comneil']\n",
      "WARNING:root:cannot compute similarity with no input ['ᵀᴴᴬᴺᴷ', 'ᵞᴼᵁ', 'ᶠᴼᴿ', 'ᴹᵞ', 'ᴳᴵᶠᵀ', 'ᴳᴼᴰ', 'ᴬᴺᴰ', 'ᴬᴸᴸᴼᵂᴵᴺᴳ', 'ᴹᴱ', 'ᵀᴼ', 'ᵀᴼᵁᶜᴴ', 'ᵀᴴᴱ', 'ᵂᴼᴿᴸᴰ', 'ᵂᴵᵀᴴ', 'ᴹᵞ', 'ᴹᵁˢᴵᶜ', 'ˢᴼᴼᴺ', 'ᵞᴼᵁ', 'ᵞᴼᵁ', 'ᵞᴼᵁ', 'ᵂᴵᴸᴸ', 'ᴷᴺᴼᵂ', 'ᴹᵞ', 'ᴺᴬᴹᴱ', 'Thankful🙏']\n",
      "WARNING:root:cannot compute similarity with no input ['awesome-answer', 'twitter-api', '🦑🤷\\u200d♂️']\n",
      "WARNING:root:cannot compute similarity with no input ['Bitter-sweet']\n",
      "WARNING:root:cannot compute similarity with no input ['ThomasWictor', 'itbmeang', 'GenFlynn', 'Beautiful💞Tribute', 'BeautifulFamily✨']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'L3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641558958']\n",
      "WARNING:root:cannot compute similarity with no input ['BLACK-', 'AUSTIN-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237728']\n",
      "WARNING:root:cannot compute similarity with no input ['IssaRae', 'insecure=life']\n",
      "WARNING:root:cannot compute similarity with no input ['TheRealVOSTCat', 'KittyLibFront', 'grateful🐾very💜']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'X1-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640242041']\n",
      "WARNING:root:cannot compute similarity with no input ['Love💕', 'Ｈａｐｐｙ', 'ړײ', 'Ｄａｙ', '1F_st', '┋💞', '1FIRST💦', '╰👑┉➢', 'BelaTaly', 'Mechis_M', 'AdryMMP', 'M_MartinezRed', 'TheLeaderMex', 'VValcuende', 'AdryMMP', 'SophiaKamy']\n",
      "WARNING:root:cannot compute similarity with no input ['BLACK-', 'QUEENS-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237589']\n",
      "WARNING:root:cannot compute similarity with no input [\"God'snotdead\"]\n",
      "WARNING:root:cannot compute similarity with no input ['AND-', 'BLUE-', 'BOHO-', 'STYLE-', 'DESIGN-', 'WITH-', 'CLEARSILVER-CASE-FOR-IPHONE-7-6-PLUS-/152641532039']\n",
      "WARNING:root:cannot compute similarity with no input ['yaaaahhhh', 'God+Grind=Success']\n",
      "WARNING:root:cannot compute similarity with no input [\"Don'tCrackUnderPressure\", 'HoldOnTight', 'ThereIsNoLimitToWhatYouCanAchieve', 'Hope/Believe/Persistence', 'Psalm3:2-6', 'Mark4:30-34', '1Peter1:36']\n",
      "WARNING:root:cannot compute similarity with no input ['Loobydooby24', 'Excited.com']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'B2-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237685']\n",
      "WARNING:root:cannot compute similarity with no input ['GOOD🙌MORNING', 'W🌎RLD😆', 'BLESSED🙏🔐💯💋']\n",
      "WARNING:root:cannot compute similarity with no input ['Badnight', 'Trust💔']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'B2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260179']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'L4-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237735']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'A2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584240']\n",
      "WARNING:root:cannot compute similarity with no input ['SKULL-', 'COOL-', '3D-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640241764']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'K2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559015']\n",
      "WARNING:root:cannot compute similarity with no input ['LittleToni💕', 'Blessed😇🙏']\n",
      "WARNING:root:cannot compute similarity with no input ['blue-grey']\n",
      "WARNING:root:cannot compute similarity with no input ['TIE-', 'DYE-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6S-PLUS-/152641575637']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'B3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640269114']\n",
      "WARNING:root:cannot compute similarity with no input ['selfie😘😘', 'cute😍😍😍😘😘']\n",
      "WARNING:root:cannot compute similarity with no input ['19cmothman', 'Pray.for.mothman']\n",
      "WARNING:root:cannot compute similarity with no input ['Happy❤❤', 'Independance💕💕Day', 'PakistanZindabad']\n",
      "WARNING:root:cannot compute similarity with no input ['Blue-', 'amp-', 'Clear-', 'Nice-', 'Cool-', 'Nature-', 'Design-Chrome-iPhone-7-6-S-Plus-se-case-/152676479500']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'B1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584295']\n",
      "WARNING:root:cannot compute similarity with no input ['BLACK-', 'BEACH-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237697']\n",
      "WARNING:root:cannot compute similarity with no input ['Better🙏🏾CauseTheGetBackComing']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'A2-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237639']\n",
      "WARNING:root:cannot compute similarity with no input ['Mom✔️dad✔️siblings✔️', 'blessed🙏🏽']\n",
      "WARNING:root:cannot compute similarity with no input ['NewYorker', 'ill-equipped']\n",
      "WARNING:root:cannot compute similarity with no input [\"God'sPurpose\"]\n",
      "WARNING:root:cannot compute similarity with no input ['tgfad', '...', 'Blessed🙌']\n",
      "WARNING:root:cannot compute similarity with no input ['LEOPARD-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'TITANIUM-', 'BLACK-CASE-FOR-IPHONE-7-6-PLUS-/152641531975']\n",
      "WARNING:root:cannot compute similarity with no input ['GoodMorning', '...', 'Blessed🤞🏾']\n",
      "WARNING:root:cannot compute similarity with no input [\"God'sSpeed\"]\n",
      "WARNING:root:cannot compute similarity with no input ['GREEK-', 'PATTERN-', 'DESIGN-', 'BLACK-', 'GOLD-', 'CASE-', 'FOR-IPHONE-6S-PLUS-GLASS-/152641564866']\n",
      "WARNING:root:cannot compute similarity with no input ['bitter-sweet']\n",
      "WARNING:root:cannot compute similarity with no input ['lauferlaw', 'shocked/NOTSHOCKED']\n",
      "WARNING:root:cannot compute similarity with no input ['welcome|to|the|deep|thoughts|of|Alisha🙇🏽']\n",
      "WARNING:root:cannot compute similarity with no input ['CassperNyovest', \"God'ssentSponsors\"]\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'V3-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640242051']\n",
      "WARNING:root:cannot compute similarity with no input ['BLACK-', 'JERSEY-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640241960']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'B4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640269070']\n",
      "WARNING:root:cannot compute similarity with no input ['M-', 'Black-', 'amp-', 'Clear-', 'Nice-', 'Creative-', 'Design-Chrome-iPhone-7-6S-Plus-5-SE-case-/152641535820']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'W2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641558973']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cannot compute similarity with no input ['Pooja_namobhakt', 'Happy-Burthday', 'To-You']\n",
      "WARNING:root:cannot compute similarity with no input ['xfactor2017', 'cute-grandparents', '👫💑💏']\n",
      "WARNING:root:cannot compute similarity with no input ['JaskenRaider', 'love+life']\n",
      "WARNING:root:cannot compute similarity with no input ['BLUE-', 'MANDALAS-', 'WITH-', 'LOGO-', 'CIRCLE-', 'DESIGN-', 'CLEAR-CHROME-CASE-FOR-IPHONE-7-/152676487296']\n",
      "WARNING:root:cannot compute similarity with no input ['Happy/HealthyGracie']\n",
      "WARNING:root:cannot compute similarity with no input ['Mondayy😇😍', 'Blessed😎']\n",
      "WARNING:root:cannot compute similarity with no input ['WOTD', 'Faith.♥']\n",
      "WARNING:root:cannot compute similarity with no input ['love🔹', 'selfawareness🔹', 'honesty🔹', 'psychology🔹', 'motivation🔹', 'learning🔹', 'emotionalintelligence🔹', 'happymonday🔹', 'goodvibes🔹blessings']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'B2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584312']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'R3-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640242050']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'W1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641586754']\n",
      "WARNING:root:cannot compute similarity with no input ['RCCGPromisedLan', 'riddingoutthestorm', \"God'slove\"]\n",
      "WARNING:root:cannot compute similarity with no input ['waiting-for-answers-on-corruption-allegations-from-maun-sahab-rahul-to-modi-94849']\n",
      "WARNING:root:cannot compute similarity with no input ['IvelisseFrances', '🔥🔥🔥', 'love-theTwitter']\n",
      "WARNING:root:cannot compute similarity with no input ['Love/GoodAlwaysWins']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'K1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559062']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'I2-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237712']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'O4-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237715']\n",
      "WARNING:root:cannot compute similarity with no input [\"God'SNotDead❤\"]\n",
      "WARNING:root:cannot compute similarity with no input ['tgfad', '...', 'Blessed🙌🏾']\n",
      "WARNING:root:cannot compute similarity with no input ['SKYLINE-', 'SEETHROUGH-', 'COOL-', '3D-', 'DESIGN-', 'ROSE-', 'GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641586909']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'W2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260095']\n",
      "WARNING:root:cannot compute similarity with no input ['Bitter＆Sweet']\n",
      "WARNING:root:cannot compute similarity with no input ['PAISLEY-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'TITANIUM-', 'BLACK-CASE-FOR-IPHONE-7-6-PLUS-/152641531866']\n",
      "WARNING:root:cannot compute similarity with no input ['productive-to-be']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'Y1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559028']\n",
      "WARNING:root:cannot compute similarity with no input ['H-', 'Black-', 'amp-', 'Clear-', 'Nice-', 'Creative-', 'Design-Chrome-iPhone-7-6-S-Plus-5-SE-case-/152676479426']\n",
      "WARNING:root:cannot compute similarity with no input ['CATCHER-', 'COOL-', 'MAGMA-', 'SERIES-', 'RED-', 'COLOR-', 'SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237659']\n",
      "WARNING:root:cannot compute similarity with no input ['love=acceptance']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'K1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584275']\n",
      "WARNING:root:cannot compute similarity with no input [\"Ursula'sDaughter\", 'Blue💙', \"Maleficent'sDaughter\", 'Purple💜']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'W4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260178']\n",
      "WARNING:root:cannot compute similarity with no input ['sad/happymories']\n",
      "WARNING:root:cannot compute similarity with no input ['SKULL-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'TITANIUM-', 'BLACK-CASE-FOR-IPHONE-7-6-PLUS-/152641532059']\n",
      "WARNING:root:cannot compute similarity with no input ['love＆peace']\n",
      "WARNING:root:cannot compute similarity with no input ['SheHatesJacoby', 'Marvel🌟Brings', '...', 'JOY🤗']\n",
      "WARNING:root:cannot compute similarity with no input ['PrayForBarcelona', 'PrayForMarawi', 'StopTerrorism', \"God'sWithUs\"]\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'R1-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640242017']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'M3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584277']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'A3-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237668']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'K2-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237631']\n",
      "WARNING:root:cannot compute similarity with no input ['lost.soul/black.lungz']\n",
      "WARNING:root:cannot compute similarity with no input ['Taembs💖', 'complete✨']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'B1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559005']\n",
      "WARNING:root:cannot compute similarity with no input ['terror-plot-to-assassinate-british-pm-foiled-report-94180']\n",
      "WARNING:root:cannot compute similarity with no input ['Dream-big', 'Start-small']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'V4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260181']\n",
      "WARNING:root:cannot compute similarity with no input ['AwEsOmE', '...', 'fEeLiNg', '...']\n",
      "WARNING:root:cannot compute similarity with no input ['¶.-.¶||¶.-.¶', 'thElaDy', '...', '.thOught', '...', \"God's*\", '.ppl', '.are', '.pOwerFUL', '-~-']\n",
      "WARNING:root:cannot compute similarity with no input ['special-traffic-block-on-20-8-2017-83305']\n",
      "WARNING:root:cannot compute similarity with no input ['ammdillaaa', 'R.I.H.Amongst🌟🌟🌟', 'AMAZING👼', 'CUTE😍', \"CUZ'💖😘\"]\n",
      "WARNING:root:cannot compute similarity with no input ['MohanShakti', '😘😘', '...', 'BeAutiFuL..😘', '...', 'Awsm..😘', '...', 'धमाKa..😘', '...', 'UniK..😘']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'B3-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237799']\n",
      "WARNING:root:cannot compute similarity with no input ['ShraddhaKapoor', 'VeetIndia', '😘😘', '...', 'BeAutiFuL..😘', '...', 'Awsm..😘', '...', 'धमाKa..😘', '...', 'UniK..😘']\n",
      "WARNING:root:cannot compute similarity with no input ['BLUE-', 'PAISLEY-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641586964']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'F4-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237625']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'C2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559041']\n",
      "WARNING:root:cannot compute similarity with no input ['cybermodaydeal', 'com/', 'p/', 'chrome-', 'dream-', 'catcher-case-for-iphone-267423-38841352.html']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'F2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559123']\n",
      "WARNING:root:cannot compute similarity with no input ['Happy..TeachersDay', '...']\n",
      "WARNING:root:cannot compute similarity with no input ['GoodMorning☺️', 'Blessed🙏🏾']\n",
      "WARNING:root:cannot compute similarity with no input ['ᴰᴼᴺ', 'ᴶᵁᴰᴳᴱ..', 'ᵂᴴᴬᵀ', 'ᵞᴼᵁ', 'ᴰᴼᴺ', 'ᴷᴺᴼᵂ😏', 'stupid🖕🏼']\n",
      "WARNING:root:cannot compute similarity with no input ['DOWN-', 'CALM-', 'DOWN-', 'QUOTE-', 'Black-', 'amp-', 'Clear-Design-Chrome-iPhone-7-6s-Plus-SE-5-case-/152676479446']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'D3-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237654']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'C4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584254']\n",
      "WARNING:root:cannot compute similarity with no input ['fantastic-scenarios-or-paths-to-future-salvation-92920']\n",
      "WARNING:root:cannot compute similarity with no input ['...', 'WondErfUl', '💝💝💝💝💝💝💝', \"cUtE'dmarcy\", '😻😻😻😻😻😻😻']\n",
      "WARNING:root:cannot compute similarity with no input ['NewNameforHer', '62ax_', '💙💙💙', 'waiting💫']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'B4-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237613']\n",
      "WARNING:root:cannot compute similarity with no input ['Live•Laugh•Love', 'Blessed🙏🏾', 'lafamilia', 'striveforgreatness🚀', '😬😆😍']\n",
      "WARNING:root:cannot compute similarity with no input ['bummed/devastated']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'R2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641586934']\n",
      "WARNING:root:cannot compute similarity with no input ['HALLOWS-', 'SYMBOL-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6-6S-/152641560442']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'C4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260300']\n",
      "WARNING:root:cannot compute similarity with no input ['sad-im-an-indian-living-in-india-actor-rohit-roy-91967']\n",
      "WARNING:root:cannot compute similarity with no input ['🌺Aloha🏝➕GoodMorning', 'Everyone❗️I😇', \"Pray🙏We'reAll🤗Happy➕💞\", 'Healthy❗️💔💔', 'Prayers💔4💔💔', 'NYC💔💔OneCanOnly😿', 'HOPE😭', 'HumanBeings🤔📖', 'Learn📚2LoveEachOther📕💡❕']\n",
      "WARNING:root:cannot compute similarity with no input ['Baby💋', 'Love😘💕']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'A4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559228']\n",
      "WARNING:root:cannot compute similarity with no input ['love-is-reserved-for-God-and-His-image-and-not-for-things']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'L2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260143']\n",
      "WARNING:root:cannot compute similarity with no input ['milliebbrown', 'Stranger_Things', 'bradenm_99', 'TheWinchesters', \"God'sTriplets\"]\n",
      "WARNING:root:cannot compute similarity with no input ['GRADIENT-', 'TURQUOIS-', 'BLUE-', 'DESIGN-', 'CHROME-', 'SILVER-', 'CASE-FOR-IPHONE-6-6S-/152641556753']\n",
      "WARNING:root:cannot compute similarity with no input ['╚╝', 'LOVE┊┊┊┊┊┃┃╭━━', '▂▂▏▏┏━━━━━━┛┛━╯┃', '┈┈┈┈▕╲┈┈╱┊▏╱thBe', '╔╔╗║░░░░░░░░░░░║░', '╢┈┈┈┈┈▕▏┈▕╮┈┈┈┈┃┃', '╰▏┈s', 'ID╱MINGSONDAY┊┊┊▕', '┈▏', '┈╲▂▂▂▂▂▂▂╯┊┊┊▏']\n",
      "WARNING:root:cannot compute similarity with no input ['nervous-about-romancing-aishwarya-says-rajkummar-rao-87052']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'T1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641586859']\n",
      "WARNING:root:cannot compute similarity with no input ['LusandaBeja_', \"'s\", 'Performance😇🙌🙏', 'Blessed🙌', 'adecateofgospel', 'ONEGospel']\n",
      "WARNING:root:cannot compute similarity with no input ['DISNEY-', 'QUOTE-', '3D-', 'PRINTED-', 'COOL-', 'DESIGN-', 'CHROME-SILVER-CASE-FOR-IPHONE-6S-PLUS-/152641575412']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'K1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-TPU-CASE-FOR-IPHONE-7-/152641594447']\n",
      "WARNING:root:cannot compute similarity with no input ['DISNEY-', 'QUOTE-', 'COOL-', 'DESIGN-', 'COOL-', 'COOL-', 'DESIGN-ROSE-GOLD-CASE-FOR-IPHONE-7-6-PLUS-/152640247215']\n",
      "WARNING:root:cannot compute similarity with no input ['for🦊sakes']\n",
      "WARNING:root:cannot compute similarity with no input ['Love💗', 'jimin']\n",
      "WARNING:root:cannot compute similarity with no input ['TellStevens', 'RealGustav', \"God'sCountry\"]\n",
      "WARNING:root:cannot compute similarity with no input ['daniel_singu', 'Lame-ntable', 'SorryNotSorry']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'M4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260081']\n",
      "WARNING:root:cannot compute similarity with no input ['IF-', 'SHE-', '039-', 'S-', 'AMAZING-', '034-', 'BOB-MARLEY-QUOTE-Chrome-iPhone-7-6-S-Plus-se-case-/152676479588']\n",
      "WARNING:root:cannot compute similarity with no input ['Happy-peace-day']\n",
      "WARNING:root:cannot compute similarity with no input ['OF-', 'SHAPES-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640269182']\n",
      "WARNING:root:cannot compute similarity with no input ['ZeeTV', 'Amazing..', 'zabardast..video..']\n",
      "WARNING:root:cannot compute similarity with no input ['thankful-for-love-criticism-for-simran-hansal-mehta-85777']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'O2-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237650']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'C4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641558972']\n",
      "WARNING:root:cannot compute similarity with no input ['DafyddTrystan', 'ayesleft', 'SAFE-TRAVEL']\n",
      "WARNING:root:cannot compute similarity with no input ['Amazing😍mosam☁☁', '💧💧']\n",
      "WARNING:root:cannot compute similarity with no input ['BLUE-', 'ANCHOR-', 'WITH-', 'ROPE-', 'MAGMA-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237656']\n",
      "WARNING:root:cannot compute similarity with no input ['isabellacueva', 'Isacuu', 'inlove', '😱😍']\n",
      "WARNING:root:cannot compute similarity with no input ['FLAG-', 'CLEAR-', 'BLUE-', 'AND-', 'RED-', 'DESIGN-', 'SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640241753']\n",
      "WARNING:root:cannot compute similarity with no input ['LOVE=', 'LOVE=', 'LOVE=', 'xoxoxoxo']\n",
      "WARNING:root:cannot compute similarity with no input ['BLACK-', 'NEW-', 'JERSEY-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-ROSE-GOLD-CASE-FOR-IPHONE-7-6-PLUS-/152640247293']\n",
      "WARNING:root:cannot compute similarity with no input ['SKULL-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-', 'SILVER-CASE-FOR-IPHONE-6S-PLUS-/152641575405']\n",
      "WARNING:root:cannot compute similarity with no input [\"God'splan\", '🙏🏽']\n",
      "WARNING:root:cannot compute similarity with no input ['💕Bruuuuuh', 'Chill😙👌']\n",
      "WARNING:root:cannot compute similarity with no input ['Mahalo🤙🏽4LotzOfExtraProtectionFrom👹', 'STALKERS👿Yesterday', 'YouNeverLeftMeUnattended😿', 'honolulupolice❗️🚨🙏😭', 'Appreciated💞💟', 'Miracle🙀From😇', 'GOD🙏😩😍']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'G3-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237684']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'A3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584186']\n",
      "WARNING:root:cannot compute similarity with no input ['dawnstaley', 'Believe.Lead.Inspire.Win', 'Proudfans']\n",
      "WARNING:root:cannot compute similarity with no input ['broken-hearted💔']\n",
      "WARNING:root:cannot compute similarity with no input ['ShawnMc56440918', 'ConstanceQueen8', 'Love❤️myPresident']\n",
      "WARNING:root:cannot compute similarity with no input ['Love💕', 'Ｈａｐｐｙ', 'ړײ', 'Ｄａｙ', '1F_st', '┋💞', '1FIRST💦', '╰👑┉➢', 'BelaTaly', 'Mechis_M', 'AdryMMP', 'M_MartinezRed', 'TheLeaderMex', 'VValcuende']\n",
      "WARNING:root:cannot compute similarity with no input ['finallyyyyy😭', 'joy🍫']\n",
      "WARNING:root:cannot compute similarity with no input ['BLACK-', 'NYC-', 'COOL-', '3D-', 'DESIGN-', 'WITH-', 'CLEAR-ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641586734']\n",
      "WARNING:root:cannot compute similarity with no input ['tealeafmeetstea', '_RebeccaParham', 'better-than-i-can-draw']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'R1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641586921']\n",
      "WARNING:root:cannot compute similarity with no input [\"God'sLoveistheAnswer\"]\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'W3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260333']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cannot compute similarity with no input ['EmpoweredToSucceed', \"God'sOwnChildren\"]\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'G1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584162']\n",
      "WARNING:root:cannot compute similarity with no input ['sad.small.hands']\n",
      "WARNING:root:cannot compute similarity with no input ['PoemsPorn', 'awesome.thissaysitall']\n",
      "WARNING:root:cannot compute similarity with no input ['DISNEY-', 'QUOTE-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641560460']\n",
      "WARNING:root:cannot compute similarity with no input ['Happy-GetTextedByUrExesTonite']\n",
      "WARNING:root:cannot compute similarity with no input ['LOVE-', 'NY-', 'SKYLINE-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237770']\n",
      "WARNING:root:cannot compute similarity with no input [\"God'sSon\"]\n",
      "WARNING:root:cannot compute similarity with no input ['Focused.us.gov']\n",
      "WARNING:root:cannot compute similarity with no input ['GersFamily', 'Heart💔Breaking', 'fernandoricksen', 'rangerslegend', 'awesomeguy', 'love♡', '💙🔴⚪🔵🙏👆']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'S3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260321']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'F1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584263']\n",
      "WARNING:root:cannot compute similarity with no input ['CAN-', 'AND-', 'I-', 'WILL-', 'QUOTE-', 'DESIGN-', 'COOL-SILVER-IPHONE-6S-CASE-amp-TEMPERED-GLASS-/152641560288']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'S2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260027']\n",
      "WARNING:root:cannot compute similarity with no input ['ready-for-any-punishment-from-party-for-remarks-aiyar-94645']\n",
      "WARNING:root:cannot compute similarity with no input [\"God'sway\"]\n",
      "WARNING:root:cannot compute similarity with no input ['Goodnight🌈💞', 'Blessed🙏', 'TeenChoice', 'backtoschool']\n",
      "WARNING:root:cannot compute similarity with no input ['OpiningPenguin', 'Surprised/NotSurprised']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'F1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559154']\n",
      "WARNING:root:cannot compute similarity with no input ['distantgeese', 'professional-troll']\n",
      "WARNING:root:cannot compute similarity with no input ['IGuessIWent2Far', 'Yet🤔again', '...', 'phewwwwy❗️❗️😿😩😶😤😏Unless', '...', 'UnlessIsAnUncertainWord4😇', 'HOPE🙏LOL🤣😅', \"I'm1stSusposed2PostAboutHis📺Performance2Day\", '...']\n",
      "WARNING:root:cannot compute similarity with no input ['اعلامِ\\u200cظهور', \"God'sNewWorldOrder\"]\n",
      "WARNING:root:cannot compute similarity with no input ['KeepGoing', 'Dream.Believe.Inspire']\n",
      "WARNING:root:cannot compute similarity with no input ['love-the-Lord-with-all-your-heart-not-your-head']\n",
      "WARNING:root:cannot compute similarity with no input ['uneasy-calm-in-punjab-haryana-army-out-83899']\n",
      "WARNING:root:cannot compute similarity with no input ['ORNAMENT-', 'COOL-', '3D-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641586772']\n",
      "WARNING:root:cannot compute similarity with no input ['Belief.Changed.Everything', 'Faith🙏🏾🙌🏾']\n",
      "WARNING:root:cannot compute similarity with no input ['billiejoe', \"God'sFavoriteBand2018Tour\"]\n",
      "WARNING:root:cannot compute similarity with no input ['welcome-to-4fashionbeats.com']\n",
      "WARNING:root:cannot compute similarity with no input ['BLACK-', 'NEW-', 'ORLEANS-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-ROSE-GOLD-CASE-FOR-IPHONE-7-6-PLUS-/152640247327']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'C1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-TPU-CASE-FOR-IPHONE-7-/152641594269']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'K3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260136']\n",
      "WARNING:root:cannot compute similarity with no input ['happy-idependenceday']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'E4-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237709']\n",
      "WARNING:root:cannot compute similarity with no input ['😇🙌🏽', 'TGFAD', 'blessed❤️']\n",
      "WARNING:root:cannot compute similarity with no input ['Happy.IndependenceDayIndia']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'N2-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237609']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'H4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584314']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'G1-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237695']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'F3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559142']\n",
      "WARNING:root:cannot compute similarity with no input ['Sleepiiiii', 'girllll', '😍😘', 'God😘']\n",
      "WARNING:root:cannot compute similarity with no input ['Believe-you-can']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'J3-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237638']\n",
      "WARNING:root:cannot compute similarity with no input ['realDonaldTrump', 'USELESS-IN-CHIEF']\n",
      "WARNING:root:cannot compute similarity with no input ['MLRosie', 'beautiful☛face', '☛you☄', '☮☯']\n",
      "WARNING:root:cannot compute similarity with no input ['Dream-chasing', '🙏🏽', '1•28•17']\n",
      "WARNING:root:cannot compute similarity with no input ['GOODMORNING❤', 'blessed☺']\n",
      "WARNING:root:cannot compute similarity with no input ['happy-that-an-underdog-film-like-fukrey-returns-did-well-says-richa-95578']\n",
      "WARNING:root:cannot compute similarity with no input ['Love‐tune', 'Mr.King']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'U1-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640241994']\n",
      "WARNING:root:cannot compute similarity with no input ['chocolate__1022', 'Bitter×Sweet', '夢咲新華', 'aran0919', '篠宮得', '25elmo__', '三葉芽生', 'mitsuba__ttr64']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'W1-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260161']\n",
      "WARNING:root:cannot compute similarity with no input ['🤔NowINeed💯🍫➕🐣🐥🦅Yayyy❗️🐥♥️😇', 'GODIsLove🙏', 'BibleStudy📚', 'COLLAB📽🎞🎬🎹🎸🎙', 'Pray🙏', '/Or😍', 'DATE👫🤣😹💝', \"JustinBieber's💜➕💘\", \"BrunoMars'🚀\", 'Feelings4Me', 'ItsBMcKnight💓']\n",
      "WARNING:root:cannot compute similarity with no input ['..', 'powerful♪', 'Stuck💭']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'T3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559131']\n",
      "WARNING:root:cannot compute similarity with no input ['CYBERSTONE666', 'RobBoxfit121', 'Signed/Shared', 'Horrible💔💔😭😡😡😡', 'StopAnimalAbuse', 'AnimalsHaveRights']\n",
      "WARNING:root:cannot compute similarity with no input ['llcoolj', 'AMEN❥🙏✝~', 'Sir💟✨❥••', 'Take•A•Knee~', 'NFL🏈~', 'Faith✞', 'With✱', 'Action✦~', '💎✱💎✱💎✱💎✱💎✱', '❥~']\n",
      "WARNING:root:cannot compute similarity with no input [\"God'sAlive\"]\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'D4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260198']\n",
      "WARNING:root:cannot compute similarity with no input ['3D-', 'PRINTED-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'TPU-ROSE-GOLD-CASE-FOR-IPHONE-6-6S-/152641565081']\n",
      "WARNING:root:cannot compute similarity with no input ['Faith+Jesse']\n",
      "WARNING:root:cannot compute similarity with no input ['Happy-vacations-people:33']\n",
      "WARNING:root:cannot compute similarity with no input ['AlexWassabi', 'Awesome👍Congrats']\n",
      "WARNING:root:cannot compute similarity with no input ['ImRaina', 'wow😍😍it', \"'s\", 'Awesome✌️✌️✌️']\n",
      "WARNING:root:cannot compute similarity with no input ['WAVES-', 'COOL-', '3D-', 'SILVER-', 'IPHONE-', '6S-', 'PLUS-CASE-TEMPERED-GLASS-PROTECTOR-/152676479488']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cannot compute similarity with no input ['0kayalexx', 'SuperKyraa', 'mariallimendoza', 'Yc_Zelle', 'gennamasilungan', 'iHateMarianne', 'mikaelazhoran', 'ClaireMaaba', 'YManset', 'congratzz', 'chill😂']\n",
      "WARNING:root:cannot compute similarity with no input ['NIGHT-', 'SKY-', 'Black-', 'amp-', 'Clear-', 'Cool-', 'Design-Chrome-iPhone-se-5-6-S-Plus-case-/152676479523']\n",
      "WARNING:root:cannot compute similarity with no input ['FlossyandJim', 'cool-on-a-spoon']\n",
      "WARNING:root:cannot compute similarity with no input ['1nationality_', 'welcome-thnk']\n",
      "WARNING:root:cannot compute similarity with no input ['Happy*', 'children*day*']\n",
      "WARNING:root:cannot compute similarity with no input ['realDonaldTrump🇺🇸', 'POTUS🗽', 'FLOTUS🌺', 'AlohaFriday🏝I😇', \"Pray🙏You'reBothHappy/Safe/Well❕💞😍💟I'm🎈Cheering🎉4YouATadInTheCorner\", '4RightChoices2', '...']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'I4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584283']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'X2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641586945']\n",
      "WARNING:root:cannot compute similarity with no input ['lame🦆trump']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'P4-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237784']\n",
      "WARNING:root:cannot compute similarity with no input ['BOHO-', 'STYLE-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584155']\n",
      "WARNING:root:cannot compute similarity with no input ['healthy-buying-sentiment-lifts-equity-indices-to-new-highs-90186']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'Y2-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640241995']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'M3-', 'COOL-', 'MAGMA-', 'BLACK-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237722']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'B1-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237616']\n",
      "WARNING:root:cannot compute similarity with no input ['AMREENam14', 'ℳǟŜŤ😘', 'ÃwēsØmē😍', 'Beautiful👉💖', 'Wow😎👈', '⚘🌼ℒℴѵℯℒy', '🌼💢®®©']\n",
      "WARNING:root:cannot compute similarity with no input ['Hellow', 'Happy😘']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'C3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260023']\n",
      "WARNING:root:cannot compute similarity with no input ['😱🚗', \"God'sPlan\"]\n",
      "WARNING:root:cannot compute similarity with no input ['love+fear', '=sweet']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'C2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584202']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'C1-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237610']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'G2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260093']\n",
      "WARNING:root:cannot compute similarity with no input ['shelbyyreynolds', \"God'sCountry\", '🙏🏽💪🏽💪🏽']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'B2-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641558963']\n",
      "WARNING:root:cannot compute similarity with no input ['tgfad', 'BLESSED🙌']\n",
      "WARNING:root:cannot compute similarity with no input ['TheRealMikeEpps', 'prayersforhouston', 'HurricaneHarvey', \"God'sProtectionforHoustonFamilies\"]\n",
      "WARNING:root:cannot compute similarity with no input ['DeborahB17', 'sh143333', '19dicembre', 'ItsDiamondMarie', 'ParisJacksonz', 'kimberlyvelasc7', 'LOVE=LOVE=LOVExoxo']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'D1-', 'COOL-', 'MAGMA-', 'BROWN-', 'RED-', 'COLOR-SHIFTING-CASE-FOR-IPHONE-7-6-PLUS-/152640237651']\n",
      "WARNING:root:cannot compute similarity with no input ['love⚽️lovetherorkes']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'F4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-7-6-PLUS-/152640260053']\n",
      "WARNING:root:cannot compute similarity with no input ['ambertamblyn', 'appreciated💯', '💯respect', '😎👍✔', '😎👊✔', '😎✌✔']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'W3-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641586957']\n",
      "WARNING:root:cannot compute similarity with no input ['PINK-', 'AND-', 'BLUE-', 'BOHO-', 'STYLE-', 'DESIGN-', 'CLEAR-ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584226']\n",
      "WARNING:root:cannot compute similarity with no input ['INITIAL-', 'K4-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'ROSE-GOLD-CASE-FOR-IPHONE-6S-PLUS-/152641584337']\n",
      "WARNING:root:cannot compute similarity with no input ['B-', 'Black-', 'amp-', 'Clear-', 'Nice-', 'Creative-', 'Design-Chrome-iPhone-7-6-S-Plus-5-SE-case-/152641535682']\n",
      "WARNING:root:cannot compute similarity with no input ['BLUE-', 'PAISLEY-', 'COOL-', 'DESIGN-', 'WITH-', 'CLEAR-', 'CHROME-SILVER-CASE-FOR-IPHONE-6-6S-/152641559077']\n"
     ]
    }
   ],
   "source": [
    "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv,test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg_Word2vec_model = LogisticRegression(n_jobs=1, C=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning:\n",
      "\n",
      "Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## training the data\n",
    "logreg_Word2vec_model = logreg_Word2vec_model.fit(X_train_word_average, traindf['text'])\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict!\n",
    "y_train_pred_Word2vec = logreg_Word2vec_model.predict(X_train)\n",
    "\n",
    "y_pred_Word2vec = logreg_Word2vec_model.predict(X_test_word_average)\n",
    "y_pred_Word2vec[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Result Evaluation /accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train1 = accuracy_score(y_true=y_train, y_pred=y_train_pred_Word2vec_model)\n",
    "acc_test1 = accuracy_score(y_true=y_test, y_pred=y_pred_Word2vec_model)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train1, 15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy %s' % accuracy_score(y_pred, test.tags))\n",
    "print(classification_report(test.tags, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result \n",
    "\n",
    "test_id = testdf.id\n",
    "def listOfTuples(test_id, y_test_pred_logreg_model): \n",
    "    return list(map(lambda x, y:(x,y), test_id, y_pred_Word2vec)) \n",
    "\n",
    "finalresult = (listOfTuples(test_id, y_pred_Word2vec))\n",
    "finalresult[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass the result into panda dataframe and print the result to see\n",
    "dfresult = pd.DataFrame(finalresult) \n",
    "dfresult\n",
    "\n",
    "#Then assign header names and print the data to see\n",
    "dfresult.columns = ['id','emotion']\n",
    "dfresult\n",
    "\n",
    "#Then export the file \n",
    "exportcsv2 = dfresult.to_csv (r'C:\\Users\\User\\Data Mining_NTHU\\DMlab2x\\DM19-Lab2-Homework_Twitter - ทำไฟล์ตรงนี้ เวลาอัพไปอัพที่อื่น\\Dataset_Twitter_Word2vec embedding and Logistic Regression.csv', \n",
    "                               index = None, header=True) \n",
    "print (dfresult)\n",
    "\n",
    "#submit score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2vec and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:648: FutureWarning:\n",
      "\n",
      "The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(doc2vec.TaggedDocument(v.split(), [label]))\n",
    "    return labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#by combine hastag, text and score for both test and train dataset\n",
    "X_train = traindf[['text','hashtag','score']].astype(str).apply('-'.join, axis=1)\n",
    "y_train = traindf['emotion']\n",
    "X_test = testdf[['text','hashtag','score']].astype(str).apply('-'.join, axis=1)\n",
    "y_test = testdf['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8afbba2c6c08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#X_train, X_test, y_train, y_test = train_test_split(df.post, df.tags, random_state=0, test_size=0.3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mall_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-bca3c695cfb6>\u001b[0m in \u001b[0;36mlabel_sentences\u001b[1;34m(corpus, label_type)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_type\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mlabeled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTaggedDocument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlabeled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc2vec' is not defined"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(df.post, df.tags, random_state=0, test_size=0.3)\n",
    "X_train = label_sentences(X_train, 'Train')\n",
    "X_test = label_sentences(X_test, 'Test')\n",
    "all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(train_vectors_dbow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
    "y_pred = logreg.predict(test_vectors_dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1018894\n",
      "Test size: -606922\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "train_size = int(len(traindf) * .7)\n",
    "print (\"Train size: %d\" % train_size)\n",
    "print (\"Test size: %d\" % (len(testdf) - train_size))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = traindf['text'][:train_size]\n",
    "train_hashtag = traindf['hashtag'][:train_size]\n",
    "\n",
    "test_text = testdf['text'][train_size:]\n",
    "test_hashtag = testdf['hashtag'][train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize.fit_on_texts(train_text) # only fit on train\n",
    "x_train = tokenize.texts_to_matrix(train_text)\n",
    "x_test = tokenize.texts_to_matrix(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_hashtag)\n",
    "y_train = encoder.transform(train_hashtag)\n",
    "y_test = encoder.transform(test_hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-08f0d304101e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mcategorical\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/twitter-sentiment-analysis-classification-using-nltk-python-fa912578614c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Data Preprocessing and Feature Engineering\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "#Model Selection and Validation\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import prepared dataset\n",
    "\n",
    "traindf = pd.read_csv('traindf.csv')\n",
    "\n",
    "testdf = pd.read_csv('testdf.csv')\n",
    "testdf['emotion'] = testdf.apply(lambda _: '', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "def no_user_alpha(tweet):\n",
    "    tweet_list = [ele for ele in tweet.split() if ele != 'user']\n",
    "    clean_tokens = [t for t in tweet_list if re.match(r'[^\\W\\d]*$', t)]\n",
    "    clean_s = ' '.join(clean_tokens)\n",
    "    clean_mess = [word for word in clean_s.split() if word.lower() not in stopwords.words('english')]\n",
    "    return clean_mess\n",
    "print(no_user_alpha(form_sentence(traindf['text'].iloc[10])))\n",
    "print(traindf['text'].iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lexicon Normalization\n",
    "def normalization(tweet_list):\n",
    "        lem = WordNetLemmatizer()\n",
    "        normalized_tweet = []\n",
    "        for word in tweet_list:\n",
    "            normalized_text = lem.lemmatize(word,'v')\n",
    "            normalized_tweet.append(normalized_text)\n",
    "        return normalized_tweet\n",
    "    \n",
    "tweet_list = 'I was playing with my friends with whom I used to play, when you called me yesterday'.split()\n",
    "print(normalization(tweet_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_processing)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_train, msg_test, label_train, label_test = train_test_split(train_tweets['tweet'], train_tweets['label'], test_size=0.2)\n",
    "pipeline.fit(msg_train,label_train)\n",
    "predictions = pipeline.predict(msg_test)\n",
    "print(classification_report(predictions,label_test))\n",
    "print(confusion_matrix(predictions,label_test))\n",
    "print(accuracy_score(predictions,label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modified Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import prepared dataset\n",
    "traindf_m = pd.read_csv('traindf.csv')\n",
    "\n",
    "testdf_m = pd.read_csv('testdf.csv')\n",
    "testdf_m['emotion'] = testdf_m.apply(lambda _: '', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a96090d81629>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0memoji\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-5f1cb59e883b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0memoji\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0memot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0memoji\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdemojize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraindf_m\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filtered_traindf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "import emot\n",
    "emoji.demojize(traindf_m['filtered_traindf'], delimiters=(\"\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'demoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c8ec97fcf5c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdemoji\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'demoji'"
     ]
    }
   ],
   "source": [
    "import demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Twitter - Kaggle ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
